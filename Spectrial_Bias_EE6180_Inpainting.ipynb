{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csxuM1GP0hav"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
        "\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import sys\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import imageio\n",
        "from scipy.signal import convolve2d as conv2\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MeanOnlyBatchNorm(nn.Module):\n",
        "    def __init__(self, num_features, momentum=0.1):\n",
        "        super(MeanOnlyBatchNorm, self).__init__()\n",
        "        self.num_features = num_features\n",
        "        self.bias = Parameter(torch.Tensor(num_features))\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, inp):\n",
        "        size = list(inp.size())\n",
        "        beta = self.bias.view(1, self.num_features, 1, 1)\n",
        "        avg = torch.mean(inp.view(size[0], self.num_features, -1), dim=2)\n",
        "\n",
        "        output = inp - avg.view(size[0], size[1], 1, 1)\n",
        "        output = output + beta\n",
        "\n",
        "        return output\n",
        "\n",
        "def bn(num_features):\n",
        "    return MeanOnlyBatchNorm(num_features)\n",
        "    #return nn.BatchNorm2d(num_features)\n",
        "\n",
        "def l2normalize(v, eps=1e-12):\n",
        "    return v / (v.norm() + eps)\n",
        "\n",
        "class SpectralNorm(nn.Module):\n",
        "    def __init__(self, module, ln_lambda=2.0, name='weight'):\n",
        "        super(SpectralNorm, self).__init__()\n",
        "        self.module = module\n",
        "        self.name = name\n",
        "        self.ln_lambda = torch.tensor(ln_lambda)\n",
        "        if not self._made_params():\n",
        "            self._make_params()\n",
        "\n",
        "    def _update_u_v(self):\n",
        "\n",
        "        w = getattr(self.module, self.name + \"_bar\")\n",
        "        height = w.data.shape[0]\n",
        "\n",
        "        _,w_svd,_ = torch.svd(w.view(height,-1).data, some=False, compute_uv=False)\n",
        "        sigma = w_svd[0]\n",
        "        sigma = torch.max(torch.ones_like(sigma),sigma/self.ln_lambda)\n",
        "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
        "\n",
        "    def _made_params(self):\n",
        "        try:\n",
        "            w = getattr(self.module, self.name + \"_bar\")\n",
        "            return True\n",
        "        except AttributeError:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def _make_params(self):\n",
        "        w = getattr(self.module, self.name)\n",
        "        w_bar = Parameter(w.data)\n",
        "        del self.module._parameters[self.name]\n",
        "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
        "\n",
        "\n",
        "    def forward(self, *args):\n",
        "        self._update_u_v()\n",
        "        return self.module.forward(*args)\n",
        "\n",
        "def conv(in_f, out_f, kernel_size=3, ln_lambda=2, stride=1, bias=True, pad='zero'):\n",
        "    downsampler = None\n",
        "    padder = None\n",
        "    to_pad = int((kernel_size - 1) / 2)\n",
        "    if pad == 'reflection':\n",
        "        padder = nn.ReflectionPad2d(to_pad)\n",
        "        to_pad = 0\n",
        "\n",
        "    convolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=bias)\n",
        "    nn.init.kaiming_uniform_(convolver.weight, a=0, mode='fan_in')\n",
        "    if ln_lambda>0:\n",
        "        convolver = SpectralNorm(convolver, ln_lambda)\n",
        "\n",
        "    layers = filter(lambda x: x is not None, [padder, convolver, downsampler])\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def get_kernel(kernel_width=5, sigma=0.5):\n",
        "\n",
        "    kernel = np.zeros([kernel_width, kernel_width])\n",
        "    center = (kernel_width + 1.)/2.\n",
        "    sigma_sq =  sigma * sigma\n",
        "\n",
        "    for i in range(1, kernel.shape[0] + 1):\n",
        "        for j in range(1, kernel.shape[1] + 1):\n",
        "            di = (i - center)/2.\n",
        "            dj = (j - center)/2.\n",
        "            kernel[i - 1][j - 1] = np.exp(-(di * di + dj * dj)/(2 * sigma_sq))\n",
        "            kernel[i - 1][j - 1] = kernel[i - 1][j - 1]/(2. * np.pi * sigma_sq)\n",
        "\n",
        "    kernel /= kernel.sum()\n",
        "\n",
        "    return kernel\n",
        "\n",
        "class gaussian(nn.Module):\n",
        "    def __init__(self, n_planes,  kernel_width=5, sigma=0.5):\n",
        "        super(gaussian, self).__init__()\n",
        "        self.n_planes = n_planes\n",
        "        self.kernel = get_kernel(kernel_width=kernel_width,sigma=sigma)\n",
        "\n",
        "        convolver = nn.ConvTranspose2d(n_planes, n_planes, kernel_size=5, stride=2, padding=2, output_padding=1, groups=n_planes)\n",
        "        convolver.weight.data[:] = 0\n",
        "        convolver.bias.data[:] = 0\n",
        "        convolver.weight.requires_grad = False\n",
        "        convolver.bias.requires_grad = False\n",
        "\n",
        "        kernel_torch = torch.from_numpy(self.kernel)\n",
        "        for i in range(n_planes):\n",
        "            convolver.weight.data[i, 0] = kernel_torch\n",
        "\n",
        "        self.upsampler_ = convolver\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.upsampler_(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "U8QSzZjDAtYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class decoder(nn.Module):\n",
        "    '''\n",
        "        upsample_mode in ['deconv', 'nearest', 'bilinear', 'gaussian']\n",
        "        pad in ['zero', 'replication', 'none']\n",
        "    '''\n",
        "    def __init__(self, num_input_channels=3, num_output_channels=3, ln_lambda=2,\n",
        "                       upsample_mode='gaussian', pad='zero', need_sigmoid=True, need_bias=True):\n",
        "        super(decoder, self).__init__()\n",
        "\n",
        "\n",
        "        filters = [128, 128, 128, 128, 128]\n",
        "        sigmas = [0.1,0.1,0.1,0.5,0.5]\n",
        "\n",
        "        layers = []\n",
        "        layers.append(unetConv2(num_input_channels, filters[0], ln_lambda, need_bias, pad))\n",
        "        for i in range(len(filters)):\n",
        "            layers.append(unetUp(filters[i], upsample_mode, ln_lambda, need_bias, pad, sigmas[i]))\n",
        "\n",
        "        layers.append(conv(filters[-1], num_output_channels, 1, 0, bias=need_bias, pad=pad))\n",
        "        if need_sigmoid:\n",
        "            layers.append(nn.Sigmoid())\n",
        "\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class unetConv2(nn.Module):\n",
        "    def __init__(self, in_size, out_size, ln_lambda, need_bias, pad):\n",
        "        super(unetConv2, self).__init__()\n",
        "\n",
        "        self.conv1= nn.Sequential(conv(in_size, out_size, 3, ln_lambda, bias=need_bias, pad=pad),\n",
        "                                   bn(out_size),\n",
        "                                   nn.LeakyReLU(),)\n",
        "        self.conv2= nn.Sequential(conv(out_size, out_size, 3, ln_lambda, bias=need_bias, pad=pad),\n",
        "                                   bn(out_size),\n",
        "                                   nn.LeakyReLU(),)\n",
        "    def forward(self, x):\n",
        "        x= self.conv1(x)\n",
        "        x= self.conv2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class unetUp(nn.Module):\n",
        "    def __init__(self, out_size, upsample_mode, ln_lambda, need_bias, pad, sigma=None):\n",
        "        super(unetUp, self).__init__()\n",
        "\n",
        "        num_filt = out_size\n",
        "        if upsample_mode == 'deconv':\n",
        "            self.up= nn.ConvTranspose2d(num_filt, out_size, 4, stride=2, padding=1)\n",
        "            self.conv= conv(out_size, out_size, 3, ln_lambda, bias=need_bias, pad=pad)\n",
        "        elif upsample_mode=='bilinear' or upsample_mode=='nearest':\n",
        "            self.up = nn.Upsample(scale_factor=2, mode=upsample_mode)\n",
        "            self.conv= unetConv2(out_size, out_size, ln_lambda, need_bias, pad)\n",
        "        elif upsample_mode == 'gaussian':\n",
        "            self.up = gaussian(out_size, kernel_width=5, sigma=sigma)\n",
        "            self.conv= unetConv2(out_size, out_size,ln_lambda, need_bias, pad)\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "    def forward(self, x):\n",
        "        x= self.up(x)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "cH4k_zQ9AwCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save2img(d_img, fn):\n",
        "    d_img = np.clip(d_img.transpose(1, 2, 0),0,1)\n",
        "    img = d_img*255.0\n",
        "    img = img.astype('uint8')\n",
        "    imageio.imwrite(fn, img)\n",
        "\n",
        "def save2enhanceimg(ori_img, out_img, fn):\n",
        "    ori_img = np.clip(ori_img.transpose(1, 2, 0),0,1)\n",
        "    out_img = np.clip(out_img.transpose(1, 2, 0),0,1)\n",
        "\n",
        "    edge_img = np.clip((ori_img-out_img),0,1)\n",
        "    en_img = np.clip(edge_img+ori_img,0,1)\n",
        "\n",
        "    ori_img = ori_img*255.0\n",
        "    ori_img = ori_img.astype('uint8')\n",
        "    out_img = out_img*255.0\n",
        "    out_img = out_img.astype('uint8')\n",
        "\n",
        "    en_img = en_img*255.0\n",
        "    en_img = en_img.astype('uint8')\n",
        "\n",
        "    imageio.imwrite(fn, en_img)\n",
        "\n",
        "def rgb2gray(rgb):\n",
        "\n",
        "    r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "\n",
        "    return np.clip(gray,0,1)\n",
        "\n",
        "def crop_image(img, d=32):\n",
        "    '''Make dimensions divisible by `d`'''\n",
        "\n",
        "    new_size = (img.size[0] - img.size[0] % d,\n",
        "                img.size[1] - img.size[1] % d)\n",
        "\n",
        "    bbox = [\n",
        "            int((img.size[0] - new_size[0])/2),\n",
        "            int((img.size[1] - new_size[1])/2),\n",
        "            int((img.size[0] + new_size[0])/2),\n",
        "            int((img.size[1] + new_size[1])/2),\n",
        "    ]\n",
        "\n",
        "    img_cropped = img.crop(bbox)\n",
        "    return img_cropped\n",
        "\n",
        "def get_params(opt_over, net, net_input, downsampler=None):\n",
        "    '''Returns parameters that we want to optimize over.\n",
        "\n",
        "    Args:\n",
        "        opt_over: comma separated list, e.g. \"net,input\" or \"net\"\n",
        "        net: network\n",
        "        net_input: torch.Tensor that stores input `z`\n",
        "    '''\n",
        "    opt_over_list = opt_over.split(',')\n",
        "    params = []\n",
        "\n",
        "    for opt in opt_over_list:\n",
        "\n",
        "        if opt == 'net':\n",
        "            params += [x for x in net.parameters() ]\n",
        "        elif  opt=='down':\n",
        "            assert downsampler is not None\n",
        "            params = [x for x in downsampler.parameters()]\n",
        "        elif opt == 'input':\n",
        "            net_input.requires_grad = True\n",
        "            params += [net_input]\n",
        "        else:\n",
        "            assert False, 'what is it?'\n",
        "\n",
        "    return params\n",
        "\n",
        "def get_image_grid(images_np, nrow=8):\n",
        "    '''Creates a grid from a list of images by concatenating them.'''\n",
        "    images_torch = [torch.from_numpy(x) for x in images_np]\n",
        "    torch_grid = torchvision.utils.make_grid(images_torch, nrow)\n",
        "\n",
        "    return torch_grid.numpy()\n",
        "\n",
        "def plot_image_grid(images_np, nrow =8, factor=1, interpolation='lanczos'):\n",
        "    \"\"\"Draws images in a grid\n",
        "\n",
        "    Args:\n",
        "        images_np: list of images, each image is np.array of size 3xHxW of 1xHxW\n",
        "        nrow: how many images will be in one row\n",
        "        factor: size if the plt.figure\n",
        "        interpolation: interpolation used in plt.imshow\n",
        "    \"\"\"\n",
        "    n_channels = max(x.shape[0] for x in images_np)\n",
        "    assert (n_channels == 3) or (n_channels == 1), \"images should have 1 or 3 channels\"\n",
        "\n",
        "    images_np = [x if (x.shape[0] == n_channels) else np.concatenate([x, x, x], axis=0) for x in images_np]\n",
        "\n",
        "    grid = get_image_grid(images_np, nrow)\n",
        "\n",
        "    plt.figure(figsize=(len(images_np) + factor, 12 + factor))\n",
        "\n",
        "    if images_np[0].shape[0] == 1:\n",
        "        plt.imshow(grid[0], cmap='gray', interpolation=interpolation)\n",
        "    else:\n",
        "        plt.imshow(grid.transpose(1, 2, 0), interpolation=interpolation)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return grid\n",
        "\n",
        "def load(path):\n",
        "    \"\"\"Load PIL image.\"\"\"\n",
        "    img = Image.open(path)\n",
        "    return img\n",
        "\n",
        "def get_image(path, imsize=-1):\n",
        "    \"\"\"Load an image and resize to a cpecific size.\n",
        "\n",
        "    Args:\n",
        "        path: path to image\n",
        "        imsize: tuple or scalar with dimensions; -1 for `no resize`\n",
        "    \"\"\"\n",
        "    img = load(path)\n",
        "\n",
        "    if isinstance(imsize, int):\n",
        "        imsize = (imsize, imsize)\n",
        "\n",
        "    if imsize[0]!= -1 and img.size != imsize:\n",
        "        if imsize[0] > img.size[0]:\n",
        "            img = img.resize(imsize, Image.BICUBIC)\n",
        "        else:\n",
        "            img = img.resize(imsize, Image.ANTIALIAS)\n",
        "\n",
        "    img_np = pil_to_np(img)\n",
        "\n",
        "    return img, img_np\n",
        "\n",
        "\n",
        "\n",
        "def fill_noise(x, noise_type):\n",
        "    \"\"\"Fills tensor `x` with noise of type `noise_type`.\"\"\"\n",
        "    if noise_type == 'u':\n",
        "        x.uniform_()\n",
        "    elif noise_type == 'n':\n",
        "        x.normal_()\n",
        "    else:\n",
        "        assert False\n",
        "\n",
        "def get_noise(input_depth, method, spatial_size, noise_type='u', var=1./10):\n",
        "    \"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`)\n",
        "    initialized in a specific way.\n",
        "    Args:\n",
        "        input_depth: number of channels in the tensor\n",
        "        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n",
        "        spatial_size: spatial size of the tensor to initialize\n",
        "        noise_type: 'u' for uniform; 'n' for normal\n",
        "        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler.\n",
        "    \"\"\"\n",
        "    if isinstance(spatial_size, int):\n",
        "        spatial_size = (spatial_size, spatial_size)\n",
        "    if method == 'noise':\n",
        "        shape = [1, input_depth, spatial_size[0], spatial_size[1]]\n",
        "        net_input = torch.zeros(shape)\n",
        "\n",
        "        fill_noise(net_input, noise_type)\n",
        "        net_input *= var\n",
        "    elif method == 'fourier':\n",
        "        shape = [1, input_depth//2, spatial_size[0], spatial_size[1]]\n",
        "        net_input = torch.zeros(shape)\n",
        "\n",
        "        fill_noise(net_input, noise_type)\n",
        "        net_input *= var\n",
        "\n",
        "        net_input = torch.cat([torch.sin(2.*np.pi*net_input), torch.cos(2.*np.pi*net_input)], 1)\n",
        "\n",
        "    elif method == 'meshgrid':\n",
        "        assert input_depth == 2\n",
        "        X, Y = np.meshgrid(np.arange(0, spatial_size[1])/float(spatial_size[1]-1), np.arange(0, spatial_size[0])/float(spatial_size[0]-1))\n",
        "        meshgrid = np.concatenate([X[None,:], Y[None,:]])\n",
        "        net_input=  np_to_torch(meshgrid)\n",
        "    else:\n",
        "        assert False\n",
        "\n",
        "    return net_input\n",
        "\n",
        "def pil_to_np(img_PIL):\n",
        "    '''Converts image in PIL format to np.array.\n",
        "\n",
        "    From W x H x C [0...255] to C x W x H [0..1]\n",
        "    '''\n",
        "    ar = np.array(img_PIL)\n",
        "\n",
        "    if len(ar.shape) == 3:\n",
        "        ar = ar.transpose(2,0,1)\n",
        "    else:\n",
        "        ar = ar[None, ...]\n",
        "\n",
        "    return ar.astype(np.float32) / 255.\n",
        "\n",
        "def np_to_pil(img_np):\n",
        "    '''Converts image in np.array format to PIL image.\n",
        "\n",
        "    From C x W x H [0..1] to  W x H x C [0...255]\n",
        "    '''\n",
        "    ar = np.clip(img_np*255,0,255).astype(np.uint8)\n",
        "\n",
        "    if img_np.shape[0] == 1:\n",
        "        ar = ar[0]\n",
        "    else:\n",
        "        ar = ar.transpose(1, 2, 0)\n",
        "\n",
        "    return Image.fromarray(ar)\n",
        "\n",
        "def np_to_torch(img_np):\n",
        "    '''Converts image in numpy.array to torch.Tensor.\n",
        "\n",
        "    From C x W x H [0..1] to  C x W x H [0..1]\n",
        "    '''\n",
        "    return torch.from_numpy(img_np)[None, :]\n",
        "\n",
        "def torch_to_np(img_var):\n",
        "    '''Converts an image in torch.Tensor format to np.array.\n",
        "\n",
        "    From 1 x C x W x H [0..1] to  C x W x H [0..1]\n",
        "    '''\n",
        "    return img_var.detach().cpu().numpy()[0]\n",
        "\n",
        "\n",
        "def optimize(optimizer_type, parameters, closure, LR, num_iter):\n",
        "    \"\"\"Runs optimization loop.\n",
        "\n",
        "    Args:\n",
        "        optimizer_type: 'LBFGS' of 'adam'\n",
        "        parameters: list of Tensors to optimize over\n",
        "        closure: function, that returns loss variable\n",
        "        LR: learning rate\n",
        "        num_iter: number of iterations\n",
        "    \"\"\"\n",
        "    if optimizer_type == 'LBFGS':\n",
        "        # Do several steps with adam first\n",
        "        optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
        "        for j in range(100):\n",
        "            optimizer.zero_grad()\n",
        "            closure()\n",
        "            optimizer.step()\n",
        "\n",
        "        print('Starting optimization with LBFGS')\n",
        "        def closure2():\n",
        "            optimizer.zero_grad()\n",
        "            return closure()\n",
        "        optimizer = torch.optim.LBFGS(parameters, max_iter=num_iter, lr=LR, tolerance_grad=-1, tolerance_change=-1)\n",
        "        optimizer.step(closure2)\n",
        "\n",
        "    elif optimizer_type == 'adam':\n",
        "        print('Starting optimization with ADAM')\n",
        "        optimizer = torch.optim.Adam(parameters, lr=LR)\n",
        "\n",
        "        for j in range(num_iter):\n",
        "            optimizer.zero_grad()\n",
        "            closure()\n",
        "            optimizer.step()\n",
        "    else:\n",
        "        assert False\n",
        "\n",
        "def get_noisy_image(img_np, sigma):\n",
        "    \"\"\"Adds Gaussian noise to an image.\n",
        "\n",
        "    Args:\n",
        "        img_np: image, np.array with values from 0 to 1\n",
        "        sigma: std of the noise\n",
        "    \"\"\"\n",
        "    img_noisy_np = np.clip(img_np + np.random.normal(scale=sigma, size=img_np.shape), 0, 1).astype(np.float32)\n",
        "    img_noisy_pil = np_to_pil(img_noisy_np)\n",
        "\n",
        "    return img_noisy_pil, img_noisy_np"
      ],
      "metadata": {
        "id": "B8W0qMYcBo14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_circular_statastic(img_it, img_gt, size=0.2):\n",
        "\n",
        "    if len(img_it.shape)==3:\n",
        "        img_it = rgb2gray(img_it)\n",
        "\n",
        "    if len(img_gt.shape)==3:\n",
        "        img_gt = rgb2gray(img_gt)\n",
        "\n",
        "    assert(size>0 and size<1)\n",
        "\n",
        "    ftimage_it = np.fft.fft2(img_it)\n",
        "    ftimage_it = abs(np.fft.fftshift(ftimage_it))\n",
        "\n",
        "    ftimage_gt = np.fft.fft2(img_gt)\n",
        "    ftimage_gt = abs(np.fft.fftshift(ftimage_gt))\n",
        "\n",
        "    m_data = ftimage_it/(ftimage_gt+1e-8)\n",
        "    m_data = np.clip(m_data, 0, 1)\n",
        "\n",
        "    h,w = m_data.shape\n",
        "\n",
        "    center = (int(w/2), int(h/2))\n",
        "    Y, X = np.ogrid[:h, :w]\n",
        "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
        "\n",
        "    avg_mask_list = []\n",
        "    pre_mask = np.zeros((h,w))\n",
        "    for sz in np.linspace(size, 1, int(1/size)):\n",
        "\n",
        "        radius = center[0]*sz#pow(center[0]**2+center[1]**2,0.5)\n",
        "        mask = dist_from_center <= radius\n",
        "        mask = mask.astype(np.int32)\n",
        "\n",
        "        mask_sz = (mask-pre_mask).astype(np.int32)\n",
        "        pre_mask = mask\n",
        "\n",
        "        avg_mask_list.append(np.sum(mask_sz*m_data)/np.sum(mask_sz))\n",
        "\n",
        "    return avg_mask_list\n",
        "\n",
        "def PerceptualBlurMetric (Image, FiltSize=9):\n",
        "\n",
        "    if len(Image.shape)==3:\n",
        "        Image = rgb2gray(Image)\n",
        "\n",
        "    m, n = Image.shape[0],Image.shape[1]\n",
        "\n",
        "    Hv = 1.0/FiltSize*np.ones((1,FiltSize))\n",
        "    Hh = Hv.T\n",
        "    Bver = conv2(Image, Hv, 'same')\n",
        "    Bhor = conv2(Image, Hh, 'same')\n",
        "\n",
        "    s_ind = int(np.ceil(FiltSize/2))\n",
        "    e_ind = int(np.floor(FiltSize/2))\n",
        "    Bver = Bver[s_ind:m-e_ind, s_ind:n-e_ind]\n",
        "    Bhor = Bhor[s_ind:m-e_ind, s_ind:n-e_ind]\n",
        "    Image = Image[s_ind:m-e_ind, s_ind:n-e_ind]\n",
        "    m, n = Image.shape[0],Image.shape[1]\n",
        "\n",
        "    Hv = np.asarray([[1, -1]])\n",
        "    Hh = Hv.T\n",
        "    D_Fver = abs(conv2(Image, Hv, 'same'))\n",
        "    D_Fhor = abs(conv2(Image, Hh, 'same'))\n",
        "    D_Fver = D_Fver[1:m-1, 1:n-1]\n",
        "    D_Fhor = D_Fhor[1:m-1, 1:n-1]\n",
        "\n",
        "    D_Bver = abs(conv2(Bver, Hv, 'same'))\n",
        "    D_Bhor = abs(conv2(Bhor, Hh, 'same'))\n",
        "    D_Bver = D_Bver[1:m-1, 1:n-1]\n",
        "    D_Bhor = D_Bhor[1:m-1, 1:n-1]\n",
        "\n",
        "\n",
        "    D_Vver = D_Fver-D_Bver\n",
        "    D_Vver[D_Vver<0] = 0\n",
        "    D_Vhor = D_Fhor-D_Bhor\n",
        "    D_Vhor[D_Vhor<0] = 0\n",
        "\n",
        "    s_Fver = np.sum(D_Fver)\n",
        "    s_Fhor = np.sum(D_Fhor)\n",
        "    s_Vver = np.sum(D_Vver)\n",
        "    s_Vhor = np.sum(D_Vhor)\n",
        "\n",
        "    b_Fver = (s_Fver - s_Vver)/s_Fver\n",
        "    b_Fhor = (s_Fhor - s_Vhor)/s_Fhor\n",
        "\n",
        "    IDM = max(b_Fver, b_Fhor)\n",
        "\n",
        "    return IDM\n",
        "\n",
        "def MLVMap(im):\n",
        "\n",
        "    if len(im.shape)==3:\n",
        "        im = rgb2gray(im)\n",
        "\n",
        "    xs, ys = im.shape\n",
        "    x=im\n",
        "\n",
        "    x1=np.zeros((xs,ys))\n",
        "    x2=np.zeros((xs,ys))\n",
        "    x3=np.zeros((xs,ys))\n",
        "    x4=np.zeros((xs,ys))\n",
        "    x5=np.zeros((xs,ys))\n",
        "    x6=np.zeros((xs,ys))\n",
        "    x7=np.zeros((xs,ys))\n",
        "    x8=np.zeros((xs,ys))\n",
        "    x9=np.zeros((xs,ys))\n",
        "\n",
        "    x1[1:xs-2,1:ys-2] = x[2:xs-1,2:ys-1]\n",
        "    x2[1:xs-2,2:ys-1] = x[2:xs-1,2:ys-1]\n",
        "    x3[1:xs-2,3:ys]   = x[2:xs-1,2:ys-1]\n",
        "    x4[2:xs-1,1:ys-2] = x[2:xs-1,2:ys-1]\n",
        "    x5[2:xs-1,2:ys-1] = x[2:xs-1,2:ys-1]\n",
        "    x6[2:xs-1,3:ys]   = x[2:xs-1,2:ys-1]\n",
        "    x7[3:xs,1:ys-2]   = x[2:xs-1,2:ys-1]\n",
        "    x8[3:xs,2:ys-1]   = x[2:xs-1,2:ys-1]\n",
        "    x9[3:xs,3:ys]     = x[2:xs-1,2:ys-1]\n",
        "\n",
        "    x1=x1[2:xs-1,2:ys-1]\n",
        "    x2=x2[2:xs-1,2:ys-1]\n",
        "    x3=x3[2:xs-1,2:ys-1]\n",
        "    x4=x4[2:xs-1,2:ys-1]\n",
        "    x5=x5[2:xs-1,2:ys-1]\n",
        "    x6=x6[2:xs-1,2:ys-1]\n",
        "    x7=x7[2:xs-1,2:ys-1]\n",
        "    x8=x8[2:xs-1,2:ys-1]\n",
        "    x9=x9[2:xs-1,2:ys-1]\n",
        "\n",
        "    d1=x1-x5\n",
        "    d2=x2-x5\n",
        "    d3=x3-x5\n",
        "    d4=x4-x5\n",
        "    d5=x6-x5\n",
        "    d6=x7-x5\n",
        "    d7=x8-x5\n",
        "    d8=x9-x5\n",
        "\n",
        "    dd=np.maximum(d1,d2)\n",
        "    dd=np.maximum(dd,d3)\n",
        "    dd=np.maximum(dd,d4)\n",
        "    dd=np.maximum(dd,d5)\n",
        "    dd=np.maximum(dd,d6)\n",
        "    dd=np.maximum(dd,d7)\n",
        "    dd=np.maximum(dd,d8)\n",
        "\n",
        "    return dd\n",
        "\n",
        "def MLVSharpnessMeasure(im):\n",
        "    T=1000;\n",
        "    alpha=-0.01\n",
        "\n",
        "    im_map = MLVMap(im)\n",
        "    xs, ys = im_map.shape\n",
        "\n",
        "    xy_number=xs*ys\n",
        "    l_number=int(xy_number)\n",
        "    vec = np.reshape(im_map,(xy_number))\n",
        "    vec=sorted(vec.tolist(),reverse = True)\n",
        "    svec=np.array(vec[1:l_number])\n",
        "\n",
        "    a=range(1,xy_number)\n",
        "    q=np.exp(np.dot(alpha,a))\n",
        "    svec=svec*q\n",
        "    svec=svec[1:T]\n",
        "    sigma = np.sqrt(np.mean(np.power(svec,2)))\n",
        "\n",
        "    return sigma"
      ],
      "metadata": {
        "id": "w0m5-zvXBr9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "def get_log_data(file_name):\n",
        "    file1 = open(file_name, 'r')\n",
        "    Lines = file1.readlines()\n",
        "    file1.close()\n",
        "\n",
        "    frequency_lists=[]\n",
        "    psnr_list=[]\n",
        "    ratio_list=[]\n",
        "\n",
        "    for line in Lines:\n",
        "        strings = re.split(':|,', line.strip())\n",
        "        #print (strings)\n",
        "        fre_list = []\n",
        "        fre_list.append(float(strings[-7][2:]))\n",
        "        fre_list.append(float(strings[-6]))\n",
        "        fre_list.append(float(strings[-5]))\n",
        "        fre_list.append(float(strings[-4]))\n",
        "        fre_list.append(float(strings[-3][:-1]))\n",
        "        frequency_lists.append(np.array(fre_list))\n",
        "\n",
        "        psnr_list.append(float(strings[5]))\n",
        "        ratio_list.append(float(strings[-1]))\n",
        "\n",
        "\n",
        "    return frequency_lists, np.array(psnr_list), np.array(ratio_list)\n",
        "\n",
        "def get_fbc_fig(all_norms,num_iter,ylim=1,save_path='',img_name=''):\n",
        "    fig, ax = plt.subplots(figsize=(7,6))\n",
        "    ax.set_xlim(0,num_iter)\n",
        "    ax.set_ylim(0, ylim)\n",
        "\n",
        "    norms=np.array(all_norms)\n",
        "\n",
        "    label_list = ['Frequency band (1,lowest)','Frequency band (2)','Frequency band (3)','Frequency band (4)','Frequency band (5, highest)']\n",
        "\n",
        "    plt.xlabel(\"Optimization Iteration\")\n",
        "    plt.ylabel(\"FBC ($\\\\bar{H}$)\")\n",
        "    #plt.title('FBC (%s)'%img_name)\n",
        "\n",
        "    color_list = ['#331900', '#994C00', '#CC6600',  '#FF8000', '#FF9933']\n",
        "    rate = 1\n",
        "    for i in range(norms.shape[1]):\n",
        "        plt.plot(range(0,num_iter,rate), norms[:num_iter:rate,i], linewidth=4, color=color_list[i], label=label_list[i])\n",
        "\n",
        "    plt.legend(loc=4,)\n",
        "    plt.grid()\n",
        "    plt.savefig(save_path)\n",
        "    #plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def get_psnr_ratio_fig(all_datas,num_iter,ylim=35, ylabel='',save_path='',img_name=''):\n",
        "    fig, ax = plt.subplots(figsize=(7,6))\n",
        "    ax.set_xlim(0,num_iter)\n",
        "    ax.set_ylim(0, ylim)\n",
        "\n",
        "    plt.xlabel(\"Optimization Iteration\")\n",
        "    #plt.ylabel(ylabel)\n",
        "    #plt.title(img_name)\n",
        "\n",
        "    label_list = ['PSNR','Ratio']\n",
        "    color_list = ['#d94a31','#4b43db']\n",
        "\n",
        "    rate = 1\n",
        "    for i in range(len(all_datas)):\n",
        "        plt.plot(range(0,num_iter,rate), all_datas[i][0:num_iter:rate], linewidth=4, color=color_list[i], label=label_list[i])\n",
        "\n",
        "    plt.legend(loc=0,)\n",
        "    plt.grid()\n",
        "    plt.savefig(save_path)\n",
        "    #plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "_4sDZZydBt7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#boat,barbara,Cameraman256,couple,fingerprint,hill\n",
        "#house,Lena512,man,montage,peppers256\n",
        "img_name = 'boat'\n",
        "fname = '/content/data/{}.png'.format(img_name)\n",
        "h5py_fname = '/content/data/{}.h5'.format(img_name)\n",
        "\n",
        "\n",
        "if not os.path.exists('./figs'):\n",
        "        os.mkdir('./figs')\n",
        "\n",
        "if not os.path.exists('./logs'):\n",
        "        os.mkdir('./logs')\n",
        "\n",
        "log_path = \"./logs/%s.txt\"%img_name\n",
        "log_file = open(log_path, \"w\")\n",
        "\n",
        "#read image\n",
        "img_pil, img_np = get_image(fname, -1)\n",
        "#np.random.seed(10000)\n",
        "#img_mask_np = (np.random.random_sample(size=img_np.shape) > 0.5).astype(int)\n",
        "with h5py.File(h5py_fname, 'r') as hf:\n",
        "    img_mask_np = hf['mask'][()]\n",
        "img_mask_pil = np_to_pil(img_mask_np)\n",
        "\n",
        "img_mask_pil = crop_image(img_mask_pil, 32)\n",
        "img_pil      = crop_image(img_pil,      32)\n",
        "img_np      = pil_to_np(img_pil)\n",
        "img_mask_np = pil_to_np(img_mask_pil)\n",
        "\n",
        "#input type\n",
        "INPUT = 'fourier' # 'meshgrid', 'noise', 'fourier'\n",
        "var=1\n",
        "input_depth = 32\n",
        "net_input = get_noise(input_depth, INPUT, (img_pil.size[1]//32, img_pil.size[0]//32),var=var).type(dtype).detach()\n",
        "\n",
        "#network parameters\n",
        "ln_lambda=1.6#the lambda in Lipschitz normalization, which is used to control spectral bias\n",
        "upsample_mode='bilinear'#['deconv', 'nearest', 'bilinear', 'gaussian'], where 'gaussian' denotes our Gaussian upsampling.\n",
        "pad = 'reflection'\n",
        "#decoder is the used network architecture in the paper\n",
        "net = decoder(num_input_channels=input_depth, num_output_channels=1, ln_lambda=ln_lambda,\n",
        "                   upsample_mode=upsample_mode, pad=pad, need_sigmoid=True, need_bias=True).type(dtype)\n",
        "\n",
        "#optimization parameters\n",
        "OPTIMIZER='adam'\n",
        "num_iter = 4000\n",
        "LR = 0.001\n",
        "reg_noise_std = 0#1./30, injecting noise in the input.\n",
        "show_every = 100\n",
        "\n",
        "#automatic stopping\n",
        "ratio_list = np.zeros((num_iter))\n",
        "ratio_iter=100#the n in Eq. (8)\n",
        "ratio_epsilon=0.01#the ratio difference threshold\n",
        "auto_stop = False\n",
        "\n",
        "# Loss\n",
        "mse = torch.nn.MSELoss().type(dtype)\n",
        "img_var = np_to_torch(img_np).type(dtype)\n",
        "mask_var = np_to_torch(img_mask_np).type(dtype)\n",
        "\n",
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "\n",
        "i = 0\n",
        "def closure():\n",
        "\n",
        "    global i, out, net_input\n",
        "\n",
        "    if reg_noise_std > 0:\n",
        "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "\n",
        "    out = net(net_input)\n",
        "\n",
        "    total_loss = mse(out * mask_var, img_var * mask_var)\n",
        "    total_loss.backward()\n",
        "\n",
        "    psrn_gt = compare_psnr(img_np, out.detach().cpu().numpy()[0])\n",
        "\n",
        "    pre_img = out.detach().cpu().numpy()[0]\n",
        "    pre_img = pre_img.transpose(1, 2, 0)\n",
        "\n",
        "    img_noisy_np = img_np*img_mask_np\n",
        "    noisy_img = img_noisy_np.transpose(1, 2, 0)\n",
        "\n",
        "    #frequency-band correspondence metric\n",
        "    avg_mask_it = get_circular_statastic(pre_img[:,:,0], noisy_img[:,:,0],  size=0.2)\n",
        "\n",
        "    #automatic stopping\n",
        "    blur_it = PerceptualBlurMetric (pre_img[:,:,0])#the blurriness of the output image\n",
        "    sharp_it = MLVSharpnessMeasure(pre_img[:,:,0])#the sharpness of the output image\n",
        "    ratio_it = blur_it/sharp_it#the ratio\n",
        "\n",
        "    if auto_stop:\n",
        "        ratio_list[i] = ratio_it\n",
        "        if i>ratio_iter*2:\n",
        "            ratio1 = np.mean(ratio_list[i-ratio_iter*2:i-ratio_iter])\n",
        "            ratio2 = np.mean(ratio_list[i-ratio_iter+1:i])\n",
        "            if np.abs(ratio1-ratio2)<ratio_epsilon:\n",
        "                print(\"The optimization is automatically stopped!\")\n",
        "                out_np = torch_to_np(out)\n",
        "                save2img(out_np, \"./figs/%s_inpainted.png\" % img_name)\n",
        "                exit()\n",
        "\n",
        "    print ('Iteration: %05d, Loss: %f, PSRN_gt: %f' % (i, total_loss.item(), psrn_gt))\n",
        "    log_file.write('Iteration: %05d, Loss: %f, PSRN_gt: %f, mask: %s, ratio: %f\\n' % (i, total_loss.item(), psrn_gt, avg_mask_it, ratio_it))\n",
        "    log_file.flush()\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "optimize(OPTIMIZER, net.parameters(), closure, LR, num_iter)\n",
        "log_file.close()\n",
        "\n",
        "#visualization\n",
        "\n",
        "out_np = torch_to_np(out)\n",
        "save2img(out_np, \"./figs/%s_inpainted.png\" % img_name)#save the denoised image\n",
        "\n",
        "frequency_lists, psnr_list, ratio_list = get_log_data(log_path)\n",
        "get_fbc_fig(frequency_lists,num_iter,ylim=1,save_path=\"./figs/%s_fbc.png\"%img_name)#save the fbc figure\n",
        "\n",
        "data_lists =[]\n",
        "data_lists.append(psnr_list)\n",
        "data_lists.append(ratio_list)\n",
        "get_psnr_ratio_fig(data_lists,num_iter,ylim=35, ylabel='PSNR', save_path=\"./figs/%s_psnr_ratio.png\"%img_name)#save the psnr_ratio figure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B-zpK2_IAlhG",
        "outputId": "000f5f10-358b-4a2c-db90-ef2a28d5345a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimization with ADAM\n",
            "Iteration: 00000, Loss: 0.017116, PSRN_gt: 14.660783\n",
            "Iteration: 00001, Loss: 0.015921, PSRN_gt: 14.973128\n",
            "Iteration: 00002, Loss: 0.009531, PSRN_gt: 17.187246\n",
            "Iteration: 00003, Loss: 0.014354, PSRN_gt: 15.440063\n",
            "Iteration: 00004, Loss: 0.009378, PSRN_gt: 17.274614\n",
            "Iteration: 00005, Loss: 0.010682, PSRN_gt: 16.700172\n",
            "Iteration: 00006, Loss: 0.009454, PSRN_gt: 17.223781\n",
            "Iteration: 00007, Loss: 0.007399, PSRN_gt: 18.285815\n",
            "Iteration: 00008, Loss: 0.006522, PSRN_gt: 18.841015\n",
            "Iteration: 00009, Loss: 0.006546, PSRN_gt: 18.832986\n",
            "Iteration: 00010, Loss: 0.005859, PSRN_gt: 19.312805\n",
            "Iteration: 00011, Loss: 0.005492, PSRN_gt: 19.592278\n",
            "Iteration: 00012, Loss: 0.005429, PSRN_gt: 19.644470\n",
            "Iteration: 00013, Loss: 0.005109, PSRN_gt: 19.911804\n",
            "Iteration: 00014, Loss: 0.004788, PSRN_gt: 20.195771\n",
            "Iteration: 00015, Loss: 0.004540, PSRN_gt: 20.427324\n",
            "Iteration: 00016, Loss: 0.004323, PSRN_gt: 20.640524\n",
            "Iteration: 00017, Loss: 0.004197, PSRN_gt: 20.766737\n",
            "Iteration: 00018, Loss: 0.004130, PSRN_gt: 20.833485\n",
            "Iteration: 00019, Loss: 0.003971, PSRN_gt: 21.007733\n",
            "Iteration: 00020, Loss: 0.003822, PSRN_gt: 21.179170\n",
            "Iteration: 00021, Loss: 0.003748, PSRN_gt: 21.265902\n",
            "Iteration: 00022, Loss: 0.003680, PSRN_gt: 21.341632\n",
            "Iteration: 00023, Loss: 0.003583, PSRN_gt: 21.455218\n",
            "Iteration: 00024, Loss: 0.003477, PSRN_gt: 21.585007\n",
            "Iteration: 00025, Loss: 0.003402, PSRN_gt: 21.677104\n",
            "Iteration: 00026, Loss: 0.003356, PSRN_gt: 21.733876\n",
            "Iteration: 00027, Loss: 0.003287, PSRN_gt: 21.820290\n",
            "Iteration: 00028, Loss: 0.003216, PSRN_gt: 21.909903\n",
            "Iteration: 00029, Loss: 0.003143, PSRN_gt: 22.003621\n",
            "Iteration: 00030, Loss: 0.003096, PSRN_gt: 22.066381\n",
            "Iteration: 00031, Loss: 0.003046, PSRN_gt: 22.136499\n",
            "Iteration: 00032, Loss: 0.003002, PSRN_gt: 22.198826\n",
            "Iteration: 00033, Loss: 0.003038, PSRN_gt: 22.154648\n",
            "Iteration: 00034, Loss: 0.002945, PSRN_gt: 22.277423\n",
            "Iteration: 00035, Loss: 0.002913, PSRN_gt: 22.320363\n",
            "Iteration: 00036, Loss: 0.002849, PSRN_gt: 22.417445\n",
            "Iteration: 00037, Loss: 0.002795, PSRN_gt: 22.500687\n",
            "Iteration: 00038, Loss: 0.002762, PSRN_gt: 22.547713\n",
            "Iteration: 00039, Loss: 0.002715, PSRN_gt: 22.620027\n",
            "Iteration: 00040, Loss: 0.002681, PSRN_gt: 22.670851\n",
            "Iteration: 00041, Loss: 0.002637, PSRN_gt: 22.731366\n",
            "Iteration: 00042, Loss: 0.002609, PSRN_gt: 22.777848\n",
            "Iteration: 00043, Loss: 0.002576, PSRN_gt: 22.829661\n",
            "Iteration: 00044, Loss: 0.002560, PSRN_gt: 22.857261\n",
            "Iteration: 00045, Loss: 0.002537, PSRN_gt: 22.897244\n",
            "Iteration: 00046, Loss: 0.002472, PSRN_gt: 23.000399\n",
            "Iteration: 00047, Loss: 0.002435, PSRN_gt: 23.064865\n",
            "Iteration: 00048, Loss: 0.002429, PSRN_gt: 23.069886\n",
            "Iteration: 00049, Loss: 0.002449, PSRN_gt: 23.044287\n",
            "Iteration: 00050, Loss: 0.002482, PSRN_gt: 22.976910\n",
            "Iteration: 00051, Loss: 0.002465, PSRN_gt: 23.007241\n",
            "Iteration: 00052, Loss: 0.002488, PSRN_gt: 22.969414\n",
            "Iteration: 00053, Loss: 0.002561, PSRN_gt: 22.838351\n",
            "Iteration: 00054, Loss: 0.002524, PSRN_gt: 22.912612\n",
            "Iteration: 00055, Loss: 0.002444, PSRN_gt: 23.053295\n",
            "Iteration: 00056, Loss: 0.002411, PSRN_gt: 23.098348\n",
            "Iteration: 00057, Loss: 0.002336, PSRN_gt: 23.222770\n",
            "Iteration: 00058, Loss: 0.002340, PSRN_gt: 23.231683\n",
            "Iteration: 00059, Loss: 0.002256, PSRN_gt: 23.374750\n",
            "Iteration: 00060, Loss: 0.002258, PSRN_gt: 23.365083\n",
            "Iteration: 00061, Loss: 0.002207, PSRN_gt: 23.467774\n",
            "Iteration: 00062, Loss: 0.002171, PSRN_gt: 23.529775\n",
            "Iteration: 00063, Loss: 0.002143, PSRN_gt: 23.573282\n",
            "Iteration: 00064, Loss: 0.002104, PSRN_gt: 23.652915\n",
            "Iteration: 00065, Loss: 0.002083, PSRN_gt: 23.708544\n",
            "Iteration: 00066, Loss: 0.002054, PSRN_gt: 23.758670\n",
            "Iteration: 00067, Loss: 0.002014, PSRN_gt: 23.842899\n",
            "Iteration: 00068, Loss: 0.001995, PSRN_gt: 23.885296\n",
            "Iteration: 00069, Loss: 0.001984, PSRN_gt: 23.897696\n",
            "Iteration: 00070, Loss: 0.001957, PSRN_gt: 23.969648\n",
            "Iteration: 00071, Loss: 0.001966, PSRN_gt: 23.937082\n",
            "Iteration: 00072, Loss: 0.002097, PSRN_gt: 23.659468\n",
            "Iteration: 00073, Loss: 0.002462, PSRN_gt: 22.998092\n",
            "Iteration: 00074, Loss: 0.002390, PSRN_gt: 23.125824\n",
            "Iteration: 00075, Loss: 0.002042, PSRN_gt: 23.774793\n",
            "Iteration: 00076, Loss: 0.002227, PSRN_gt: 23.429498\n",
            "Iteration: 00077, Loss: 0.002029, PSRN_gt: 23.800994\n",
            "Iteration: 00078, Loss: 0.002067, PSRN_gt: 23.730363\n",
            "Iteration: 00079, Loss: 0.001985, PSRN_gt: 23.908456\n",
            "Iteration: 00080, Loss: 0.001993, PSRN_gt: 23.885022\n",
            "Iteration: 00081, Loss: 0.001925, PSRN_gt: 24.028416\n",
            "Iteration: 00082, Loss: 0.001919, PSRN_gt: 24.034494\n",
            "Iteration: 00083, Loss: 0.001880, PSRN_gt: 24.119090\n",
            "Iteration: 00084, Loss: 0.001862, PSRN_gt: 24.157727\n",
            "Iteration: 00085, Loss: 0.001822, PSRN_gt: 24.254377\n",
            "Iteration: 00086, Loss: 0.001799, PSRN_gt: 24.306460\n",
            "Iteration: 00087, Loss: 0.001787, PSRN_gt: 24.337413\n",
            "Iteration: 00088, Loss: 0.001757, PSRN_gt: 24.395655\n",
            "Iteration: 00089, Loss: 0.001744, PSRN_gt: 24.435179\n",
            "Iteration: 00090, Loss: 0.001722, PSRN_gt: 24.481245\n",
            "Iteration: 00091, Loss: 0.001709, PSRN_gt: 24.509444\n",
            "Iteration: 00092, Loss: 0.001696, PSRN_gt: 24.552337\n",
            "Iteration: 00093, Loss: 0.001690, PSRN_gt: 24.552625\n",
            "Iteration: 00094, Loss: 0.001672, PSRN_gt: 24.601163\n",
            "Iteration: 00095, Loss: 0.001688, PSRN_gt: 24.556142\n",
            "Iteration: 00096, Loss: 0.001825, PSRN_gt: 24.241014\n",
            "Iteration: 00097, Loss: 0.002046, PSRN_gt: 23.746504\n",
            "Iteration: 00098, Loss: 0.001986, PSRN_gt: 23.874723\n",
            "Iteration: 00099, Loss: 0.001703, PSRN_gt: 24.527484\n",
            "Iteration: 00100, Loss: 0.001796, PSRN_gt: 24.300376\n",
            "Iteration: 00101, Loss: 0.001723, PSRN_gt: 24.476362\n",
            "Iteration: 00102, Loss: 0.001678, PSRN_gt: 24.595545\n",
            "Iteration: 00103, Loss: 0.001715, PSRN_gt: 24.499273\n",
            "Iteration: 00104, Loss: 0.001614, PSRN_gt: 24.746782\n",
            "Iteration: 00105, Loss: 0.001661, PSRN_gt: 24.626845\n",
            "Iteration: 00106, Loss: 0.001601, PSRN_gt: 24.783125\n",
            "Iteration: 00107, Loss: 0.001594, PSRN_gt: 24.797806\n",
            "Iteration: 00108, Loss: 0.001570, PSRN_gt: 24.862469\n",
            "Iteration: 00109, Loss: 0.001556, PSRN_gt: 24.892439\n",
            "Iteration: 00110, Loss: 0.001537, PSRN_gt: 24.939699\n",
            "Iteration: 00111, Loss: 0.001519, PSRN_gt: 24.999381\n",
            "Iteration: 00112, Loss: 0.001500, PSRN_gt: 25.046956\n",
            "Iteration: 00113, Loss: 0.001497, PSRN_gt: 25.037772\n",
            "Iteration: 00114, Loss: 0.001479, PSRN_gt: 25.093252\n",
            "Iteration: 00115, Loss: 0.001472, PSRN_gt: 25.127107\n",
            "Iteration: 00116, Loss: 0.001459, PSRN_gt: 25.146713\n",
            "Iteration: 00117, Loss: 0.001451, PSRN_gt: 25.169591\n",
            "Iteration: 00118, Loss: 0.001462, PSRN_gt: 25.158931\n",
            "Iteration: 00119, Loss: 0.001490, PSRN_gt: 25.053760\n",
            "Iteration: 00120, Loss: 0.001533, PSRN_gt: 24.953367\n",
            "Iteration: 00121, Loss: 0.001628, PSRN_gt: 24.699208\n",
            "Iteration: 00122, Loss: 0.001601, PSRN_gt: 24.769596\n",
            "Iteration: 00123, Loss: 0.001467, PSRN_gt: 25.116136\n",
            "Iteration: 00124, Loss: 0.001439, PSRN_gt: 25.203508\n",
            "Iteration: 00125, Loss: 0.001496, PSRN_gt: 25.056935\n",
            "Iteration: 00126, Loss: 0.001473, PSRN_gt: 25.098321\n",
            "Iteration: 00127, Loss: 0.001406, PSRN_gt: 25.302052\n",
            "Iteration: 00128, Loss: 0.001407, PSRN_gt: 25.300079\n",
            "Iteration: 00129, Loss: 0.001417, PSRN_gt: 25.262966\n",
            "Iteration: 00130, Loss: 0.001376, PSRN_gt: 25.391507\n",
            "Iteration: 00131, Loss: 0.001372, PSRN_gt: 25.383551\n",
            "Iteration: 00132, Loss: 0.001373, PSRN_gt: 25.388204\n",
            "Iteration: 00133, Loss: 0.001337, PSRN_gt: 25.511420\n",
            "Iteration: 00134, Loss: 0.001328, PSRN_gt: 25.520626\n",
            "Iteration: 00135, Loss: 0.001341, PSRN_gt: 25.483487\n",
            "Iteration: 00136, Loss: 0.001327, PSRN_gt: 25.531449\n",
            "Iteration: 00137, Loss: 0.001314, PSRN_gt: 25.566143\n",
            "Iteration: 00138, Loss: 0.001338, PSRN_gt: 25.488725\n",
            "Iteration: 00139, Loss: 0.001420, PSRN_gt: 25.245232\n",
            "Iteration: 00140, Loss: 0.001527, PSRN_gt: 24.957892\n",
            "Iteration: 00141, Loss: 0.001574, PSRN_gt: 24.835811\n",
            "Iteration: 00142, Loss: 0.001436, PSRN_gt: 25.196463\n",
            "Iteration: 00143, Loss: 0.001403, PSRN_gt: 25.317544\n",
            "Iteration: 00144, Loss: 0.001492, PSRN_gt: 25.043170\n",
            "Iteration: 00145, Loss: 0.001435, PSRN_gt: 25.201065\n",
            "Iteration: 00146, Loss: 0.001405, PSRN_gt: 25.295977\n",
            "Iteration: 00147, Loss: 0.001399, PSRN_gt: 25.318459\n",
            "Iteration: 00148, Loss: 0.001323, PSRN_gt: 25.533779\n",
            "Iteration: 00149, Loss: 0.001326, PSRN_gt: 25.539007\n",
            "Iteration: 00150, Loss: 0.001317, PSRN_gt: 25.561801\n",
            "Iteration: 00151, Loss: 0.001308, PSRN_gt: 25.570333\n",
            "Iteration: 00152, Loss: 0.001290, PSRN_gt: 25.655546\n",
            "Iteration: 00153, Loss: 0.001270, PSRN_gt: 25.707311\n",
            "Iteration: 00154, Loss: 0.001264, PSRN_gt: 25.705706\n",
            "Iteration: 00155, Loss: 0.001237, PSRN_gt: 25.819536\n",
            "Iteration: 00156, Loss: 0.001238, PSRN_gt: 25.813038\n",
            "Iteration: 00157, Loss: 0.001229, PSRN_gt: 25.823870\n",
            "Iteration: 00158, Loss: 0.001225, PSRN_gt: 25.834834\n",
            "Iteration: 00159, Loss: 0.001229, PSRN_gt: 25.833529\n",
            "Iteration: 00160, Loss: 0.001230, PSRN_gt: 25.815937\n",
            "Iteration: 00161, Loss: 0.001256, PSRN_gt: 25.738152\n",
            "Iteration: 00162, Loss: 0.001302, PSRN_gt: 25.585020\n",
            "Iteration: 00163, Loss: 0.001383, PSRN_gt: 25.339943\n",
            "Iteration: 00164, Loss: 0.001386, PSRN_gt: 25.333807\n",
            "Iteration: 00165, Loss: 0.001282, PSRN_gt: 25.668837\n",
            "Iteration: 00166, Loss: 0.001220, PSRN_gt: 25.837907\n",
            "Iteration: 00167, Loss: 0.001282, PSRN_gt: 25.653947\n",
            "Iteration: 00168, Loss: 0.001341, PSRN_gt: 25.485539\n",
            "Iteration: 00169, Loss: 0.001249, PSRN_gt: 25.759168\n",
            "Iteration: 00170, Loss: 0.001209, PSRN_gt: 25.886929\n",
            "Iteration: 00171, Loss: 0.001258, PSRN_gt: 25.744366\n",
            "Iteration: 00172, Loss: 0.001212, PSRN_gt: 25.872749\n",
            "Iteration: 00173, Loss: 0.001167, PSRN_gt: 26.027362\n",
            "Iteration: 00174, Loss: 0.001210, PSRN_gt: 25.895833\n",
            "Iteration: 00175, Loss: 0.001179, PSRN_gt: 25.983922\n",
            "Iteration: 00176, Loss: 0.001140, PSRN_gt: 26.118053\n",
            "Iteration: 00177, Loss: 0.001147, PSRN_gt: 26.105960\n",
            "Iteration: 00178, Loss: 0.001166, PSRN_gt: 26.026638\n",
            "Iteration: 00179, Loss: 0.001137, PSRN_gt: 26.122739\n",
            "Iteration: 00180, Loss: 0.001104, PSRN_gt: 26.252163\n",
            "Iteration: 00181, Loss: 0.001122, PSRN_gt: 26.176488\n",
            "Iteration: 00182, Loss: 0.001127, PSRN_gt: 26.150205\n",
            "Iteration: 00183, Loss: 0.001111, PSRN_gt: 26.218816\n",
            "Iteration: 00184, Loss: 0.001113, PSRN_gt: 26.197948\n",
            "Iteration: 00185, Loss: 0.001169, PSRN_gt: 26.013146\n",
            "Iteration: 00186, Loss: 0.001280, PSRN_gt: 25.635845\n",
            "Iteration: 00187, Loss: 0.001347, PSRN_gt: 25.447317\n",
            "Iteration: 00188, Loss: 0.001323, PSRN_gt: 25.502284\n",
            "Iteration: 00189, Loss: 0.001299, PSRN_gt: 25.624765\n",
            "Iteration: 00190, Loss: 0.001408, PSRN_gt: 25.250478\n",
            "Iteration: 00191, Loss: 0.001309, PSRN_gt: 25.563036\n",
            "Iteration: 00192, Loss: 0.001207, PSRN_gt: 25.902251\n",
            "Iteration: 00193, Loss: 0.001325, PSRN_gt: 25.499151\n",
            "Iteration: 00194, Loss: 0.001220, PSRN_gt: 25.857189\n",
            "Iteration: 00195, Loss: 0.001219, PSRN_gt: 25.856843\n",
            "Iteration: 00196, Loss: 0.001235, PSRN_gt: 25.781690\n",
            "Iteration: 00197, Loss: 0.001161, PSRN_gt: 26.047731\n",
            "Iteration: 00198, Loss: 0.001172, PSRN_gt: 26.001217\n",
            "Iteration: 00199, Loss: 0.001148, PSRN_gt: 26.086856\n",
            "Iteration: 00200, Loss: 0.001141, PSRN_gt: 26.111454\n",
            "Iteration: 00201, Loss: 0.001123, PSRN_gt: 26.173552\n",
            "Iteration: 00202, Loss: 0.001105, PSRN_gt: 26.238603\n",
            "Iteration: 00203, Loss: 0.001108, PSRN_gt: 26.224283\n",
            "Iteration: 00204, Loss: 0.001073, PSRN_gt: 26.353029\n",
            "Iteration: 00205, Loss: 0.001080, PSRN_gt: 26.319006\n",
            "Iteration: 00206, Loss: 0.001072, PSRN_gt: 26.338710\n",
            "Iteration: 00207, Loss: 0.001063, PSRN_gt: 26.386257\n",
            "Iteration: 00208, Loss: 0.001057, PSRN_gt: 26.407317\n",
            "Iteration: 00209, Loss: 0.001057, PSRN_gt: 26.404847\n",
            "Iteration: 00210, Loss: 0.001054, PSRN_gt: 26.410782\n",
            "Iteration: 00211, Loss: 0.001063, PSRN_gt: 26.389081\n",
            "Iteration: 00212, Loss: 0.001080, PSRN_gt: 26.314290\n",
            "Iteration: 00213, Loss: 0.001085, PSRN_gt: 26.308367\n",
            "Iteration: 00214, Loss: 0.001090, PSRN_gt: 26.268627\n",
            "Iteration: 00215, Loss: 0.001106, PSRN_gt: 26.224955\n",
            "Iteration: 00216, Loss: 0.001086, PSRN_gt: 26.287709\n",
            "Iteration: 00217, Loss: 0.001060, PSRN_gt: 26.390100\n",
            "Iteration: 00218, Loss: 0.001038, PSRN_gt: 26.453821\n",
            "Iteration: 00219, Loss: 0.001041, PSRN_gt: 26.468513\n",
            "Iteration: 00220, Loss: 0.001063, PSRN_gt: 26.370957\n",
            "Iteration: 00221, Loss: 0.001054, PSRN_gt: 26.400521\n",
            "Iteration: 00222, Loss: 0.001040, PSRN_gt: 26.471109\n",
            "Iteration: 00223, Loss: 0.001027, PSRN_gt: 26.501430\n",
            "Iteration: 00224, Loss: 0.001019, PSRN_gt: 26.542185\n",
            "Iteration: 00225, Loss: 0.001036, PSRN_gt: 26.462410\n",
            "Iteration: 00226, Loss: 0.001037, PSRN_gt: 26.476855\n",
            "Iteration: 00227, Loss: 0.001009, PSRN_gt: 26.570265\n",
            "Iteration: 00228, Loss: 0.000989, PSRN_gt: 26.657629\n",
            "Iteration: 00229, Loss: 0.001004, PSRN_gt: 26.595557\n",
            "Iteration: 00230, Loss: 0.001030, PSRN_gt: 26.488433\n",
            "Iteration: 00231, Loss: 0.001052, PSRN_gt: 26.417734\n",
            "Iteration: 00232, Loss: 0.001120, PSRN_gt: 26.153403\n",
            "Iteration: 00233, Loss: 0.001211, PSRN_gt: 25.859562\n",
            "Iteration: 00234, Loss: 0.001201, PSRN_gt: 25.883135\n",
            "Iteration: 00235, Loss: 0.001063, PSRN_gt: 26.374934\n",
            "Iteration: 00236, Loss: 0.001049, PSRN_gt: 26.439967\n",
            "Iteration: 00237, Loss: 0.001133, PSRN_gt: 26.099802\n",
            "Iteration: 00238, Loss: 0.001078, PSRN_gt: 26.322035\n",
            "Iteration: 00239, Loss: 0.001015, PSRN_gt: 26.560325\n",
            "Iteration: 00240, Loss: 0.001062, PSRN_gt: 26.366537\n",
            "Iteration: 00241, Loss: 0.001042, PSRN_gt: 26.456855\n",
            "Iteration: 00242, Loss: 0.000996, PSRN_gt: 26.633423\n",
            "Iteration: 00243, Loss: 0.000994, PSRN_gt: 26.628714\n",
            "Iteration: 00244, Loss: 0.001005, PSRN_gt: 26.594535\n",
            "Iteration: 00245, Loss: 0.000979, PSRN_gt: 26.681714\n",
            "Iteration: 00246, Loss: 0.000959, PSRN_gt: 26.763163\n",
            "Iteration: 00247, Loss: 0.000972, PSRN_gt: 26.729956\n",
            "Iteration: 00248, Loss: 0.000967, PSRN_gt: 26.729188\n",
            "Iteration: 00249, Loss: 0.000948, PSRN_gt: 26.817830\n",
            "Iteration: 00250, Loss: 0.000950, PSRN_gt: 26.807999\n",
            "Iteration: 00251, Loss: 0.000964, PSRN_gt: 26.744547\n",
            "Iteration: 00252, Loss: 0.000977, PSRN_gt: 26.687735\n",
            "Iteration: 00253, Loss: 0.001025, PSRN_gt: 26.521655\n",
            "Iteration: 00254, Loss: 0.001098, PSRN_gt: 26.218326\n",
            "Iteration: 00255, Loss: 0.001108, PSRN_gt: 26.205641\n",
            "Iteration: 00256, Loss: 0.001022, PSRN_gt: 26.515955\n",
            "Iteration: 00257, Loss: 0.000960, PSRN_gt: 26.756238\n",
            "Iteration: 00258, Loss: 0.001013, PSRN_gt: 26.548487\n",
            "Iteration: 00259, Loss: 0.001042, PSRN_gt: 26.445786\n",
            "Iteration: 00260, Loss: 0.000984, PSRN_gt: 26.673337\n",
            "Iteration: 00261, Loss: 0.000947, PSRN_gt: 26.811458\n",
            "Iteration: 00262, Loss: 0.000965, PSRN_gt: 26.732652\n",
            "Iteration: 00263, Loss: 0.000987, PSRN_gt: 26.642470\n",
            "Iteration: 00264, Loss: 0.000935, PSRN_gt: 26.863885\n",
            "Iteration: 00265, Loss: 0.000913, PSRN_gt: 26.957613\n",
            "Iteration: 00266, Loss: 0.000945, PSRN_gt: 26.814612\n",
            "Iteration: 00267, Loss: 0.000917, PSRN_gt: 26.930596\n",
            "Iteration: 00268, Loss: 0.000898, PSRN_gt: 27.015646\n",
            "Iteration: 00269, Loss: 0.000907, PSRN_gt: 26.974053\n",
            "Iteration: 00270, Loss: 0.000904, PSRN_gt: 26.986858\n",
            "Iteration: 00271, Loss: 0.000889, PSRN_gt: 27.050342\n",
            "Iteration: 00272, Loss: 0.000888, PSRN_gt: 27.041415\n",
            "Iteration: 00273, Loss: 0.000894, PSRN_gt: 27.038849\n",
            "Iteration: 00274, Loss: 0.000917, PSRN_gt: 26.929287\n",
            "Iteration: 00275, Loss: 0.000955, PSRN_gt: 26.762443\n",
            "Iteration: 00276, Loss: 0.001033, PSRN_gt: 26.444468\n",
            "Iteration: 00277, Loss: 0.001178, PSRN_gt: 25.952604\n",
            "Iteration: 00278, Loss: 0.001195, PSRN_gt: 25.862318\n",
            "Iteration: 00279, Loss: 0.001001, PSRN_gt: 26.603671\n",
            "Iteration: 00280, Loss: 0.000947, PSRN_gt: 26.806779\n",
            "Iteration: 00281, Loss: 0.001068, PSRN_gt: 26.322391\n",
            "Iteration: 00282, Loss: 0.000999, PSRN_gt: 26.609091\n",
            "Iteration: 00283, Loss: 0.000922, PSRN_gt: 26.903051\n",
            "Iteration: 00284, Loss: 0.001007, PSRN_gt: 26.565538\n",
            "Iteration: 00285, Loss: 0.000944, PSRN_gt: 26.835491\n",
            "Iteration: 00286, Loss: 0.000908, PSRN_gt: 26.976596\n",
            "Iteration: 00287, Loss: 0.000940, PSRN_gt: 26.829236\n",
            "Iteration: 00288, Loss: 0.000900, PSRN_gt: 27.009682\n",
            "Iteration: 00289, Loss: 0.000902, PSRN_gt: 26.988870\n",
            "Iteration: 00290, Loss: 0.000899, PSRN_gt: 26.996516\n",
            "Iteration: 00291, Loss: 0.000882, PSRN_gt: 27.091632\n",
            "Iteration: 00292, Loss: 0.000876, PSRN_gt: 27.096572\n",
            "Iteration: 00293, Loss: 0.000864, PSRN_gt: 27.154518\n",
            "Iteration: 00294, Loss: 0.000864, PSRN_gt: 27.160837\n",
            "Iteration: 00295, Loss: 0.000853, PSRN_gt: 27.194712\n",
            "Iteration: 00296, Loss: 0.000850, PSRN_gt: 27.215566\n",
            "Iteration: 00297, Loss: 0.000850, PSRN_gt: 27.220471\n",
            "Iteration: 00298, Loss: 0.000835, PSRN_gt: 27.271998\n",
            "Iteration: 00299, Loss: 0.000839, PSRN_gt: 27.259910\n",
            "Iteration: 00300, Loss: 0.000846, PSRN_gt: 27.232733\n",
            "Iteration: 00301, Loss: 0.000855, PSRN_gt: 27.179439\n",
            "Iteration: 00302, Loss: 0.000903, PSRN_gt: 26.980467\n",
            "Iteration: 00303, Loss: 0.000997, PSRN_gt: 26.584148\n",
            "Iteration: 00304, Loss: 0.001095, PSRN_gt: 26.224013\n",
            "Iteration: 00305, Loss: 0.001091, PSRN_gt: 26.218067\n",
            "Iteration: 00306, Loss: 0.001013, PSRN_gt: 26.537666\n",
            "Iteration: 00307, Loss: 0.001032, PSRN_gt: 26.449891\n",
            "Iteration: 00308, Loss: 0.001077, PSRN_gt: 26.279920\n",
            "Iteration: 00309, Loss: 0.001005, PSRN_gt: 26.586627\n",
            "Iteration: 00310, Loss: 0.000926, PSRN_gt: 26.889067\n",
            "Iteration: 00311, Loss: 0.000975, PSRN_gt: 26.673545\n",
            "Iteration: 00312, Loss: 0.000947, PSRN_gt: 26.788968\n",
            "Iteration: 00313, Loss: 0.000892, PSRN_gt: 27.023786\n",
            "Iteration: 00314, Loss: 0.000928, PSRN_gt: 26.864359\n",
            "Iteration: 00315, Loss: 0.000891, PSRN_gt: 27.025299\n",
            "Iteration: 00316, Loss: 0.000873, PSRN_gt: 27.106672\n",
            "Iteration: 00317, Loss: 0.000894, PSRN_gt: 27.016751\n",
            "Iteration: 00318, Loss: 0.000848, PSRN_gt: 27.223942\n",
            "Iteration: 00319, Loss: 0.000856, PSRN_gt: 27.184285\n",
            "Iteration: 00320, Loss: 0.000856, PSRN_gt: 27.173982\n",
            "Iteration: 00321, Loss: 0.000823, PSRN_gt: 27.327307\n",
            "Iteration: 00322, Loss: 0.000834, PSRN_gt: 27.279206\n",
            "Iteration: 00323, Loss: 0.000819, PSRN_gt: 27.350961\n",
            "Iteration: 00324, Loss: 0.000811, PSRN_gt: 27.385151\n",
            "Iteration: 00325, Loss: 0.000810, PSRN_gt: 27.383590\n",
            "Iteration: 00326, Loss: 0.000802, PSRN_gt: 27.414736\n",
            "Iteration: 00327, Loss: 0.000798, PSRN_gt: 27.433273\n",
            "Iteration: 00328, Loss: 0.000788, PSRN_gt: 27.495583\n",
            "Iteration: 00329, Loss: 0.000786, PSRN_gt: 27.503725\n",
            "Iteration: 00330, Loss: 0.000790, PSRN_gt: 27.470052\n",
            "Iteration: 00331, Loss: 0.000783, PSRN_gt: 27.511408\n",
            "Iteration: 00332, Loss: 0.000788, PSRN_gt: 27.488040\n",
            "Iteration: 00333, Loss: 0.000821, PSRN_gt: 27.314146\n",
            "Iteration: 00334, Loss: 0.000882, PSRN_gt: 27.051796\n",
            "Iteration: 00335, Loss: 0.001002, PSRN_gt: 26.568467\n",
            "Iteration: 00336, Loss: 0.001154, PSRN_gt: 26.003805\n",
            "Iteration: 00337, Loss: 0.001015, PSRN_gt: 26.506239\n",
            "Iteration: 00338, Loss: 0.000838, PSRN_gt: 27.269745\n",
            "Iteration: 00339, Loss: 0.000941, PSRN_gt: 26.809173\n",
            "Iteration: 00340, Loss: 0.000983, PSRN_gt: 26.641455\n",
            "Iteration: 00341, Loss: 0.000842, PSRN_gt: 27.257334\n",
            "Iteration: 00342, Loss: 0.000876, PSRN_gt: 27.082315\n",
            "Iteration: 00343, Loss: 0.000896, PSRN_gt: 26.987237\n",
            "Iteration: 00344, Loss: 0.000839, PSRN_gt: 27.255344\n",
            "Iteration: 00345, Loss: 0.000841, PSRN_gt: 27.233398\n",
            "Iteration: 00346, Loss: 0.000841, PSRN_gt: 27.237630\n",
            "Iteration: 00347, Loss: 0.000812, PSRN_gt: 27.371107\n",
            "Iteration: 00348, Loss: 0.000811, PSRN_gt: 27.369431\n",
            "Iteration: 00349, Loss: 0.000808, PSRN_gt: 27.395231\n",
            "Iteration: 00350, Loss: 0.000794, PSRN_gt: 27.463386\n",
            "Iteration: 00351, Loss: 0.000783, PSRN_gt: 27.507785\n",
            "Iteration: 00352, Loss: 0.000784, PSRN_gt: 27.500824\n",
            "Iteration: 00353, Loss: 0.000779, PSRN_gt: 27.539349\n",
            "Iteration: 00354, Loss: 0.000762, PSRN_gt: 27.601016\n",
            "Iteration: 00355, Loss: 0.000766, PSRN_gt: 27.572763\n",
            "Iteration: 00356, Loss: 0.000764, PSRN_gt: 27.611206\n",
            "Iteration: 00357, Loss: 0.000749, PSRN_gt: 27.675920\n",
            "Iteration: 00358, Loss: 0.000746, PSRN_gt: 27.671734\n",
            "Iteration: 00359, Loss: 0.000746, PSRN_gt: 27.678212\n",
            "Iteration: 00360, Loss: 0.000738, PSRN_gt: 27.725113\n",
            "Iteration: 00361, Loss: 0.000734, PSRN_gt: 27.739497\n",
            "Iteration: 00362, Loss: 0.000730, PSRN_gt: 27.759067\n",
            "Iteration: 00363, Loss: 0.000728, PSRN_gt: 27.768857\n",
            "Iteration: 00364, Loss: 0.000727, PSRN_gt: 27.780677\n",
            "Iteration: 00365, Loss: 0.000726, PSRN_gt: 27.773037\n",
            "Iteration: 00366, Loss: 0.000727, PSRN_gt: 27.770831\n",
            "Iteration: 00367, Loss: 0.000738, PSRN_gt: 27.716105\n",
            "Iteration: 00368, Loss: 0.000771, PSRN_gt: 27.552419\n",
            "Iteration: 00369, Loss: 0.000859, PSRN_gt: 27.123336\n",
            "Iteration: 00370, Loss: 0.000975, PSRN_gt: 26.656067\n",
            "Iteration: 00371, Loss: 0.001042, PSRN_gt: 26.380127\n",
            "Iteration: 00372, Loss: 0.000906, PSRN_gt: 26.948491\n",
            "Iteration: 00373, Loss: 0.000845, PSRN_gt: 27.218632\n",
            "Iteration: 00374, Loss: 0.000996, PSRN_gt: 26.571458\n",
            "Iteration: 00375, Loss: 0.000968, PSRN_gt: 26.706942\n",
            "Iteration: 00376, Loss: 0.000950, PSRN_gt: 26.767236\n",
            "Iteration: 00377, Loss: 0.000974, PSRN_gt: 26.665363\n",
            "Iteration: 00378, Loss: 0.000931, PSRN_gt: 26.847989\n",
            "Iteration: 00379, Loss: 0.000920, PSRN_gt: 26.913100\n",
            "Iteration: 00380, Loss: 0.000920, PSRN_gt: 26.880352\n",
            "Iteration: 00381, Loss: 0.000835, PSRN_gt: 27.267450\n",
            "Iteration: 00382, Loss: 0.000830, PSRN_gt: 27.285652\n",
            "Iteration: 00383, Loss: 0.000839, PSRN_gt: 27.230766\n",
            "Iteration: 00384, Loss: 0.000813, PSRN_gt: 27.384126\n",
            "Iteration: 00385, Loss: 0.000808, PSRN_gt: 27.388624\n",
            "Iteration: 00386, Loss: 0.000785, PSRN_gt: 27.489544\n",
            "Iteration: 00387, Loss: 0.000782, PSRN_gt: 27.518190\n",
            "Iteration: 00388, Loss: 0.000767, PSRN_gt: 27.586987\n",
            "Iteration: 00389, Loss: 0.000763, PSRN_gt: 27.604904\n",
            "Iteration: 00390, Loss: 0.000756, PSRN_gt: 27.622494\n",
            "Iteration: 00391, Loss: 0.000736, PSRN_gt: 27.739345\n",
            "Iteration: 00392, Loss: 0.000743, PSRN_gt: 27.699209\n",
            "Iteration: 00393, Loss: 0.000728, PSRN_gt: 27.767568\n",
            "Iteration: 00394, Loss: 0.000726, PSRN_gt: 27.781991\n",
            "Iteration: 00395, Loss: 0.000727, PSRN_gt: 27.772495\n",
            "Iteration: 00396, Loss: 0.000711, PSRN_gt: 27.861968\n",
            "Iteration: 00397, Loss: 0.000713, PSRN_gt: 27.844362\n",
            "Iteration: 00398, Loss: 0.000705, PSRN_gt: 27.887869\n",
            "Iteration: 00399, Loss: 0.000696, PSRN_gt: 27.927073\n",
            "Iteration: 00400, Loss: 0.000698, PSRN_gt: 27.923528\n",
            "Iteration: 00401, Loss: 0.000690, PSRN_gt: 27.957568\n",
            "Iteration: 00402, Loss: 0.000688, PSRN_gt: 27.960219\n",
            "Iteration: 00403, Loss: 0.000690, PSRN_gt: 27.957932\n",
            "Iteration: 00404, Loss: 0.000688, PSRN_gt: 27.963728\n",
            "Iteration: 00405, Loss: 0.000698, PSRN_gt: 27.915547\n",
            "Iteration: 00406, Loss: 0.000725, PSRN_gt: 27.757097\n",
            "Iteration: 00407, Loss: 0.000777, PSRN_gt: 27.522323\n",
            "Iteration: 00408, Loss: 0.000876, PSRN_gt: 27.043144\n",
            "Iteration: 00409, Loss: 0.000916, PSRN_gt: 26.896123\n",
            "Iteration: 00410, Loss: 0.000845, PSRN_gt: 27.173761\n",
            "Iteration: 00411, Loss: 0.000779, PSRN_gt: 27.506131\n",
            "Iteration: 00412, Loss: 0.000847, PSRN_gt: 27.201215\n",
            "Iteration: 00413, Loss: 0.000859, PSRN_gt: 27.122409\n",
            "Iteration: 00414, Loss: 0.000783, PSRN_gt: 27.501639\n",
            "Iteration: 00415, Loss: 0.000809, PSRN_gt: 27.366359\n",
            "Iteration: 00416, Loss: 0.000821, PSRN_gt: 27.292236\n",
            "Iteration: 00417, Loss: 0.000733, PSRN_gt: 27.737302\n",
            "Iteration: 00418, Loss: 0.000753, PSRN_gt: 27.651801\n",
            "Iteration: 00419, Loss: 0.000779, PSRN_gt: 27.505092\n",
            "Iteration: 00420, Loss: 0.000716, PSRN_gt: 27.814587\n",
            "Iteration: 00421, Loss: 0.000734, PSRN_gt: 27.739296\n",
            "Iteration: 00422, Loss: 0.000736, PSRN_gt: 27.714664\n",
            "Iteration: 00423, Loss: 0.000694, PSRN_gt: 27.924225\n",
            "Iteration: 00424, Loss: 0.000711, PSRN_gt: 27.847306\n",
            "Iteration: 00425, Loss: 0.000710, PSRN_gt: 27.849305\n",
            "Iteration: 00426, Loss: 0.000689, PSRN_gt: 27.960200\n",
            "Iteration: 00427, Loss: 0.000696, PSRN_gt: 27.922711\n",
            "Iteration: 00428, Loss: 0.000696, PSRN_gt: 27.921542\n",
            "Iteration: 00429, Loss: 0.000670, PSRN_gt: 28.062619\n",
            "Iteration: 00430, Loss: 0.000673, PSRN_gt: 28.042523\n",
            "Iteration: 00431, Loss: 0.000675, PSRN_gt: 28.028052\n",
            "Iteration: 00432, Loss: 0.000658, PSRN_gt: 28.126870\n",
            "Iteration: 00433, Loss: 0.000662, PSRN_gt: 28.107987\n",
            "Iteration: 00434, Loss: 0.000664, PSRN_gt: 28.092874\n",
            "Iteration: 00435, Loss: 0.000650, PSRN_gt: 28.160281\n",
            "Iteration: 00436, Loss: 0.000652, PSRN_gt: 28.160842\n",
            "Iteration: 00437, Loss: 0.000653, PSRN_gt: 28.152067\n",
            "Iteration: 00438, Loss: 0.000651, PSRN_gt: 28.156066\n",
            "Iteration: 00439, Loss: 0.000660, PSRN_gt: 28.106744\n",
            "Iteration: 00440, Loss: 0.000689, PSRN_gt: 27.945172\n",
            "Iteration: 00441, Loss: 0.000769, PSRN_gt: 27.536361\n",
            "Iteration: 00442, Loss: 0.000902, PSRN_gt: 26.924261\n",
            "Iteration: 00443, Loss: 0.001124, PSRN_gt: 26.072255\n",
            "Iteration: 00444, Loss: 0.001030, PSRN_gt: 26.425200\n",
            "Iteration: 00445, Loss: 0.000774, PSRN_gt: 27.528655\n",
            "Iteration: 00446, Loss: 0.000885, PSRN_gt: 27.011155\n",
            "Iteration: 00447, Loss: 0.000895, PSRN_gt: 26.987016\n",
            "Iteration: 00448, Loss: 0.000738, PSRN_gt: 27.711197\n",
            "Iteration: 00449, Loss: 0.000811, PSRN_gt: 27.341415\n",
            "Iteration: 00450, Loss: 0.000771, PSRN_gt: 27.555947\n",
            "Iteration: 00451, Loss: 0.000739, PSRN_gt: 27.702365\n",
            "Iteration: 00452, Loss: 0.000759, PSRN_gt: 27.603904\n",
            "Iteration: 00453, Loss: 0.000716, PSRN_gt: 27.835338\n",
            "Iteration: 00454, Loss: 0.000719, PSRN_gt: 27.806189\n",
            "Iteration: 00455, Loss: 0.000713, PSRN_gt: 27.840499\n",
            "Iteration: 00456, Loss: 0.000690, PSRN_gt: 27.972849\n",
            "Iteration: 00457, Loss: 0.000698, PSRN_gt: 27.905639\n",
            "Iteration: 00458, Loss: 0.000679, PSRN_gt: 28.008967\n",
            "Iteration: 00459, Loss: 0.000673, PSRN_gt: 28.052889\n",
            "Iteration: 00460, Loss: 0.000672, PSRN_gt: 28.057083\n",
            "Iteration: 00461, Loss: 0.000658, PSRN_gt: 28.122633\n",
            "Iteration: 00462, Loss: 0.000662, PSRN_gt: 28.099539\n",
            "Iteration: 00463, Loss: 0.000648, PSRN_gt: 28.185918\n",
            "Iteration: 00464, Loss: 0.000649, PSRN_gt: 28.180288\n",
            "Iteration: 00465, Loss: 0.000641, PSRN_gt: 28.215769\n",
            "Iteration: 00466, Loss: 0.000639, PSRN_gt: 28.223248\n",
            "Iteration: 00467, Loss: 0.000635, PSRN_gt: 28.253800\n",
            "Iteration: 00468, Loss: 0.000628, PSRN_gt: 28.286869\n",
            "Iteration: 00469, Loss: 0.000627, PSRN_gt: 28.283956\n",
            "Iteration: 00470, Loss: 0.000619, PSRN_gt: 28.334832\n",
            "Iteration: 00471, Loss: 0.000622, PSRN_gt: 28.320916\n",
            "Iteration: 00472, Loss: 0.000614, PSRN_gt: 28.365551\n",
            "Iteration: 00473, Loss: 0.000614, PSRN_gt: 28.366836\n",
            "Iteration: 00474, Loss: 0.000612, PSRN_gt: 28.367022\n",
            "Iteration: 00475, Loss: 0.000607, PSRN_gt: 28.400731\n",
            "Iteration: 00476, Loss: 0.000607, PSRN_gt: 28.397778\n",
            "Iteration: 00477, Loss: 0.000605, PSRN_gt: 28.416825\n",
            "Iteration: 00478, Loss: 0.000605, PSRN_gt: 28.408631\n",
            "Iteration: 00479, Loss: 0.000605, PSRN_gt: 28.408762\n",
            "Iteration: 00480, Loss: 0.000611, PSRN_gt: 28.373694\n",
            "Iteration: 00481, Loss: 0.000625, PSRN_gt: 28.296751\n",
            "Iteration: 00482, Loss: 0.000657, PSRN_gt: 28.097141\n",
            "Iteration: 00483, Loss: 0.000730, PSRN_gt: 27.736648\n",
            "Iteration: 00484, Loss: 0.000807, PSRN_gt: 27.330052\n",
            "Iteration: 00485, Loss: 0.000850, PSRN_gt: 27.167302\n",
            "Iteration: 00486, Loss: 0.000748, PSRN_gt: 27.616816\n",
            "Iteration: 00487, Loss: 0.000674, PSRN_gt: 28.023877\n",
            "Iteration: 00488, Loss: 0.000745, PSRN_gt: 27.662272\n",
            "Iteration: 00489, Loss: 0.000762, PSRN_gt: 27.549359\n",
            "Iteration: 00490, Loss: 0.000686, PSRN_gt: 27.978866\n",
            "Iteration: 00491, Loss: 0.000689, PSRN_gt: 27.952225\n",
            "Iteration: 00492, Loss: 0.000716, PSRN_gt: 27.788744\n",
            "Iteration: 00493, Loss: 0.000662, PSRN_gt: 28.110293\n",
            "Iteration: 00494, Loss: 0.000656, PSRN_gt: 28.124475\n",
            "Iteration: 00495, Loss: 0.000682, PSRN_gt: 27.970776\n",
            "Iteration: 00496, Loss: 0.000644, PSRN_gt: 28.208230\n",
            "Iteration: 00497, Loss: 0.000636, PSRN_gt: 28.246149\n",
            "Iteration: 00498, Loss: 0.000651, PSRN_gt: 28.143058\n",
            "Iteration: 00499, Loss: 0.000627, PSRN_gt: 28.292809\n",
            "Iteration: 00500, Loss: 0.000617, PSRN_gt: 28.352652\n",
            "Iteration: 00501, Loss: 0.000627, PSRN_gt: 28.281665\n",
            "Iteration: 00502, Loss: 0.000617, PSRN_gt: 28.333709\n",
            "Iteration: 00503, Loss: 0.000605, PSRN_gt: 28.410959\n",
            "Iteration: 00504, Loss: 0.000608, PSRN_gt: 28.391627\n",
            "Iteration: 00505, Loss: 0.000604, PSRN_gt: 28.409709\n",
            "Iteration: 00506, Loss: 0.000595, PSRN_gt: 28.466076\n",
            "Iteration: 00507, Loss: 0.000594, PSRN_gt: 28.472090\n",
            "Iteration: 00508, Loss: 0.000592, PSRN_gt: 28.484298\n",
            "Iteration: 00509, Loss: 0.000585, PSRN_gt: 28.521156\n",
            "Iteration: 00510, Loss: 0.000584, PSRN_gt: 28.531882\n",
            "Iteration: 00511, Loss: 0.000579, PSRN_gt: 28.556362\n",
            "Iteration: 00512, Loss: 0.000579, PSRN_gt: 28.553730\n",
            "Iteration: 00513, Loss: 0.000579, PSRN_gt: 28.555970\n",
            "Iteration: 00514, Loss: 0.000573, PSRN_gt: 28.589996\n",
            "Iteration: 00515, Loss: 0.000576, PSRN_gt: 28.576030\n",
            "Iteration: 00516, Loss: 0.000584, PSRN_gt: 28.525133\n",
            "Iteration: 00517, Loss: 0.000597, PSRN_gt: 28.435717\n",
            "Iteration: 00518, Loss: 0.000631, PSRN_gt: 28.246413\n",
            "Iteration: 00519, Loss: 0.000708, PSRN_gt: 27.813289\n",
            "Iteration: 00520, Loss: 0.000815, PSRN_gt: 27.294215\n",
            "Iteration: 00521, Loss: 0.000876, PSRN_gt: 27.012613\n",
            "Iteration: 00522, Loss: 0.000738, PSRN_gt: 27.677499\n",
            "Iteration: 00523, Loss: 0.000628, PSRN_gt: 28.283346\n",
            "Iteration: 00524, Loss: 0.000746, PSRN_gt: 27.637294\n",
            "Iteration: 00525, Loss: 0.000788, PSRN_gt: 27.441732\n",
            "Iteration: 00526, Loss: 0.000662, PSRN_gt: 28.075809\n",
            "Iteration: 00527, Loss: 0.000648, PSRN_gt: 28.161629\n",
            "Iteration: 00528, Loss: 0.000693, PSRN_gt: 27.912845\n",
            "Iteration: 00529, Loss: 0.000635, PSRN_gt: 28.242677\n",
            "Iteration: 00530, Loss: 0.000634, PSRN_gt: 28.248357\n",
            "Iteration: 00531, Loss: 0.000656, PSRN_gt: 28.108964\n",
            "Iteration: 00532, Loss: 0.000608, PSRN_gt: 28.402445\n",
            "Iteration: 00533, Loss: 0.000615, PSRN_gt: 28.357891\n",
            "Iteration: 00534, Loss: 0.000624, PSRN_gt: 28.288908\n",
            "Iteration: 00535, Loss: 0.000591, PSRN_gt: 28.501287\n",
            "Iteration: 00536, Loss: 0.000597, PSRN_gt: 28.464586\n",
            "Iteration: 00537, Loss: 0.000598, PSRN_gt: 28.441195\n",
            "Iteration: 00538, Loss: 0.000581, PSRN_gt: 28.543280\n",
            "Iteration: 00539, Loss: 0.000583, PSRN_gt: 28.535509\n",
            "Iteration: 00540, Loss: 0.000578, PSRN_gt: 28.568188\n",
            "Iteration: 00541, Loss: 0.000570, PSRN_gt: 28.614270\n",
            "Iteration: 00542, Loss: 0.000573, PSRN_gt: 28.592338\n",
            "Iteration: 00543, Loss: 0.000564, PSRN_gt: 28.654722\n",
            "Iteration: 00544, Loss: 0.000560, PSRN_gt: 28.677612\n",
            "Iteration: 00545, Loss: 0.000561, PSRN_gt: 28.658843\n",
            "Iteration: 00546, Loss: 0.000554, PSRN_gt: 28.711317\n",
            "Iteration: 00547, Loss: 0.000551, PSRN_gt: 28.736449\n",
            "Iteration: 00548, Loss: 0.000551, PSRN_gt: 28.721960\n",
            "Iteration: 00549, Loss: 0.000545, PSRN_gt: 28.761092\n",
            "Iteration: 00550, Loss: 0.000543, PSRN_gt: 28.782015\n",
            "Iteration: 00551, Loss: 0.000543, PSRN_gt: 28.774182\n",
            "Iteration: 00552, Loss: 0.000541, PSRN_gt: 28.790456\n",
            "Iteration: 00553, Loss: 0.000538, PSRN_gt: 28.805903\n",
            "Iteration: 00554, Loss: 0.000536, PSRN_gt: 28.811147\n",
            "Iteration: 00555, Loss: 0.000542, PSRN_gt: 28.780585\n",
            "Iteration: 00556, Loss: 0.000555, PSRN_gt: 28.690833\n",
            "Iteration: 00557, Loss: 0.000595, PSRN_gt: 28.440733\n",
            "Iteration: 00558, Loss: 0.000709, PSRN_gt: 27.812137\n",
            "Iteration: 00559, Loss: 0.000918, PSRN_gt: 26.844183\n",
            "Iteration: 00560, Loss: 0.001110, PSRN_gt: 26.116363\n",
            "Iteration: 00561, Loss: 0.000857, PSRN_gt: 27.114774\n",
            "Iteration: 00562, Loss: 0.000713, PSRN_gt: 27.812415\n",
            "Iteration: 00563, Loss: 0.000863, PSRN_gt: 27.115540\n",
            "Iteration: 00564, Loss: 0.000751, PSRN_gt: 27.615651\n",
            "Iteration: 00565, Loss: 0.000726, PSRN_gt: 27.734754\n",
            "Iteration: 00566, Loss: 0.000740, PSRN_gt: 27.709274\n",
            "Iteration: 00567, Loss: 0.000682, PSRN_gt: 27.981043\n",
            "Iteration: 00568, Loss: 0.000711, PSRN_gt: 27.816888\n",
            "Iteration: 00569, Loss: 0.000648, PSRN_gt: 28.186408\n",
            "Iteration: 00570, Loss: 0.000663, PSRN_gt: 28.094818\n",
            "Iteration: 00571, Loss: 0.000643, PSRN_gt: 28.185335\n",
            "Iteration: 00572, Loss: 0.000625, PSRN_gt: 28.295349\n",
            "Iteration: 00573, Loss: 0.000628, PSRN_gt: 28.296512\n",
            "Iteration: 00574, Loss: 0.000606, PSRN_gt: 28.403942\n",
            "Iteration: 00575, Loss: 0.000603, PSRN_gt: 28.414458\n",
            "Iteration: 00576, Loss: 0.000597, PSRN_gt: 28.465112\n",
            "Iteration: 00577, Loss: 0.000583, PSRN_gt: 28.550164\n",
            "Iteration: 00578, Loss: 0.000582, PSRN_gt: 28.544400\n",
            "Iteration: 00579, Loss: 0.000572, PSRN_gt: 28.602615\n",
            "Iteration: 00580, Loss: 0.000569, PSRN_gt: 28.635473\n",
            "Iteration: 00581, Loss: 0.000560, PSRN_gt: 28.689274\n",
            "Iteration: 00582, Loss: 0.000559, PSRN_gt: 28.679613\n",
            "Iteration: 00583, Loss: 0.000549, PSRN_gt: 28.733590\n",
            "Iteration: 00584, Loss: 0.000550, PSRN_gt: 28.738497\n",
            "Iteration: 00585, Loss: 0.000541, PSRN_gt: 28.790414\n",
            "Iteration: 00586, Loss: 0.000542, PSRN_gt: 28.777680\n",
            "Iteration: 00587, Loss: 0.000533, PSRN_gt: 28.840860\n",
            "Iteration: 00588, Loss: 0.000535, PSRN_gt: 28.833931\n",
            "Iteration: 00589, Loss: 0.000529, PSRN_gt: 28.860980\n",
            "Iteration: 00590, Loss: 0.000526, PSRN_gt: 28.876833\n",
            "Iteration: 00591, Loss: 0.000524, PSRN_gt: 28.902637\n",
            "Iteration: 00592, Loss: 0.000520, PSRN_gt: 28.918229\n",
            "Iteration: 00593, Loss: 0.000519, PSRN_gt: 28.914181\n",
            "Iteration: 00594, Loss: 0.000515, PSRN_gt: 28.951374\n",
            "Iteration: 00595, Loss: 0.000514, PSRN_gt: 28.971473\n",
            "Iteration: 00596, Loss: 0.000512, PSRN_gt: 28.968516\n",
            "Iteration: 00597, Loss: 0.000509, PSRN_gt: 28.991489\n",
            "Iteration: 00598, Loss: 0.000508, PSRN_gt: 28.994008\n",
            "Iteration: 00599, Loss: 0.000506, PSRN_gt: 29.003436\n",
            "Iteration: 00600, Loss: 0.000506, PSRN_gt: 29.005214\n",
            "Iteration: 00601, Loss: 0.000507, PSRN_gt: 29.002476\n",
            "Iteration: 00602, Loss: 0.000512, PSRN_gt: 28.954953\n",
            "Iteration: 00603, Loss: 0.000530, PSRN_gt: 28.845849\n",
            "Iteration: 00604, Loss: 0.000569, PSRN_gt: 28.588238\n",
            "Iteration: 00605, Loss: 0.000656, PSRN_gt: 28.100332\n",
            "Iteration: 00606, Loss: 0.000743, PSRN_gt: 27.609330\n",
            "Iteration: 00607, Loss: 0.000737, PSRN_gt: 27.678297\n",
            "Iteration: 00608, Loss: 0.000607, PSRN_gt: 28.361647\n",
            "Iteration: 00609, Loss: 0.000590, PSRN_gt: 28.467867\n",
            "Iteration: 00610, Loss: 0.000690, PSRN_gt: 27.926715\n",
            "Iteration: 00611, Loss: 0.000645, PSRN_gt: 28.154561\n",
            "Iteration: 00612, Loss: 0.000559, PSRN_gt: 28.665105\n",
            "Iteration: 00613, Loss: 0.000619, PSRN_gt: 28.309357\n",
            "Iteration: 00614, Loss: 0.000612, PSRN_gt: 28.348936\n",
            "Iteration: 00615, Loss: 0.000536, PSRN_gt: 28.819760\n",
            "Iteration: 00616, Loss: 0.000572, PSRN_gt: 28.596212\n",
            "Iteration: 00617, Loss: 0.000574, PSRN_gt: 28.569607\n",
            "Iteration: 00618, Loss: 0.000529, PSRN_gt: 28.863622\n",
            "Iteration: 00619, Loss: 0.000555, PSRN_gt: 28.699760\n",
            "Iteration: 00620, Loss: 0.000550, PSRN_gt: 28.712382\n",
            "Iteration: 00621, Loss: 0.000521, PSRN_gt: 28.913038\n",
            "Iteration: 00622, Loss: 0.000530, PSRN_gt: 28.849367\n",
            "Iteration: 00623, Loss: 0.000531, PSRN_gt: 28.835537\n",
            "Iteration: 00624, Loss: 0.000516, PSRN_gt: 28.951552\n",
            "Iteration: 00625, Loss: 0.000513, PSRN_gt: 28.957627\n",
            "Iteration: 00626, Loss: 0.000520, PSRN_gt: 28.896777\n",
            "Iteration: 00627, Loss: 0.000512, PSRN_gt: 28.970078\n",
            "Iteration: 00628, Loss: 0.000503, PSRN_gt: 29.028826\n",
            "Iteration: 00629, Loss: 0.000509, PSRN_gt: 28.980422\n",
            "Iteration: 00630, Loss: 0.000506, PSRN_gt: 29.010683\n",
            "Iteration: 00631, Loss: 0.000498, PSRN_gt: 29.061465\n",
            "Iteration: 00632, Loss: 0.000497, PSRN_gt: 29.059024\n",
            "Iteration: 00633, Loss: 0.000497, PSRN_gt: 29.059066\n",
            "Iteration: 00634, Loss: 0.000496, PSRN_gt: 29.066230\n",
            "Iteration: 00635, Loss: 0.000495, PSRN_gt: 29.067537\n",
            "Iteration: 00636, Loss: 0.000499, PSRN_gt: 29.041138\n",
            "Iteration: 00637, Loss: 0.000510, PSRN_gt: 28.967967\n",
            "Iteration: 00638, Loss: 0.000527, PSRN_gt: 28.850507\n",
            "Iteration: 00639, Loss: 0.000561, PSRN_gt: 28.628947\n",
            "Iteration: 00640, Loss: 0.000611, PSRN_gt: 28.337215\n",
            "Iteration: 00641, Loss: 0.000674, PSRN_gt: 27.980162\n",
            "Iteration: 00642, Loss: 0.000655, PSRN_gt: 28.077440\n",
            "Iteration: 00643, Loss: 0.000568, PSRN_gt: 28.597802\n",
            "Iteration: 00644, Loss: 0.000500, PSRN_gt: 29.047846\n",
            "Iteration: 00645, Loss: 0.000533, PSRN_gt: 28.813135\n",
            "Iteration: 00646, Loss: 0.000582, PSRN_gt: 28.511392\n",
            "Iteration: 00647, Loss: 0.000547, PSRN_gt: 28.732407\n",
            "Iteration: 00648, Loss: 0.000498, PSRN_gt: 29.038957\n",
            "Iteration: 00649, Loss: 0.000508, PSRN_gt: 28.997200\n",
            "Iteration: 00650, Loss: 0.000531, PSRN_gt: 28.833573\n",
            "Iteration: 00651, Loss: 0.000518, PSRN_gt: 28.904215\n",
            "Iteration: 00652, Loss: 0.000493, PSRN_gt: 29.101071\n",
            "Iteration: 00653, Loss: 0.000495, PSRN_gt: 29.063010\n",
            "Iteration: 00654, Loss: 0.000506, PSRN_gt: 28.992796\n",
            "Iteration: 00655, Loss: 0.000496, PSRN_gt: 29.065630\n",
            "Iteration: 00656, Loss: 0.000486, PSRN_gt: 29.123878\n",
            "Iteration: 00657, Loss: 0.000487, PSRN_gt: 29.131801\n",
            "Iteration: 00658, Loss: 0.000484, PSRN_gt: 29.129986\n",
            "Iteration: 00659, Loss: 0.000479, PSRN_gt: 29.173826\n",
            "Iteration: 00660, Loss: 0.000478, PSRN_gt: 29.194103\n",
            "Iteration: 00661, Loss: 0.000477, PSRN_gt: 29.179007\n",
            "Iteration: 00662, Loss: 0.000472, PSRN_gt: 29.231602\n",
            "Iteration: 00663, Loss: 0.000469, PSRN_gt: 29.246794\n",
            "Iteration: 00664, Loss: 0.000469, PSRN_gt: 29.238544\n",
            "Iteration: 00665, Loss: 0.000466, PSRN_gt: 29.271905\n",
            "Iteration: 00666, Loss: 0.000463, PSRN_gt: 29.277636\n",
            "Iteration: 00667, Loss: 0.000463, PSRN_gt: 29.285107\n",
            "Iteration: 00668, Loss: 0.000464, PSRN_gt: 29.279203\n",
            "Iteration: 00669, Loss: 0.000464, PSRN_gt: 29.272258\n",
            "Iteration: 00670, Loss: 0.000468, PSRN_gt: 29.257848\n",
            "Iteration: 00671, Loss: 0.000480, PSRN_gt: 29.157201\n",
            "Iteration: 00672, Loss: 0.000510, PSRN_gt: 28.955994\n",
            "Iteration: 00673, Loss: 0.000570, PSRN_gt: 28.565747\n",
            "Iteration: 00674, Loss: 0.000669, PSRN_gt: 27.985116\n",
            "Iteration: 00675, Loss: 0.000755, PSRN_gt: 27.543127\n",
            "Iteration: 00676, Loss: 0.000709, PSRN_gt: 27.784547\n",
            "Iteration: 00677, Loss: 0.000562, PSRN_gt: 28.628282\n",
            "Iteration: 00678, Loss: 0.000578, PSRN_gt: 28.536424\n",
            "Iteration: 00679, Loss: 0.000658, PSRN_gt: 28.070411\n",
            "Iteration: 00680, Loss: 0.000580, PSRN_gt: 28.509147\n",
            "Iteration: 00681, Loss: 0.000528, PSRN_gt: 28.866509\n",
            "Iteration: 00682, Loss: 0.000587, PSRN_gt: 28.480983\n",
            "Iteration: 00683, Loss: 0.000544, PSRN_gt: 28.735650\n",
            "Iteration: 00684, Loss: 0.000507, PSRN_gt: 29.016723\n",
            "Iteration: 00685, Loss: 0.000546, PSRN_gt: 28.735308\n",
            "Iteration: 00686, Loss: 0.000516, PSRN_gt: 28.918084\n",
            "Iteration: 00687, Loss: 0.000489, PSRN_gt: 29.125023\n",
            "Iteration: 00688, Loss: 0.000514, PSRN_gt: 28.939861\n",
            "Iteration: 00689, Loss: 0.000494, PSRN_gt: 29.064616\n",
            "Iteration: 00690, Loss: 0.000480, PSRN_gt: 29.178282\n",
            "Iteration: 00691, Loss: 0.000495, PSRN_gt: 29.074030\n",
            "Iteration: 00692, Loss: 0.000479, PSRN_gt: 29.172144\n",
            "Iteration: 00693, Loss: 0.000469, PSRN_gt: 29.251558\n",
            "Iteration: 00694, Loss: 0.000478, PSRN_gt: 29.186750\n",
            "Iteration: 00695, Loss: 0.000467, PSRN_gt: 29.260124\n",
            "Iteration: 00696, Loss: 0.000459, PSRN_gt: 29.318417\n",
            "Iteration: 00697, Loss: 0.000466, PSRN_gt: 29.267121\n",
            "Iteration: 00698, Loss: 0.000459, PSRN_gt: 29.313799\n",
            "Iteration: 00699, Loss: 0.000453, PSRN_gt: 29.354275\n",
            "Iteration: 00700, Loss: 0.000456, PSRN_gt: 29.337392\n",
            "Iteration: 00701, Loss: 0.000451, PSRN_gt: 29.364940\n",
            "Iteration: 00702, Loss: 0.000447, PSRN_gt: 29.395206\n",
            "Iteration: 00703, Loss: 0.000448, PSRN_gt: 29.389671\n",
            "Iteration: 00704, Loss: 0.000443, PSRN_gt: 29.431874\n",
            "Iteration: 00705, Loss: 0.000443, PSRN_gt: 29.424360\n",
            "Iteration: 00706, Loss: 0.000443, PSRN_gt: 29.420286\n",
            "Iteration: 00707, Loss: 0.000439, PSRN_gt: 29.455618\n",
            "Iteration: 00708, Loss: 0.000441, PSRN_gt: 29.428554\n",
            "Iteration: 00709, Loss: 0.000445, PSRN_gt: 29.410490\n",
            "Iteration: 00710, Loss: 0.000449, PSRN_gt: 29.371543\n",
            "Iteration: 00711, Loss: 0.000466, PSRN_gt: 29.249542\n",
            "Iteration: 00712, Loss: 0.000496, PSRN_gt: 29.044091\n",
            "Iteration: 00713, Loss: 0.000547, PSRN_gt: 28.697808\n",
            "Iteration: 00714, Loss: 0.000592, PSRN_gt: 28.429699\n",
            "Iteration: 00715, Loss: 0.000611, PSRN_gt: 28.312041\n",
            "Iteration: 00716, Loss: 0.000569, PSRN_gt: 28.575274\n",
            "Iteration: 00717, Loss: 0.000514, PSRN_gt: 28.924383\n",
            "Iteration: 00718, Loss: 0.000532, PSRN_gt: 28.814945\n",
            "Iteration: 00719, Loss: 0.000559, PSRN_gt: 28.637434\n",
            "Iteration: 00720, Loss: 0.000521, PSRN_gt: 28.889453\n",
            "Iteration: 00721, Loss: 0.000475, PSRN_gt: 29.200224\n",
            "Iteration: 00722, Loss: 0.000493, PSRN_gt: 29.069000\n",
            "Iteration: 00723, Loss: 0.000508, PSRN_gt: 28.973676\n",
            "Iteration: 00724, Loss: 0.000474, PSRN_gt: 29.214361\n",
            "Iteration: 00725, Loss: 0.000465, PSRN_gt: 29.272041\n",
            "Iteration: 00726, Loss: 0.000479, PSRN_gt: 29.175961\n",
            "Iteration: 00727, Loss: 0.000467, PSRN_gt: 29.244566\n",
            "Iteration: 00728, Loss: 0.000456, PSRN_gt: 29.328685\n",
            "Iteration: 00729, Loss: 0.000456, PSRN_gt: 29.337463\n",
            "Iteration: 00730, Loss: 0.000456, PSRN_gt: 29.318790\n",
            "Iteration: 00731, Loss: 0.000453, PSRN_gt: 29.362109\n",
            "Iteration: 00732, Loss: 0.000442, PSRN_gt: 29.426285\n",
            "Iteration: 00733, Loss: 0.000442, PSRN_gt: 29.427995\n",
            "Iteration: 00734, Loss: 0.000444, PSRN_gt: 29.423713\n",
            "Iteration: 00735, Loss: 0.000436, PSRN_gt: 29.471043\n",
            "Iteration: 00736, Loss: 0.000431, PSRN_gt: 29.505851\n",
            "Iteration: 00737, Loss: 0.000435, PSRN_gt: 29.479073\n",
            "Iteration: 00738, Loss: 0.000432, PSRN_gt: 29.503647\n",
            "Iteration: 00739, Loss: 0.000427, PSRN_gt: 29.539998\n",
            "Iteration: 00740, Loss: 0.000425, PSRN_gt: 29.541820\n",
            "Iteration: 00741, Loss: 0.000426, PSRN_gt: 29.549998\n",
            "Iteration: 00742, Loss: 0.000425, PSRN_gt: 29.553164\n",
            "Iteration: 00743, Loss: 0.000424, PSRN_gt: 29.548640\n",
            "Iteration: 00744, Loss: 0.000424, PSRN_gt: 29.553776\n",
            "Iteration: 00745, Loss: 0.000427, PSRN_gt: 29.530685\n",
            "Iteration: 00746, Loss: 0.000437, PSRN_gt: 29.441181\n",
            "Iteration: 00747, Loss: 0.000460, PSRN_gt: 29.290714\n",
            "Iteration: 00748, Loss: 0.000504, PSRN_gt: 28.959985\n",
            "Iteration: 00749, Loss: 0.000594, PSRN_gt: 28.397295\n",
            "Iteration: 00750, Loss: 0.000680, PSRN_gt: 27.912765\n",
            "Iteration: 00751, Loss: 0.000703, PSRN_gt: 27.793512\n",
            "Iteration: 00752, Loss: 0.000549, PSRN_gt: 28.702714\n",
            "Iteration: 00753, Loss: 0.000480, PSRN_gt: 29.138475\n",
            "Iteration: 00754, Loss: 0.000576, PSRN_gt: 28.533924\n",
            "Iteration: 00755, Loss: 0.000570, PSRN_gt: 28.560880\n",
            "Iteration: 00756, Loss: 0.000474, PSRN_gt: 29.176804\n",
            "Iteration: 00757, Loss: 0.000499, PSRN_gt: 29.025631\n",
            "Iteration: 00758, Loss: 0.000531, PSRN_gt: 28.815172\n",
            "Iteration: 00759, Loss: 0.000468, PSRN_gt: 29.239452\n",
            "Iteration: 00760, Loss: 0.000465, PSRN_gt: 29.274693\n",
            "Iteration: 00761, Loss: 0.000497, PSRN_gt: 29.029822\n",
            "Iteration: 00762, Loss: 0.000460, PSRN_gt: 29.303392\n",
            "Iteration: 00763, Loss: 0.000449, PSRN_gt: 29.388681\n",
            "Iteration: 00764, Loss: 0.000470, PSRN_gt: 29.214252\n",
            "Iteration: 00765, Loss: 0.000449, PSRN_gt: 29.377837\n",
            "Iteration: 00766, Loss: 0.000439, PSRN_gt: 29.447550\n",
            "Iteration: 00767, Loss: 0.000449, PSRN_gt: 29.369688\n",
            "Iteration: 00768, Loss: 0.000439, PSRN_gt: 29.460000\n",
            "Iteration: 00769, Loss: 0.000433, PSRN_gt: 29.490757\n",
            "Iteration: 00770, Loss: 0.000432, PSRN_gt: 29.488085\n",
            "Iteration: 00771, Loss: 0.000429, PSRN_gt: 29.532016\n",
            "Iteration: 00772, Loss: 0.000425, PSRN_gt: 29.545429\n",
            "Iteration: 00773, Loss: 0.000422, PSRN_gt: 29.556019\n",
            "Iteration: 00774, Loss: 0.000419, PSRN_gt: 29.600412\n",
            "Iteration: 00775, Loss: 0.000418, PSRN_gt: 29.596212\n",
            "Iteration: 00776, Loss: 0.000416, PSRN_gt: 29.615733\n",
            "Iteration: 00777, Loss: 0.000410, PSRN_gt: 29.665893\n",
            "Iteration: 00778, Loss: 0.000411, PSRN_gt: 29.645846\n",
            "Iteration: 00779, Loss: 0.000411, PSRN_gt: 29.653779\n",
            "Iteration: 00780, Loss: 0.000404, PSRN_gt: 29.695709\n",
            "Iteration: 00781, Loss: 0.000404, PSRN_gt: 29.694747\n",
            "Iteration: 00782, Loss: 0.000405, PSRN_gt: 29.694722\n",
            "Iteration: 00783, Loss: 0.000402, PSRN_gt: 29.706302\n",
            "Iteration: 00784, Loss: 0.000401, PSRN_gt: 29.722507\n",
            "Iteration: 00785, Loss: 0.000403, PSRN_gt: 29.707634\n",
            "Iteration: 00786, Loss: 0.000409, PSRN_gt: 29.647721\n",
            "Iteration: 00787, Loss: 0.000425, PSRN_gt: 29.540474\n",
            "Iteration: 00788, Loss: 0.000464, PSRN_gt: 29.245594\n",
            "Iteration: 00789, Loss: 0.000536, PSRN_gt: 28.764358\n",
            "Iteration: 00790, Loss: 0.000648, PSRN_gt: 28.098786\n",
            "Iteration: 00791, Loss: 0.000650, PSRN_gt: 28.097168\n",
            "Iteration: 00792, Loss: 0.000526, PSRN_gt: 28.821835\n",
            "Iteration: 00793, Loss: 0.000482, PSRN_gt: 29.129495\n",
            "Iteration: 00794, Loss: 0.000560, PSRN_gt: 28.631309\n",
            "Iteration: 00795, Loss: 0.000555, PSRN_gt: 28.662144\n",
            "Iteration: 00796, Loss: 0.000476, PSRN_gt: 29.185975\n",
            "Iteration: 00797, Loss: 0.000521, PSRN_gt: 28.885273\n",
            "Iteration: 00798, Loss: 0.000525, PSRN_gt: 28.845715\n",
            "Iteration: 00799, Loss: 0.000469, PSRN_gt: 29.225079\n",
            "Iteration: 00800, Loss: 0.000500, PSRN_gt: 29.035267\n",
            "Iteration: 00801, Loss: 0.000477, PSRN_gt: 29.181925\n",
            "Iteration: 00802, Loss: 0.000460, PSRN_gt: 29.290607\n",
            "Iteration: 00803, Loss: 0.000478, PSRN_gt: 29.177573\n",
            "Iteration: 00804, Loss: 0.000438, PSRN_gt: 29.468887\n",
            "Iteration: 00805, Loss: 0.000451, PSRN_gt: 29.362799\n",
            "Iteration: 00806, Loss: 0.000451, PSRN_gt: 29.356266\n",
            "Iteration: 00807, Loss: 0.000425, PSRN_gt: 29.557171\n",
            "Iteration: 00808, Loss: 0.000440, PSRN_gt: 29.453957\n",
            "Iteration: 00809, Loss: 0.000426, PSRN_gt: 29.546152\n",
            "Iteration: 00810, Loss: 0.000417, PSRN_gt: 29.606083\n",
            "Iteration: 00811, Loss: 0.000424, PSRN_gt: 29.555918\n",
            "Iteration: 00812, Loss: 0.000413, PSRN_gt: 29.637538\n",
            "Iteration: 00813, Loss: 0.000410, PSRN_gt: 29.655616\n",
            "Iteration: 00814, Loss: 0.000412, PSRN_gt: 29.649851\n",
            "Iteration: 00815, Loss: 0.000404, PSRN_gt: 29.714855\n",
            "Iteration: 00816, Loss: 0.000402, PSRN_gt: 29.717662\n",
            "Iteration: 00817, Loss: 0.000403, PSRN_gt: 29.712248\n",
            "Iteration: 00818, Loss: 0.000396, PSRN_gt: 29.769127\n",
            "Iteration: 00819, Loss: 0.000396, PSRN_gt: 29.764351\n",
            "Iteration: 00820, Loss: 0.000394, PSRN_gt: 29.776301\n",
            "Iteration: 00821, Loss: 0.000390, PSRN_gt: 29.811157\n",
            "Iteration: 00822, Loss: 0.000391, PSRN_gt: 29.805415\n",
            "Iteration: 00823, Loss: 0.000388, PSRN_gt: 29.823094\n",
            "Iteration: 00824, Loss: 0.000386, PSRN_gt: 29.836991\n",
            "Iteration: 00825, Loss: 0.000385, PSRN_gt: 29.842500\n",
            "Iteration: 00826, Loss: 0.000384, PSRN_gt: 29.866561\n",
            "Iteration: 00827, Loss: 0.000382, PSRN_gt: 29.863750\n",
            "Iteration: 00828, Loss: 0.000380, PSRN_gt: 29.878722\n",
            "Iteration: 00829, Loss: 0.000381, PSRN_gt: 29.879648\n",
            "Iteration: 00830, Loss: 0.000380, PSRN_gt: 29.879218\n",
            "Iteration: 00831, Loss: 0.000381, PSRN_gt: 29.872145\n",
            "Iteration: 00832, Loss: 0.000386, PSRN_gt: 29.836557\n",
            "Iteration: 00833, Loss: 0.000395, PSRN_gt: 29.747885\n",
            "Iteration: 00834, Loss: 0.000415, PSRN_gt: 29.600074\n",
            "Iteration: 00835, Loss: 0.000454, PSRN_gt: 29.299578\n",
            "Iteration: 00836, Loss: 0.000506, PSRN_gt: 28.947181\n",
            "Iteration: 00837, Loss: 0.000551, PSRN_gt: 28.631342\n",
            "Iteration: 00838, Loss: 0.000524, PSRN_gt: 28.833906\n",
            "Iteration: 00839, Loss: 0.000448, PSRN_gt: 29.347360\n",
            "Iteration: 00840, Loss: 0.000416, PSRN_gt: 29.599847\n",
            "Iteration: 00841, Loss: 0.000458, PSRN_gt: 29.293358\n",
            "Iteration: 00842, Loss: 0.000482, PSRN_gt: 29.102803\n",
            "Iteration: 00843, Loss: 0.000439, PSRN_gt: 29.434991\n",
            "Iteration: 00844, Loss: 0.000407, PSRN_gt: 29.677623\n",
            "Iteration: 00845, Loss: 0.000435, PSRN_gt: 29.452585\n",
            "Iteration: 00846, Loss: 0.000448, PSRN_gt: 29.368630\n",
            "Iteration: 00847, Loss: 0.000409, PSRN_gt: 29.645406\n",
            "Iteration: 00848, Loss: 0.000395, PSRN_gt: 29.761549\n",
            "Iteration: 00849, Loss: 0.000420, PSRN_gt: 29.570946\n",
            "Iteration: 00850, Loss: 0.000416, PSRN_gt: 29.594032\n",
            "Iteration: 00851, Loss: 0.000390, PSRN_gt: 29.811156\n",
            "Iteration: 00852, Loss: 0.000390, PSRN_gt: 29.801265\n",
            "Iteration: 00853, Loss: 0.000403, PSRN_gt: 29.689695\n",
            "Iteration: 00854, Loss: 0.000392, PSRN_gt: 29.783019\n",
            "Iteration: 00855, Loss: 0.000377, PSRN_gt: 29.902436\n",
            "Iteration: 00856, Loss: 0.000384, PSRN_gt: 29.849140\n",
            "Iteration: 00857, Loss: 0.000390, PSRN_gt: 29.806017\n",
            "Iteration: 00858, Loss: 0.000381, PSRN_gt: 29.863325\n",
            "Iteration: 00859, Loss: 0.000374, PSRN_gt: 29.923689\n",
            "Iteration: 00860, Loss: 0.000378, PSRN_gt: 29.901011\n",
            "Iteration: 00861, Loss: 0.000378, PSRN_gt: 29.881648\n",
            "Iteration: 00862, Loss: 0.000376, PSRN_gt: 29.913892\n",
            "Iteration: 00863, Loss: 0.000372, PSRN_gt: 29.944387\n",
            "Iteration: 00864, Loss: 0.000373, PSRN_gt: 29.930987\n",
            "Iteration: 00865, Loss: 0.000377, PSRN_gt: 29.895280\n",
            "Iteration: 00866, Loss: 0.000382, PSRN_gt: 29.863553\n",
            "Iteration: 00867, Loss: 0.000384, PSRN_gt: 29.833398\n",
            "Iteration: 00868, Loss: 0.000392, PSRN_gt: 29.785593\n",
            "Iteration: 00869, Loss: 0.000402, PSRN_gt: 29.686694\n",
            "Iteration: 00870, Loss: 0.000412, PSRN_gt: 29.621706\n",
            "Iteration: 00871, Loss: 0.000414, PSRN_gt: 29.590867\n",
            "Iteration: 00872, Loss: 0.000409, PSRN_gt: 29.636029\n",
            "Iteration: 00873, Loss: 0.000403, PSRN_gt: 29.689216\n",
            "Iteration: 00874, Loss: 0.000395, PSRN_gt: 29.719691\n",
            "Iteration: 00875, Loss: 0.000397, PSRN_gt: 29.739647\n",
            "Iteration: 00876, Loss: 0.000400, PSRN_gt: 29.698155\n",
            "Iteration: 00877, Loss: 0.000406, PSRN_gt: 29.665509\n",
            "Iteration: 00878, Loss: 0.000399, PSRN_gt: 29.707982\n",
            "Iteration: 00879, Loss: 0.000393, PSRN_gt: 29.753981\n",
            "Iteration: 00880, Loss: 0.000391, PSRN_gt: 29.768513\n",
            "Iteration: 00881, Loss: 0.000397, PSRN_gt: 29.720990\n",
            "Iteration: 00882, Loss: 0.000401, PSRN_gt: 29.703240\n",
            "Iteration: 00883, Loss: 0.000398, PSRN_gt: 29.709170\n",
            "Iteration: 00884, Loss: 0.000399, PSRN_gt: 29.713099\n",
            "Iteration: 00885, Loss: 0.000415, PSRN_gt: 29.584265\n",
            "Iteration: 00886, Loss: 0.000440, PSRN_gt: 29.395308\n",
            "Iteration: 00887, Loss: 0.000459, PSRN_gt: 29.261553\n",
            "Iteration: 00888, Loss: 0.000457, PSRN_gt: 29.262366\n",
            "Iteration: 00889, Loss: 0.000443, PSRN_gt: 29.382022\n",
            "Iteration: 00890, Loss: 0.000418, PSRN_gt: 29.564722\n",
            "Iteration: 00891, Loss: 0.000404, PSRN_gt: 29.688717\n",
            "Iteration: 00892, Loss: 0.000400, PSRN_gt: 29.696165\n",
            "Iteration: 00893, Loss: 0.000404, PSRN_gt: 29.688894\n",
            "Iteration: 00894, Loss: 0.000398, PSRN_gt: 29.741105\n",
            "Iteration: 00895, Loss: 0.000388, PSRN_gt: 29.790949\n",
            "Iteration: 00896, Loss: 0.000384, PSRN_gt: 29.842377\n",
            "Iteration: 00897, Loss: 0.000383, PSRN_gt: 29.862026\n",
            "Iteration: 00898, Loss: 0.000379, PSRN_gt: 29.857615\n",
            "Iteration: 00899, Loss: 0.000375, PSRN_gt: 29.922175\n",
            "Iteration: 00900, Loss: 0.000372, PSRN_gt: 29.936286\n",
            "Iteration: 00901, Loss: 0.000366, PSRN_gt: 29.966603\n",
            "Iteration: 00902, Loss: 0.000363, PSRN_gt: 30.022458\n",
            "Iteration: 00903, Loss: 0.000362, PSRN_gt: 30.002662\n",
            "Iteration: 00904, Loss: 0.000361, PSRN_gt: 30.015552\n",
            "Iteration: 00905, Loss: 0.000361, PSRN_gt: 30.035980\n",
            "Iteration: 00906, Loss: 0.000359, PSRN_gt: 30.027390\n",
            "Iteration: 00907, Loss: 0.000356, PSRN_gt: 30.058998\n",
            "Iteration: 00908, Loss: 0.000355, PSRN_gt: 30.080146\n",
            "Iteration: 00909, Loss: 0.000354, PSRN_gt: 30.066437\n",
            "Iteration: 00910, Loss: 0.000353, PSRN_gt: 30.086779\n",
            "Iteration: 00911, Loss: 0.000356, PSRN_gt: 30.051121\n",
            "Iteration: 00912, Loss: 0.000363, PSRN_gt: 29.992410\n",
            "Iteration: 00913, Loss: 0.000373, PSRN_gt: 29.903209\n",
            "Iteration: 00914, Loss: 0.000390, PSRN_gt: 29.776743\n",
            "Iteration: 00915, Loss: 0.000421, PSRN_gt: 29.507073\n",
            "Iteration: 00916, Loss: 0.000458, PSRN_gt: 29.253268\n",
            "Iteration: 00917, Loss: 0.000491, PSRN_gt: 28.999208\n",
            "Iteration: 00918, Loss: 0.000486, PSRN_gt: 29.059350\n",
            "Iteration: 00919, Loss: 0.000442, PSRN_gt: 29.360736\n",
            "Iteration: 00920, Loss: 0.000408, PSRN_gt: 29.641843\n",
            "Iteration: 00921, Loss: 0.000432, PSRN_gt: 29.464886\n",
            "Iteration: 00922, Loss: 0.000451, PSRN_gt: 29.291262\n",
            "Iteration: 00923, Loss: 0.000424, PSRN_gt: 29.530934\n",
            "Iteration: 00924, Loss: 0.000382, PSRN_gt: 29.838787\n",
            "Iteration: 00925, Loss: 0.000398, PSRN_gt: 29.695963\n",
            "Iteration: 00926, Loss: 0.000422, PSRN_gt: 29.547792\n",
            "Iteration: 00927, Loss: 0.000396, PSRN_gt: 29.733954\n",
            "Iteration: 00928, Loss: 0.000370, PSRN_gt: 29.941151\n",
            "Iteration: 00929, Loss: 0.000383, PSRN_gt: 29.842180\n",
            "Iteration: 00930, Loss: 0.000391, PSRN_gt: 29.762698\n",
            "Iteration: 00931, Loss: 0.000374, PSRN_gt: 29.912643\n",
            "Iteration: 00932, Loss: 0.000363, PSRN_gt: 30.005473\n",
            "Iteration: 00933, Loss: 0.000367, PSRN_gt: 29.952069\n",
            "Iteration: 00934, Loss: 0.000367, PSRN_gt: 29.973759\n",
            "Iteration: 00935, Loss: 0.000358, PSRN_gt: 30.053046\n",
            "Iteration: 00936, Loss: 0.000357, PSRN_gt: 30.042394\n",
            "Iteration: 00937, Loss: 0.000355, PSRN_gt: 30.067077\n",
            "Iteration: 00938, Loss: 0.000352, PSRN_gt: 30.107563\n",
            "Iteration: 00939, Loss: 0.000353, PSRN_gt: 30.076078\n",
            "Iteration: 00940, Loss: 0.000348, PSRN_gt: 30.110351\n",
            "Iteration: 00941, Loss: 0.000343, PSRN_gt: 30.168106\n",
            "Iteration: 00942, Loss: 0.000344, PSRN_gt: 30.156956\n",
            "Iteration: 00943, Loss: 0.000344, PSRN_gt: 30.152021\n",
            "Iteration: 00944, Loss: 0.000343, PSRN_gt: 30.161346\n",
            "Iteration: 00945, Loss: 0.000339, PSRN_gt: 30.194356\n",
            "Iteration: 00946, Loss: 0.000338, PSRN_gt: 30.203511\n",
            "Iteration: 00947, Loss: 0.000339, PSRN_gt: 30.191631\n",
            "Iteration: 00948, Loss: 0.000343, PSRN_gt: 30.161290\n",
            "Iteration: 00949, Loss: 0.000346, PSRN_gt: 30.133058\n",
            "Iteration: 00950, Loss: 0.000354, PSRN_gt: 30.058467\n",
            "Iteration: 00951, Loss: 0.000374, PSRN_gt: 29.898074\n",
            "Iteration: 00952, Loss: 0.000410, PSRN_gt: 29.588331\n",
            "Iteration: 00953, Loss: 0.000466, PSRN_gt: 29.190043\n",
            "Iteration: 00954, Loss: 0.000508, PSRN_gt: 28.894732\n",
            "Iteration: 00955, Loss: 0.000482, PSRN_gt: 29.080480\n",
            "Iteration: 00956, Loss: 0.000403, PSRN_gt: 29.659709\n",
            "Iteration: 00957, Loss: 0.000381, PSRN_gt: 29.846415\n",
            "Iteration: 00958, Loss: 0.000430, PSRN_gt: 29.460595\n",
            "Iteration: 00959, Loss: 0.000438, PSRN_gt: 29.393211\n",
            "Iteration: 00960, Loss: 0.000397, PSRN_gt: 29.720087\n",
            "Iteration: 00961, Loss: 0.000396, PSRN_gt: 29.728978\n",
            "Iteration: 00962, Loss: 0.000412, PSRN_gt: 29.594772\n",
            "Iteration: 00963, Loss: 0.000382, PSRN_gt: 29.856696\n",
            "Iteration: 00964, Loss: 0.000369, PSRN_gt: 29.959805\n",
            "Iteration: 00965, Loss: 0.000384, PSRN_gt: 29.812811\n",
            "Iteration: 00966, Loss: 0.000379, PSRN_gt: 29.870019\n",
            "Iteration: 00967, Loss: 0.000366, PSRN_gt: 29.973998\n",
            "Iteration: 00968, Loss: 0.000370, PSRN_gt: 29.932556\n",
            "Iteration: 00969, Loss: 0.000357, PSRN_gt: 30.044315\n",
            "Iteration: 00970, Loss: 0.000349, PSRN_gt: 30.121479\n",
            "Iteration: 00971, Loss: 0.000352, PSRN_gt: 30.083510\n",
            "Iteration: 00972, Loss: 0.000345, PSRN_gt: 30.141454\n",
            "Iteration: 00973, Loss: 0.000341, PSRN_gt: 30.181773\n",
            "Iteration: 00974, Loss: 0.000345, PSRN_gt: 30.129880\n",
            "Iteration: 00975, Loss: 0.000342, PSRN_gt: 30.175214\n",
            "Iteration: 00976, Loss: 0.000335, PSRN_gt: 30.231880\n",
            "Iteration: 00977, Loss: 0.000336, PSRN_gt: 30.215047\n",
            "Iteration: 00978, Loss: 0.000336, PSRN_gt: 30.223178\n",
            "Iteration: 00979, Loss: 0.000332, PSRN_gt: 30.255479\n",
            "Iteration: 00980, Loss: 0.000329, PSRN_gt: 30.275273\n",
            "Iteration: 00981, Loss: 0.000330, PSRN_gt: 30.268962\n",
            "Iteration: 00982, Loss: 0.000329, PSRN_gt: 30.279690\n",
            "Iteration: 00983, Loss: 0.000327, PSRN_gt: 30.283973\n",
            "Iteration: 00984, Loss: 0.000328, PSRN_gt: 30.287828\n",
            "Iteration: 00985, Loss: 0.000330, PSRN_gt: 30.260650\n",
            "Iteration: 00986, Loss: 0.000333, PSRN_gt: 30.235388\n",
            "Iteration: 00987, Loss: 0.000341, PSRN_gt: 30.164068\n",
            "Iteration: 00988, Loss: 0.000358, PSRN_gt: 30.015131\n",
            "Iteration: 00989, Loss: 0.000392, PSRN_gt: 29.747614\n",
            "Iteration: 00990, Loss: 0.000453, PSRN_gt: 29.248525\n",
            "Iteration: 00991, Loss: 0.000464, PSRN_gt: 29.198748\n",
            "Iteration: 00992, Loss: 0.000468, PSRN_gt: 29.161505\n",
            "Iteration: 00993, Loss: 0.000449, PSRN_gt: 29.325815\n",
            "Iteration: 00994, Loss: 0.000399, PSRN_gt: 29.672261\n",
            "Iteration: 00995, Loss: 0.000375, PSRN_gt: 29.870466\n",
            "Iteration: 00996, Loss: 0.000391, PSRN_gt: 29.764345\n",
            "Iteration: 00997, Loss: 0.000402, PSRN_gt: 29.650309\n",
            "Iteration: 00998, Loss: 0.000378, PSRN_gt: 29.852039\n",
            "Iteration: 00999, Loss: 0.000357, PSRN_gt: 30.036158\n",
            "Iteration: 01000, Loss: 0.000363, PSRN_gt: 29.974052\n",
            "Iteration: 01001, Loss: 0.000370, PSRN_gt: 29.916186\n",
            "Iteration: 01002, Loss: 0.000367, PSRN_gt: 29.954098\n",
            "Iteration: 01003, Loss: 0.000359, PSRN_gt: 30.001318\n",
            "Iteration: 01004, Loss: 0.000357, PSRN_gt: 30.029437\n",
            "Iteration: 01005, Loss: 0.000369, PSRN_gt: 29.926079\n",
            "Iteration: 01006, Loss: 0.000374, PSRN_gt: 29.875003\n",
            "Iteration: 01007, Loss: 0.000375, PSRN_gt: 29.877513\n",
            "Iteration: 01008, Loss: 0.000381, PSRN_gt: 29.822942\n",
            "Iteration: 01009, Loss: 0.000383, PSRN_gt: 29.825274\n",
            "Iteration: 01010, Loss: 0.000374, PSRN_gt: 29.863833\n",
            "Iteration: 01011, Loss: 0.000357, PSRN_gt: 30.040276\n",
            "Iteration: 01012, Loss: 0.000339, PSRN_gt: 30.189474\n",
            "Iteration: 01013, Loss: 0.000334, PSRN_gt: 30.207479\n",
            "Iteration: 01014, Loss: 0.000333, PSRN_gt: 30.254066\n",
            "Iteration: 01015, Loss: 0.000336, PSRN_gt: 30.200841\n",
            "Iteration: 01016, Loss: 0.000339, PSRN_gt: 30.173343\n",
            "Iteration: 01017, Loss: 0.000333, PSRN_gt: 30.234686\n",
            "Iteration: 01018, Loss: 0.000333, PSRN_gt: 30.239908\n",
            "Iteration: 01019, Loss: 0.000332, PSRN_gt: 30.233872\n",
            "Iteration: 01020, Loss: 0.000325, PSRN_gt: 30.308844\n",
            "Iteration: 01021, Loss: 0.000320, PSRN_gt: 30.352382\n",
            "Iteration: 01022, Loss: 0.000320, PSRN_gt: 30.341807\n",
            "Iteration: 01023, Loss: 0.000318, PSRN_gt: 30.367210\n",
            "Iteration: 01024, Loss: 0.000319, PSRN_gt: 30.358294\n",
            "Iteration: 01025, Loss: 0.000320, PSRN_gt: 30.343399\n",
            "Iteration: 01026, Loss: 0.000320, PSRN_gt: 30.345591\n",
            "Iteration: 01027, Loss: 0.000323, PSRN_gt: 30.333963\n",
            "Iteration: 01028, Loss: 0.000329, PSRN_gt: 30.254438\n",
            "Iteration: 01029, Loss: 0.000336, PSRN_gt: 30.193979\n",
            "Iteration: 01030, Loss: 0.000342, PSRN_gt: 30.143952\n",
            "Iteration: 01031, Loss: 0.000350, PSRN_gt: 30.060805\n",
            "Iteration: 01032, Loss: 0.000358, PSRN_gt: 29.995314\n",
            "Iteration: 01033, Loss: 0.000368, PSRN_gt: 29.922704\n",
            "Iteration: 01034, Loss: 0.000368, PSRN_gt: 29.917557\n",
            "Iteration: 01035, Loss: 0.000357, PSRN_gt: 30.001134\n",
            "Iteration: 01036, Loss: 0.000341, PSRN_gt: 30.151675\n",
            "Iteration: 01037, Loss: 0.000334, PSRN_gt: 30.217515\n",
            "Iteration: 01038, Loss: 0.000334, PSRN_gt: 30.214662\n",
            "Iteration: 01039, Loss: 0.000342, PSRN_gt: 30.139348\n",
            "Iteration: 01040, Loss: 0.000350, PSRN_gt: 30.062721\n",
            "Iteration: 01041, Loss: 0.000349, PSRN_gt: 30.089021\n",
            "Iteration: 01042, Loss: 0.000350, PSRN_gt: 30.061942\n",
            "Iteration: 01043, Loss: 0.000351, PSRN_gt: 30.073630\n",
            "Iteration: 01044, Loss: 0.000352, PSRN_gt: 30.060532\n",
            "Iteration: 01045, Loss: 0.000350, PSRN_gt: 30.081383\n",
            "Iteration: 01046, Loss: 0.000350, PSRN_gt: 30.065765\n",
            "Iteration: 01047, Loss: 0.000358, PSRN_gt: 30.022150\n",
            "Iteration: 01048, Loss: 0.000362, PSRN_gt: 29.963674\n",
            "Iteration: 01049, Loss: 0.000351, PSRN_gt: 30.071187\n",
            "Iteration: 01050, Loss: 0.000337, PSRN_gt: 30.175752\n",
            "Iteration: 01051, Loss: 0.000337, PSRN_gt: 30.177377\n",
            "Iteration: 01052, Loss: 0.000351, PSRN_gt: 30.079525\n",
            "Iteration: 01053, Loss: 0.000360, PSRN_gt: 29.963763\n",
            "Iteration: 01054, Loss: 0.000370, PSRN_gt: 29.913944\n",
            "Iteration: 01055, Loss: 0.000373, PSRN_gt: 29.865996\n",
            "Iteration: 01056, Loss: 0.000364, PSRN_gt: 29.946687\n",
            "Iteration: 01057, Loss: 0.000348, PSRN_gt: 30.082706\n",
            "Iteration: 01058, Loss: 0.000349, PSRN_gt: 30.090605\n",
            "Iteration: 01059, Loss: 0.000352, PSRN_gt: 30.054377\n",
            "Iteration: 01060, Loss: 0.000342, PSRN_gt: 30.140455\n",
            "Iteration: 01061, Loss: 0.000330, PSRN_gt: 30.245889\n",
            "Iteration: 01062, Loss: 0.000323, PSRN_gt: 30.302245\n",
            "Iteration: 01063, Loss: 0.000328, PSRN_gt: 30.263266\n",
            "Iteration: 01064, Loss: 0.000330, PSRN_gt: 30.231369\n",
            "Iteration: 01065, Loss: 0.000323, PSRN_gt: 30.318182\n",
            "Iteration: 01066, Loss: 0.000317, PSRN_gt: 30.340247\n",
            "Iteration: 01067, Loss: 0.000314, PSRN_gt: 30.394371\n",
            "Iteration: 01068, Loss: 0.000311, PSRN_gt: 30.424864\n",
            "Iteration: 01069, Loss: 0.000311, PSRN_gt: 30.399760\n",
            "Iteration: 01070, Loss: 0.000310, PSRN_gt: 30.418195\n",
            "Iteration: 01071, Loss: 0.000308, PSRN_gt: 30.438762\n",
            "Iteration: 01072, Loss: 0.000307, PSRN_gt: 30.446641\n",
            "Iteration: 01073, Loss: 0.000306, PSRN_gt: 30.455014\n",
            "Iteration: 01074, Loss: 0.000307, PSRN_gt: 30.451130\n",
            "Iteration: 01075, Loss: 0.000305, PSRN_gt: 30.458064\n",
            "Iteration: 01076, Loss: 0.000306, PSRN_gt: 30.461963\n",
            "Iteration: 01077, Loss: 0.000309, PSRN_gt: 30.419841\n",
            "Iteration: 01078, Loss: 0.000313, PSRN_gt: 30.386658\n",
            "Iteration: 01079, Loss: 0.000317, PSRN_gt: 30.349649\n",
            "Iteration: 01080, Loss: 0.000323, PSRN_gt: 30.288870\n",
            "Iteration: 01081, Loss: 0.000330, PSRN_gt: 30.218043\n",
            "Iteration: 01082, Loss: 0.000341, PSRN_gt: 30.135946\n",
            "Iteration: 01083, Loss: 0.000360, PSRN_gt: 29.947155\n",
            "Iteration: 01084, Loss: 0.000387, PSRN_gt: 29.752900\n",
            "Iteration: 01085, Loss: 0.000422, PSRN_gt: 29.459799\n",
            "Iteration: 01086, Loss: 0.000429, PSRN_gt: 29.428817\n",
            "Iteration: 01087, Loss: 0.000408, PSRN_gt: 29.581315\n",
            "Iteration: 01088, Loss: 0.000370, PSRN_gt: 29.887088\n",
            "Iteration: 01089, Loss: 0.000385, PSRN_gt: 29.787443\n",
            "Iteration: 01090, Loss: 0.000404, PSRN_gt: 29.604217\n",
            "Iteration: 01091, Loss: 0.000376, PSRN_gt: 29.859226\n",
            "Iteration: 01092, Loss: 0.000333, PSRN_gt: 30.222235\n",
            "Iteration: 01093, Loss: 0.000340, PSRN_gt: 30.145207\n",
            "Iteration: 01094, Loss: 0.000362, PSRN_gt: 29.994427\n",
            "Iteration: 01095, Loss: 0.000345, PSRN_gt: 30.099462\n",
            "Iteration: 01096, Loss: 0.000324, PSRN_gt: 30.291900\n",
            "Iteration: 01097, Loss: 0.000326, PSRN_gt: 30.300454\n",
            "Iteration: 01098, Loss: 0.000331, PSRN_gt: 30.228188\n",
            "Iteration: 01099, Loss: 0.000324, PSRN_gt: 30.304711\n",
            "Iteration: 01100, Loss: 0.000312, PSRN_gt: 30.414833\n",
            "Iteration: 01101, Loss: 0.000311, PSRN_gt: 30.413871\n",
            "Iteration: 01102, Loss: 0.000313, PSRN_gt: 30.385917\n",
            "Iteration: 01103, Loss: 0.000303, PSRN_gt: 30.485931\n",
            "Iteration: 01104, Loss: 0.000302, PSRN_gt: 30.497343\n",
            "Iteration: 01105, Loss: 0.000304, PSRN_gt: 30.471892\n",
            "Iteration: 01106, Loss: 0.000299, PSRN_gt: 30.517985\n",
            "Iteration: 01107, Loss: 0.000297, PSRN_gt: 30.544983\n",
            "Iteration: 01108, Loss: 0.000295, PSRN_gt: 30.549428\n",
            "Iteration: 01109, Loss: 0.000292, PSRN_gt: 30.576413\n",
            "Iteration: 01110, Loss: 0.000292, PSRN_gt: 30.587437\n",
            "Iteration: 01111, Loss: 0.000291, PSRN_gt: 30.598491\n",
            "Iteration: 01112, Loss: 0.000290, PSRN_gt: 30.600141\n",
            "Iteration: 01113, Loss: 0.000288, PSRN_gt: 30.610530\n",
            "Iteration: 01114, Loss: 0.000288, PSRN_gt: 30.619232\n",
            "Iteration: 01115, Loss: 0.000289, PSRN_gt: 30.594864\n",
            "Iteration: 01116, Loss: 0.000291, PSRN_gt: 30.581687\n",
            "Iteration: 01117, Loss: 0.000295, PSRN_gt: 30.552625\n",
            "Iteration: 01118, Loss: 0.000305, PSRN_gt: 30.446581\n",
            "Iteration: 01119, Loss: 0.000324, PSRN_gt: 30.282680\n",
            "Iteration: 01120, Loss: 0.000348, PSRN_gt: 30.072140\n",
            "Iteration: 01121, Loss: 0.000384, PSRN_gt: 29.740132\n",
            "Iteration: 01122, Loss: 0.000415, PSRN_gt: 29.542363\n",
            "Iteration: 01123, Loss: 0.000419, PSRN_gt: 29.450297\n",
            "Iteration: 01124, Loss: 0.000388, PSRN_gt: 29.753110\n",
            "Iteration: 01125, Loss: 0.000363, PSRN_gt: 29.926780\n",
            "Iteration: 01126, Loss: 0.000405, PSRN_gt: 29.592333\n",
            "Iteration: 01127, Loss: 0.000438, PSRN_gt: 29.369072\n",
            "Iteration: 01128, Loss: 0.000397, PSRN_gt: 29.654554\n",
            "Iteration: 01129, Loss: 0.000338, PSRN_gt: 30.164288\n",
            "Iteration: 01130, Loss: 0.000348, PSRN_gt: 30.105166\n",
            "Iteration: 01131, Loss: 0.000366, PSRN_gt: 29.911338\n",
            "Iteration: 01132, Loss: 0.000342, PSRN_gt: 30.131791\n",
            "Iteration: 01133, Loss: 0.000331, PSRN_gt: 30.237633\n",
            "Iteration: 01134, Loss: 0.000343, PSRN_gt: 30.104962\n",
            "Iteration: 01135, Loss: 0.000330, PSRN_gt: 30.237524\n",
            "Iteration: 01136, Loss: 0.000321, PSRN_gt: 30.328476\n",
            "Iteration: 01137, Loss: 0.000322, PSRN_gt: 30.296892\n",
            "Iteration: 01138, Loss: 0.000316, PSRN_gt: 30.356108\n",
            "Iteration: 01139, Loss: 0.000307, PSRN_gt: 30.437985\n",
            "Iteration: 01140, Loss: 0.000305, PSRN_gt: 30.445371\n",
            "Iteration: 01141, Loss: 0.000303, PSRN_gt: 30.471144\n",
            "Iteration: 01142, Loss: 0.000299, PSRN_gt: 30.508236\n",
            "Iteration: 01143, Loss: 0.000297, PSRN_gt: 30.537824\n",
            "Iteration: 01144, Loss: 0.000294, PSRN_gt: 30.557230\n",
            "Iteration: 01145, Loss: 0.000292, PSRN_gt: 30.562396\n",
            "Iteration: 01146, Loss: 0.000291, PSRN_gt: 30.583444\n",
            "Iteration: 01147, Loss: 0.000289, PSRN_gt: 30.604286\n",
            "Iteration: 01148, Loss: 0.000289, PSRN_gt: 30.589181\n",
            "Iteration: 01149, Loss: 0.000288, PSRN_gt: 30.606780\n",
            "Iteration: 01150, Loss: 0.000289, PSRN_gt: 30.601373\n",
            "Iteration: 01151, Loss: 0.000295, PSRN_gt: 30.528728\n",
            "Iteration: 01152, Loss: 0.000301, PSRN_gt: 30.480795\n",
            "Iteration: 01153, Loss: 0.000314, PSRN_gt: 30.359098\n",
            "Iteration: 01154, Loss: 0.000339, PSRN_gt: 30.128765\n",
            "Iteration: 01155, Loss: 0.000369, PSRN_gt: 29.876808\n",
            "Iteration: 01156, Loss: 0.000389, PSRN_gt: 29.698617\n",
            "Iteration: 01157, Loss: 0.000395, PSRN_gt: 29.663360\n",
            "Iteration: 01158, Loss: 0.000361, PSRN_gt: 29.934391\n",
            "Iteration: 01159, Loss: 0.000325, PSRN_gt: 30.276455\n",
            "Iteration: 01160, Loss: 0.000325, PSRN_gt: 30.254335\n",
            "Iteration: 01161, Loss: 0.000356, PSRN_gt: 30.009674\n",
            "Iteration: 01162, Loss: 0.000370, PSRN_gt: 29.861547\n",
            "Iteration: 01163, Loss: 0.000337, PSRN_gt: 30.150229\n",
            "Iteration: 01164, Loss: 0.000307, PSRN_gt: 30.440313\n",
            "Iteration: 01165, Loss: 0.000306, PSRN_gt: 30.431400\n",
            "Iteration: 01166, Loss: 0.000317, PSRN_gt: 30.346218\n",
            "Iteration: 01167, Loss: 0.000316, PSRN_gt: 30.336993\n",
            "Iteration: 01168, Loss: 0.000304, PSRN_gt: 30.456615\n",
            "Iteration: 01169, Loss: 0.000295, PSRN_gt: 30.541290\n",
            "Iteration: 01170, Loss: 0.000298, PSRN_gt: 30.512200\n",
            "Iteration: 01171, Loss: 0.000301, PSRN_gt: 30.485572\n",
            "Iteration: 01172, Loss: 0.000294, PSRN_gt: 30.539996\n",
            "Iteration: 01173, Loss: 0.000288, PSRN_gt: 30.613353\n",
            "Iteration: 01174, Loss: 0.000284, PSRN_gt: 30.634834\n",
            "Iteration: 01175, Loss: 0.000283, PSRN_gt: 30.650523\n",
            "Iteration: 01176, Loss: 0.000284, PSRN_gt: 30.650728\n",
            "Iteration: 01177, Loss: 0.000283, PSRN_gt: 30.645169\n",
            "Iteration: 01178, Loss: 0.000278, PSRN_gt: 30.707718\n",
            "Iteration: 01179, Loss: 0.000275, PSRN_gt: 30.725779\n",
            "Iteration: 01180, Loss: 0.000277, PSRN_gt: 30.701916\n",
            "Iteration: 01181, Loss: 0.000276, PSRN_gt: 30.717350\n",
            "Iteration: 01182, Loss: 0.000274, PSRN_gt: 30.724981\n",
            "Iteration: 01183, Loss: 0.000274, PSRN_gt: 30.741448\n",
            "Iteration: 01184, Loss: 0.000273, PSRN_gt: 30.736700\n",
            "Iteration: 01185, Loss: 0.000274, PSRN_gt: 30.735193\n",
            "Iteration: 01186, Loss: 0.000279, PSRN_gt: 30.684703\n",
            "Iteration: 01187, Loss: 0.000289, PSRN_gt: 30.582405\n",
            "Iteration: 01188, Loss: 0.000302, PSRN_gt: 30.453677\n",
            "Iteration: 01189, Loss: 0.000324, PSRN_gt: 30.264148\n",
            "Iteration: 01190, Loss: 0.000358, PSRN_gt: 29.953365\n",
            "Iteration: 01191, Loss: 0.000393, PSRN_gt: 29.688504\n",
            "Iteration: 01192, Loss: 0.000409, PSRN_gt: 29.532950\n",
            "Iteration: 01193, Loss: 0.000372, PSRN_gt: 29.846232\n",
            "Iteration: 01194, Loss: 0.000331, PSRN_gt: 30.193471\n",
            "Iteration: 01195, Loss: 0.000333, PSRN_gt: 30.184588\n",
            "Iteration: 01196, Loss: 0.000372, PSRN_gt: 29.871511\n",
            "Iteration: 01197, Loss: 0.000378, PSRN_gt: 29.798790\n",
            "Iteration: 01198, Loss: 0.000338, PSRN_gt: 30.151371\n",
            "Iteration: 01199, Loss: 0.000302, PSRN_gt: 30.468821\n",
            "Iteration: 01200, Loss: 0.000313, PSRN_gt: 30.368691\n",
            "Iteration: 01201, Loss: 0.000323, PSRN_gt: 30.277248\n",
            "Iteration: 01202, Loss: 0.000304, PSRN_gt: 30.447612\n",
            "Iteration: 01203, Loss: 0.000294, PSRN_gt: 30.551017\n",
            "Iteration: 01204, Loss: 0.000300, PSRN_gt: 30.475985\n",
            "Iteration: 01205, Loss: 0.000300, PSRN_gt: 30.508692\n",
            "Iteration: 01206, Loss: 0.000288, PSRN_gt: 30.602179\n",
            "Iteration: 01207, Loss: 0.000282, PSRN_gt: 30.660186\n",
            "Iteration: 01208, Loss: 0.000286, PSRN_gt: 30.623906\n",
            "Iteration: 01209, Loss: 0.000287, PSRN_gt: 30.603489\n",
            "Iteration: 01210, Loss: 0.000279, PSRN_gt: 30.692670\n",
            "Iteration: 01211, Loss: 0.000276, PSRN_gt: 30.717299\n",
            "Iteration: 01212, Loss: 0.000278, PSRN_gt: 30.691523\n",
            "Iteration: 01213, Loss: 0.000274, PSRN_gt: 30.731117\n",
            "Iteration: 01214, Loss: 0.000272, PSRN_gt: 30.755326\n",
            "Iteration: 01215, Loss: 0.000271, PSRN_gt: 30.752416\n",
            "Iteration: 01216, Loss: 0.000268, PSRN_gt: 30.796310\n",
            "Iteration: 01217, Loss: 0.000267, PSRN_gt: 30.792071\n",
            "Iteration: 01218, Loss: 0.000267, PSRN_gt: 30.795954\n",
            "Iteration: 01219, Loss: 0.000265, PSRN_gt: 30.817653\n",
            "Iteration: 01220, Loss: 0.000264, PSRN_gt: 30.825629\n",
            "Iteration: 01221, Loss: 0.000264, PSRN_gt: 30.819192\n",
            "Iteration: 01222, Loss: 0.000265, PSRN_gt: 30.818779\n",
            "Iteration: 01223, Loss: 0.000267, PSRN_gt: 30.779209\n",
            "Iteration: 01224, Loss: 0.000272, PSRN_gt: 30.744061\n",
            "Iteration: 01225, Loss: 0.000279, PSRN_gt: 30.666253\n",
            "Iteration: 01226, Loss: 0.000291, PSRN_gt: 30.563584\n",
            "Iteration: 01227, Loss: 0.000309, PSRN_gt: 30.366487\n",
            "Iteration: 01228, Loss: 0.000333, PSRN_gt: 30.177836\n",
            "Iteration: 01229, Loss: 0.000352, PSRN_gt: 29.994864\n",
            "Iteration: 01230, Loss: 0.000369, PSRN_gt: 29.839836\n",
            "Iteration: 01231, Loss: 0.000374, PSRN_gt: 29.831173\n",
            "Iteration: 01232, Loss: 0.000373, PSRN_gt: 29.796465\n",
            "Iteration: 01233, Loss: 0.000368, PSRN_gt: 29.886937\n",
            "Iteration: 01234, Loss: 0.000355, PSRN_gt: 29.969366\n",
            "Iteration: 01235, Loss: 0.000340, PSRN_gt: 30.119260\n",
            "Iteration: 01236, Loss: 0.000325, PSRN_gt: 30.263098\n",
            "Iteration: 01237, Loss: 0.000331, PSRN_gt: 30.175239\n",
            "Iteration: 01238, Loss: 0.000332, PSRN_gt: 30.210358\n",
            "Iteration: 01239, Loss: 0.000313, PSRN_gt: 30.368686\n",
            "Iteration: 01240, Loss: 0.000303, PSRN_gt: 30.444991\n",
            "Iteration: 01241, Loss: 0.000309, PSRN_gt: 30.401622\n",
            "Iteration: 01242, Loss: 0.000305, PSRN_gt: 30.420017\n",
            "Iteration: 01243, Loss: 0.000291, PSRN_gt: 30.564999\n",
            "Iteration: 01244, Loss: 0.000288, PSRN_gt: 30.598697\n",
            "Iteration: 01245, Loss: 0.000289, PSRN_gt: 30.564676\n",
            "Iteration: 01246, Loss: 0.000283, PSRN_gt: 30.653227\n",
            "Iteration: 01247, Loss: 0.000279, PSRN_gt: 30.683385\n",
            "Iteration: 01248, Loss: 0.000276, PSRN_gt: 30.699484\n",
            "Iteration: 01249, Loss: 0.000274, PSRN_gt: 30.749582\n",
            "Iteration: 01250, Loss: 0.000271, PSRN_gt: 30.743331\n",
            "Iteration: 01251, Loss: 0.000270, PSRN_gt: 30.765225\n",
            "Iteration: 01252, Loss: 0.000268, PSRN_gt: 30.789912\n",
            "Iteration: 01253, Loss: 0.000265, PSRN_gt: 30.810872\n",
            "Iteration: 01254, Loss: 0.000263, PSRN_gt: 30.826666\n",
            "Iteration: 01255, Loss: 0.000264, PSRN_gt: 30.824417\n",
            "Iteration: 01256, Loss: 0.000263, PSRN_gt: 30.819564\n",
            "Iteration: 01257, Loss: 0.000261, PSRN_gt: 30.854262\n",
            "Iteration: 01258, Loss: 0.000264, PSRN_gt: 30.812283\n",
            "Iteration: 01259, Loss: 0.000271, PSRN_gt: 30.745859\n",
            "Iteration: 01260, Loss: 0.000280, PSRN_gt: 30.641526\n",
            "Iteration: 01261, Loss: 0.000297, PSRN_gt: 30.491741\n",
            "Iteration: 01262, Loss: 0.000322, PSRN_gt: 30.234632\n",
            "Iteration: 01263, Loss: 0.000357, PSRN_gt: 29.960233\n",
            "Iteration: 01264, Loss: 0.000371, PSRN_gt: 29.827587\n",
            "Iteration: 01265, Loss: 0.000363, PSRN_gt: 29.898110\n",
            "Iteration: 01266, Loss: 0.000322, PSRN_gt: 30.261238\n",
            "Iteration: 01267, Loss: 0.000292, PSRN_gt: 30.544379\n",
            "Iteration: 01268, Loss: 0.000295, PSRN_gt: 30.514935\n",
            "Iteration: 01269, Loss: 0.000308, PSRN_gt: 30.392700\n",
            "Iteration: 01270, Loss: 0.000303, PSRN_gt: 30.438001\n",
            "Iteration: 01271, Loss: 0.000285, PSRN_gt: 30.604645\n",
            "Iteration: 01272, Loss: 0.000278, PSRN_gt: 30.683712\n",
            "Iteration: 01273, Loss: 0.000283, PSRN_gt: 30.630946\n",
            "Iteration: 01274, Loss: 0.000285, PSRN_gt: 30.611149\n",
            "Iteration: 01275, Loss: 0.000274, PSRN_gt: 30.716457\n",
            "Iteration: 01276, Loss: 0.000264, PSRN_gt: 30.813935\n",
            "Iteration: 01277, Loss: 0.000268, PSRN_gt: 30.788902\n",
            "Iteration: 01278, Loss: 0.000273, PSRN_gt: 30.729412\n",
            "Iteration: 01279, Loss: 0.000268, PSRN_gt: 30.772851\n",
            "Iteration: 01280, Loss: 0.000260, PSRN_gt: 30.868041\n",
            "Iteration: 01281, Loss: 0.000256, PSRN_gt: 30.894462\n",
            "Iteration: 01282, Loss: 0.000260, PSRN_gt: 30.858279\n",
            "Iteration: 01283, Loss: 0.000262, PSRN_gt: 30.834848\n",
            "Iteration: 01284, Loss: 0.000259, PSRN_gt: 30.869379\n",
            "Iteration: 01285, Loss: 0.000252, PSRN_gt: 30.928995\n",
            "Iteration: 01286, Loss: 0.000251, PSRN_gt: 30.943271\n",
            "Iteration: 01287, Loss: 0.000255, PSRN_gt: 30.891354\n",
            "Iteration: 01288, Loss: 0.000257, PSRN_gt: 30.881007\n",
            "Iteration: 01289, Loss: 0.000257, PSRN_gt: 30.870401\n",
            "Iteration: 01290, Loss: 0.000260, PSRN_gt: 30.860445\n",
            "Iteration: 01291, Loss: 0.000266, PSRN_gt: 30.775954\n",
            "Iteration: 01292, Loss: 0.000277, PSRN_gt: 30.694508\n",
            "Iteration: 01293, Loss: 0.000284, PSRN_gt: 30.591044\n",
            "Iteration: 01294, Loss: 0.000294, PSRN_gt: 30.532632\n",
            "Iteration: 01295, Loss: 0.000294, PSRN_gt: 30.494437\n",
            "Iteration: 01296, Loss: 0.000288, PSRN_gt: 30.575411\n",
            "Iteration: 01297, Loss: 0.000283, PSRN_gt: 30.601570\n",
            "Iteration: 01298, Loss: 0.000291, PSRN_gt: 30.544070\n",
            "Iteration: 01299, Loss: 0.000310, PSRN_gt: 30.386110\n",
            "Iteration: 01300, Loss: 0.000320, PSRN_gt: 30.269188\n",
            "Iteration: 01301, Loss: 0.000325, PSRN_gt: 30.237318\n",
            "Iteration: 01302, Loss: 0.000324, PSRN_gt: 30.240123\n",
            "Iteration: 01303, Loss: 0.000329, PSRN_gt: 30.180698\n",
            "Iteration: 01304, Loss: 0.000328, PSRN_gt: 30.217928\n",
            "Iteration: 01305, Loss: 0.000314, PSRN_gt: 30.302346\n",
            "Iteration: 01306, Loss: 0.000308, PSRN_gt: 30.405026\n",
            "Iteration: 01307, Loss: 0.000301, PSRN_gt: 30.456131\n",
            "Iteration: 01308, Loss: 0.000291, PSRN_gt: 30.540422\n",
            "Iteration: 01309, Loss: 0.000284, PSRN_gt: 30.611866\n",
            "Iteration: 01310, Loss: 0.000283, PSRN_gt: 30.629958\n",
            "Iteration: 01311, Loss: 0.000275, PSRN_gt: 30.706942\n",
            "Iteration: 01312, Loss: 0.000269, PSRN_gt: 30.748895\n",
            "Iteration: 01313, Loss: 0.000273, PSRN_gt: 30.736433\n",
            "Iteration: 01314, Loss: 0.000273, PSRN_gt: 30.718775\n",
            "Iteration: 01315, Loss: 0.000265, PSRN_gt: 30.793361\n",
            "Iteration: 01316, Loss: 0.000261, PSRN_gt: 30.858771\n",
            "Iteration: 01317, Loss: 0.000260, PSRN_gt: 30.854809\n",
            "Iteration: 01318, Loss: 0.000255, PSRN_gt: 30.889916\n",
            "Iteration: 01319, Loss: 0.000254, PSRN_gt: 30.916729\n",
            "Iteration: 01320, Loss: 0.000255, PSRN_gt: 30.899178\n",
            "Iteration: 01321, Loss: 0.000250, PSRN_gt: 30.963406\n",
            "Iteration: 01322, Loss: 0.000247, PSRN_gt: 30.975010\n",
            "Iteration: 01323, Loss: 0.000248, PSRN_gt: 30.959975\n",
            "Iteration: 01324, Loss: 0.000246, PSRN_gt: 30.989661\n",
            "Iteration: 01325, Loss: 0.000242, PSRN_gt: 31.019655\n",
            "Iteration: 01326, Loss: 0.000242, PSRN_gt: 31.031017\n",
            "Iteration: 01327, Loss: 0.000243, PSRN_gt: 31.014384\n",
            "Iteration: 01328, Loss: 0.000243, PSRN_gt: 31.008774\n",
            "Iteration: 01329, Loss: 0.000246, PSRN_gt: 30.983080\n",
            "Iteration: 01330, Loss: 0.000253, PSRN_gt: 30.897934\n",
            "Iteration: 01331, Loss: 0.000265, PSRN_gt: 30.771698\n",
            "Iteration: 01332, Loss: 0.000290, PSRN_gt: 30.538733\n",
            "Iteration: 01333, Loss: 0.000338, PSRN_gt: 30.072073\n",
            "Iteration: 01334, Loss: 0.000397, PSRN_gt: 29.611788\n",
            "Iteration: 01335, Loss: 0.000462, PSRN_gt: 29.094755\n",
            "Iteration: 01336, Loss: 0.000423, PSRN_gt: 29.412250\n",
            "Iteration: 01337, Loss: 0.000321, PSRN_gt: 30.245718\n",
            "Iteration: 01338, Loss: 0.000284, PSRN_gt: 30.599296\n",
            "Iteration: 01339, Loss: 0.000347, PSRN_gt: 30.051363\n",
            "Iteration: 01340, Loss: 0.000367, PSRN_gt: 29.844357\n",
            "Iteration: 01341, Loss: 0.000294, PSRN_gt: 30.531776\n",
            "Iteration: 01342, Loss: 0.000283, PSRN_gt: 30.630357\n",
            "Iteration: 01343, Loss: 0.000327, PSRN_gt: 30.205333\n",
            "Iteration: 01344, Loss: 0.000305, PSRN_gt: 30.432861\n",
            "Iteration: 01345, Loss: 0.000271, PSRN_gt: 30.752454\n",
            "Iteration: 01346, Loss: 0.000294, PSRN_gt: 30.515701\n",
            "Iteration: 01347, Loss: 0.000294, PSRN_gt: 30.530935\n",
            "Iteration: 01348, Loss: 0.000266, PSRN_gt: 30.810983\n",
            "Iteration: 01349, Loss: 0.000273, PSRN_gt: 30.720215\n",
            "Iteration: 01350, Loss: 0.000278, PSRN_gt: 30.679668\n",
            "Iteration: 01351, Loss: 0.000260, PSRN_gt: 30.851281\n",
            "Iteration: 01352, Loss: 0.000258, PSRN_gt: 30.868016\n",
            "Iteration: 01353, Loss: 0.000265, PSRN_gt: 30.795420\n",
            "Iteration: 01354, Loss: 0.000255, PSRN_gt: 30.900632\n",
            "Iteration: 01355, Loss: 0.000250, PSRN_gt: 30.956981\n",
            "Iteration: 01356, Loss: 0.000255, PSRN_gt: 30.891199\n",
            "Iteration: 01357, Loss: 0.000250, PSRN_gt: 30.951321\n",
            "Iteration: 01358, Loss: 0.000245, PSRN_gt: 31.003265\n",
            "Iteration: 01359, Loss: 0.000247, PSRN_gt: 30.968107\n",
            "Iteration: 01360, Loss: 0.000244, PSRN_gt: 31.016572\n",
            "Iteration: 01361, Loss: 0.000241, PSRN_gt: 31.051543\n",
            "Iteration: 01362, Loss: 0.000241, PSRN_gt: 31.032002\n",
            "Iteration: 01363, Loss: 0.000239, PSRN_gt: 31.061856\n",
            "Iteration: 01364, Loss: 0.000238, PSRN_gt: 31.071610\n",
            "Iteration: 01365, Loss: 0.000239, PSRN_gt: 31.049894\n",
            "Iteration: 01366, Loss: 0.000239, PSRN_gt: 31.068334\n",
            "Iteration: 01367, Loss: 0.000242, PSRN_gt: 31.026927\n",
            "Iteration: 01368, Loss: 0.000246, PSRN_gt: 30.972980\n",
            "Iteration: 01369, Loss: 0.000252, PSRN_gt: 30.932703\n",
            "Iteration: 01370, Loss: 0.000260, PSRN_gt: 30.819520\n",
            "Iteration: 01371, Loss: 0.000267, PSRN_gt: 30.773984\n",
            "Iteration: 01372, Loss: 0.000268, PSRN_gt: 30.729560\n",
            "Iteration: 01373, Loss: 0.000268, PSRN_gt: 30.760672\n",
            "Iteration: 01374, Loss: 0.000266, PSRN_gt: 30.744047\n",
            "Iteration: 01375, Loss: 0.000268, PSRN_gt: 30.762333\n",
            "Iteration: 01376, Loss: 0.000274, PSRN_gt: 30.674271\n",
            "Iteration: 01377, Loss: 0.000280, PSRN_gt: 30.657819\n",
            "Iteration: 01378, Loss: 0.000281, PSRN_gt: 30.605145\n",
            "Iteration: 01379, Loss: 0.000275, PSRN_gt: 30.697086\n",
            "Iteration: 01380, Loss: 0.000269, PSRN_gt: 30.720221\n",
            "Iteration: 01381, Loss: 0.000265, PSRN_gt: 30.776654\n",
            "Iteration: 01382, Loss: 0.000261, PSRN_gt: 30.822511\n",
            "Iteration: 01383, Loss: 0.000257, PSRN_gt: 30.850733\n",
            "Iteration: 01384, Loss: 0.000254, PSRN_gt: 30.898115\n",
            "Iteration: 01385, Loss: 0.000255, PSRN_gt: 30.886871\n",
            "Iteration: 01386, Loss: 0.000255, PSRN_gt: 30.876919\n",
            "Iteration: 01387, Loss: 0.000258, PSRN_gt: 30.867030\n",
            "Iteration: 01388, Loss: 0.000259, PSRN_gt: 30.826369\n",
            "Iteration: 01389, Loss: 0.000257, PSRN_gt: 30.873342\n",
            "Iteration: 01390, Loss: 0.000252, PSRN_gt: 30.890543\n",
            "Iteration: 01391, Loss: 0.000257, PSRN_gt: 30.853247\n",
            "Iteration: 01392, Loss: 0.000271, PSRN_gt: 30.723583\n",
            "Iteration: 01393, Loss: 0.000283, PSRN_gt: 30.601323\n",
            "Iteration: 01394, Loss: 0.000300, PSRN_gt: 30.434375\n",
            "Iteration: 01395, Loss: 0.000319, PSRN_gt: 30.239490\n",
            "Iteration: 01396, Loss: 0.000333, PSRN_gt: 30.119869\n",
            "Iteration: 01397, Loss: 0.000336, PSRN_gt: 30.119987\n",
            "Iteration: 01398, Loss: 0.000310, PSRN_gt: 30.315343\n",
            "Iteration: 01399, Loss: 0.000297, PSRN_gt: 30.500213\n",
            "Iteration: 01400, Loss: 0.000288, PSRN_gt: 30.541981\n",
            "Iteration: 01401, Loss: 0.000284, PSRN_gt: 30.601395\n",
            "Iteration: 01402, Loss: 0.000280, PSRN_gt: 30.665713\n",
            "Iteration: 01403, Loss: 0.000279, PSRN_gt: 30.621991\n",
            "Iteration: 01404, Loss: 0.000277, PSRN_gt: 30.694404\n",
            "Iteration: 01405, Loss: 0.000266, PSRN_gt: 30.771784\n",
            "Iteration: 01406, Loss: 0.000259, PSRN_gt: 30.860932\n",
            "Iteration: 01407, Loss: 0.000256, PSRN_gt: 30.890181\n",
            "Iteration: 01408, Loss: 0.000257, PSRN_gt: 30.870906\n",
            "Iteration: 01409, Loss: 0.000253, PSRN_gt: 30.914882\n",
            "Iteration: 01410, Loss: 0.000248, PSRN_gt: 30.958191\n",
            "Iteration: 01411, Loss: 0.000245, PSRN_gt: 30.995670\n",
            "Iteration: 01412, Loss: 0.000242, PSRN_gt: 31.024399\n",
            "Iteration: 01413, Loss: 0.000242, PSRN_gt: 31.027340\n",
            "Iteration: 01414, Loss: 0.000239, PSRN_gt: 31.056205\n",
            "Iteration: 01415, Loss: 0.000235, PSRN_gt: 31.088771\n",
            "Iteration: 01416, Loss: 0.000235, PSRN_gt: 31.100676\n",
            "Iteration: 01417, Loss: 0.000234, PSRN_gt: 31.104257\n",
            "Iteration: 01418, Loss: 0.000232, PSRN_gt: 31.119664\n",
            "Iteration: 01419, Loss: 0.000230, PSRN_gt: 31.158790\n",
            "Iteration: 01420, Loss: 0.000230, PSRN_gt: 31.135855\n",
            "Iteration: 01421, Loss: 0.000228, PSRN_gt: 31.162203\n",
            "Iteration: 01422, Loss: 0.000229, PSRN_gt: 31.149088\n",
            "Iteration: 01423, Loss: 0.000231, PSRN_gt: 31.126713\n",
            "Iteration: 01424, Loss: 0.000232, PSRN_gt: 31.109186\n",
            "Iteration: 01425, Loss: 0.000236, PSRN_gt: 31.083972\n",
            "Iteration: 01426, Loss: 0.000243, PSRN_gt: 30.987569\n",
            "Iteration: 01427, Loss: 0.000254, PSRN_gt: 30.891484\n",
            "Iteration: 01428, Loss: 0.000272, PSRN_gt: 30.676043\n",
            "Iteration: 01429, Loss: 0.000292, PSRN_gt: 30.527819\n",
            "Iteration: 01430, Loss: 0.000308, PSRN_gt: 30.324092\n",
            "Iteration: 01431, Loss: 0.000307, PSRN_gt: 30.380687\n",
            "Iteration: 01432, Loss: 0.000291, PSRN_gt: 30.479288\n",
            "Iteration: 01433, Loss: 0.000279, PSRN_gt: 30.635966\n",
            "Iteration: 01434, Loss: 0.000285, PSRN_gt: 30.568959\n",
            "Iteration: 01435, Loss: 0.000303, PSRN_gt: 30.392571\n",
            "Iteration: 01436, Loss: 0.000299, PSRN_gt: 30.456649\n",
            "Iteration: 01437, Loss: 0.000273, PSRN_gt: 30.685463\n",
            "Iteration: 01438, Loss: 0.000258, PSRN_gt: 30.841128\n",
            "Iteration: 01439, Loss: 0.000271, PSRN_gt: 30.733376\n",
            "Iteration: 01440, Loss: 0.000275, PSRN_gt: 30.661509\n",
            "Iteration: 01441, Loss: 0.000258, PSRN_gt: 30.855214\n",
            "Iteration: 01442, Loss: 0.000242, PSRN_gt: 31.021880\n",
            "Iteration: 01443, Loss: 0.000246, PSRN_gt: 30.960315\n",
            "Iteration: 01444, Loss: 0.000253, PSRN_gt: 30.901186\n",
            "Iteration: 01445, Loss: 0.000243, PSRN_gt: 31.002936\n",
            "Iteration: 01446, Loss: 0.000236, PSRN_gt: 31.072214\n",
            "Iteration: 01447, Loss: 0.000240, PSRN_gt: 31.029255\n",
            "Iteration: 01448, Loss: 0.000241, PSRN_gt: 31.024505\n",
            "Iteration: 01449, Loss: 0.000233, PSRN_gt: 31.101726\n",
            "Iteration: 01450, Loss: 0.000228, PSRN_gt: 31.163521\n",
            "Iteration: 01451, Loss: 0.000230, PSRN_gt: 31.130351\n",
            "Iteration: 01452, Loss: 0.000229, PSRN_gt: 31.141296\n",
            "Iteration: 01453, Loss: 0.000225, PSRN_gt: 31.191381\n",
            "Iteration: 01454, Loss: 0.000224, PSRN_gt: 31.203851\n",
            "Iteration: 01455, Loss: 0.000224, PSRN_gt: 31.194263\n",
            "Iteration: 01456, Loss: 0.000223, PSRN_gt: 31.213016\n",
            "Iteration: 01457, Loss: 0.000222, PSRN_gt: 31.226917\n",
            "Iteration: 01458, Loss: 0.000222, PSRN_gt: 31.204616\n",
            "Iteration: 01459, Loss: 0.000223, PSRN_gt: 31.201672\n",
            "Iteration: 01460, Loss: 0.000228, PSRN_gt: 31.165948\n",
            "Iteration: 01461, Loss: 0.000238, PSRN_gt: 31.025135\n",
            "Iteration: 01462, Loss: 0.000259, PSRN_gt: 30.834969\n",
            "Iteration: 01463, Loss: 0.000289, PSRN_gt: 30.516572\n",
            "Iteration: 01464, Loss: 0.000332, PSRN_gt: 30.141182\n",
            "Iteration: 01465, Loss: 0.000346, PSRN_gt: 29.992795\n",
            "Iteration: 01466, Loss: 0.000328, PSRN_gt: 30.171781\n",
            "Iteration: 01467, Loss: 0.000287, PSRN_gt: 30.553659\n",
            "Iteration: 01468, Loss: 0.000297, PSRN_gt: 30.446774\n",
            "Iteration: 01469, Loss: 0.000342, PSRN_gt: 30.079772\n",
            "Iteration: 01470, Loss: 0.000340, PSRN_gt: 30.064514\n",
            "Iteration: 01471, Loss: 0.000294, PSRN_gt: 30.493163\n",
            "Iteration: 01472, Loss: 0.000285, PSRN_gt: 30.583683\n",
            "Iteration: 01473, Loss: 0.000300, PSRN_gt: 30.420392\n",
            "Iteration: 01474, Loss: 0.000278, PSRN_gt: 30.671375\n",
            "Iteration: 01475, Loss: 0.000254, PSRN_gt: 30.886953\n",
            "Iteration: 01476, Loss: 0.000269, PSRN_gt: 30.734348\n",
            "Iteration: 01477, Loss: 0.000269, PSRN_gt: 30.750596\n",
            "Iteration: 01478, Loss: 0.000250, PSRN_gt: 30.922836\n",
            "Iteration: 01479, Loss: 0.000249, PSRN_gt: 30.935756\n",
            "Iteration: 01480, Loss: 0.000249, PSRN_gt: 30.954448\n",
            "Iteration: 01481, Loss: 0.000242, PSRN_gt: 31.011946\n",
            "Iteration: 01482, Loss: 0.000240, PSRN_gt: 31.024097\n",
            "Iteration: 01483, Loss: 0.000238, PSRN_gt: 31.065513\n",
            "Iteration: 01484, Loss: 0.000235, PSRN_gt: 31.081492\n",
            "Iteration: 01485, Loss: 0.000232, PSRN_gt: 31.113014\n",
            "Iteration: 01486, Loss: 0.000229, PSRN_gt: 31.151073\n",
            "Iteration: 01487, Loss: 0.000227, PSRN_gt: 31.170485\n",
            "Iteration: 01488, Loss: 0.000226, PSRN_gt: 31.171599\n",
            "Iteration: 01489, Loss: 0.000224, PSRN_gt: 31.209238\n",
            "Iteration: 01490, Loss: 0.000220, PSRN_gt: 31.250889\n",
            "Iteration: 01491, Loss: 0.000221, PSRN_gt: 31.220702\n",
            "Iteration: 01492, Loss: 0.000219, PSRN_gt: 31.254310\n",
            "Iteration: 01493, Loss: 0.000217, PSRN_gt: 31.282826\n",
            "Iteration: 01494, Loss: 0.000217, PSRN_gt: 31.254950\n",
            "Iteration: 01495, Loss: 0.000215, PSRN_gt: 31.293008\n",
            "Iteration: 01496, Loss: 0.000214, PSRN_gt: 31.308653\n",
            "Iteration: 01497, Loss: 0.000215, PSRN_gt: 31.279454\n",
            "Iteration: 01498, Loss: 0.000215, PSRN_gt: 31.278416\n",
            "Iteration: 01499, Loss: 0.000218, PSRN_gt: 31.262082\n",
            "Iteration: 01500, Loss: 0.000224, PSRN_gt: 31.187209\n",
            "Iteration: 01501, Loss: 0.000234, PSRN_gt: 31.069457\n",
            "Iteration: 01502, Loss: 0.000251, PSRN_gt: 30.892409\n",
            "Iteration: 01503, Loss: 0.000280, PSRN_gt: 30.597258\n",
            "Iteration: 01504, Loss: 0.000319, PSRN_gt: 30.236103\n",
            "Iteration: 01505, Loss: 0.000357, PSRN_gt: 29.883660\n",
            "Iteration: 01506, Loss: 0.000383, PSRN_gt: 29.696247\n",
            "Iteration: 01507, Loss: 0.000352, PSRN_gt: 29.933357\n",
            "Iteration: 01508, Loss: 0.000309, PSRN_gt: 30.361740\n",
            "Iteration: 01509, Loss: 0.000292, PSRN_gt: 30.509033\n",
            "Iteration: 01510, Loss: 0.000320, PSRN_gt: 30.242675\n",
            "Iteration: 01511, Loss: 0.000323, PSRN_gt: 30.225554\n",
            "Iteration: 01512, Loss: 0.000288, PSRN_gt: 30.535088\n",
            "Iteration: 01513, Loss: 0.000260, PSRN_gt: 30.841949\n",
            "Iteration: 01514, Loss: 0.000268, PSRN_gt: 30.741599\n",
            "Iteration: 01515, Loss: 0.000276, PSRN_gt: 30.640097\n",
            "Iteration: 01516, Loss: 0.000260, PSRN_gt: 30.842966\n",
            "Iteration: 01517, Loss: 0.000250, PSRN_gt: 30.917608\n",
            "Iteration: 01518, Loss: 0.000249, PSRN_gt: 30.942726\n",
            "Iteration: 01519, Loss: 0.000245, PSRN_gt: 30.989328\n",
            "Iteration: 01520, Loss: 0.000243, PSRN_gt: 30.977276\n",
            "Iteration: 01521, Loss: 0.000238, PSRN_gt: 31.062241\n",
            "Iteration: 01522, Loss: 0.000229, PSRN_gt: 31.153653\n",
            "Iteration: 01523, Loss: 0.000232, PSRN_gt: 31.093153\n",
            "Iteration: 01524, Loss: 0.000230, PSRN_gt: 31.152832\n",
            "Iteration: 01525, Loss: 0.000225, PSRN_gt: 31.185967\n",
            "Iteration: 01526, Loss: 0.000224, PSRN_gt: 31.182002\n",
            "Iteration: 01527, Loss: 0.000220, PSRN_gt: 31.255518\n",
            "Iteration: 01528, Loss: 0.000219, PSRN_gt: 31.247690\n",
            "Iteration: 01529, Loss: 0.000220, PSRN_gt: 31.227107\n",
            "Iteration: 01530, Loss: 0.000216, PSRN_gt: 31.284344\n",
            "Iteration: 01531, Loss: 0.000214, PSRN_gt: 31.305902\n",
            "Iteration: 01532, Loss: 0.000215, PSRN_gt: 31.288043\n",
            "Iteration: 01533, Loss: 0.000214, PSRN_gt: 31.289246\n",
            "Iteration: 01534, Loss: 0.000215, PSRN_gt: 31.287323\n",
            "Iteration: 01535, Loss: 0.000216, PSRN_gt: 31.268297\n",
            "Iteration: 01536, Loss: 0.000221, PSRN_gt: 31.221756\n",
            "Iteration: 01537, Loss: 0.000231, PSRN_gt: 31.084993\n",
            "Iteration: 01538, Loss: 0.000251, PSRN_gt: 30.902732\n",
            "Iteration: 01539, Loss: 0.000275, PSRN_gt: 30.630312\n",
            "Iteration: 01540, Loss: 0.000302, PSRN_gt: 30.393799\n",
            "Iteration: 01541, Loss: 0.000306, PSRN_gt: 30.333161\n",
            "Iteration: 01542, Loss: 0.000284, PSRN_gt: 30.582796\n",
            "Iteration: 01543, Loss: 0.000259, PSRN_gt: 30.809035\n",
            "Iteration: 01544, Loss: 0.000275, PSRN_gt: 30.647874\n",
            "Iteration: 01545, Loss: 0.000276, PSRN_gt: 30.665586\n",
            "Iteration: 01546, Loss: 0.000274, PSRN_gt: 30.649307\n",
            "Iteration: 01547, Loss: 0.000262, PSRN_gt: 30.815131\n",
            "Iteration: 01548, Loss: 0.000256, PSRN_gt: 30.833763\n",
            "Iteration: 01549, Loss: 0.000253, PSRN_gt: 30.896647\n",
            "Iteration: 01550, Loss: 0.000245, PSRN_gt: 30.969465\n",
            "Iteration: 01551, Loss: 0.000233, PSRN_gt: 31.072304\n",
            "Iteration: 01552, Loss: 0.000232, PSRN_gt: 31.116796\n",
            "Iteration: 01553, Loss: 0.000234, PSRN_gt: 31.070147\n",
            "Iteration: 01554, Loss: 0.000230, PSRN_gt: 31.121416\n",
            "Iteration: 01555, Loss: 0.000226, PSRN_gt: 31.171436\n",
            "Iteration: 01556, Loss: 0.000224, PSRN_gt: 31.191499\n",
            "Iteration: 01557, Loss: 0.000218, PSRN_gt: 31.248936\n",
            "Iteration: 01558, Loss: 0.000217, PSRN_gt: 31.270236\n",
            "Iteration: 01559, Loss: 0.000219, PSRN_gt: 31.248481\n",
            "Iteration: 01560, Loss: 0.000213, PSRN_gt: 31.293644\n",
            "Iteration: 01561, Loss: 0.000209, PSRN_gt: 31.357513\n",
            "Iteration: 01562, Loss: 0.000213, PSRN_gt: 31.317626\n",
            "Iteration: 01563, Loss: 0.000211, PSRN_gt: 31.319105\n",
            "Iteration: 01564, Loss: 0.000207, PSRN_gt: 31.374048\n",
            "Iteration: 01565, Loss: 0.000206, PSRN_gt: 31.373377\n",
            "Iteration: 01566, Loss: 0.000206, PSRN_gt: 31.377494\n",
            "Iteration: 01567, Loss: 0.000204, PSRN_gt: 31.404537\n",
            "Iteration: 01568, Loss: 0.000205, PSRN_gt: 31.379927\n",
            "Iteration: 01569, Loss: 0.000206, PSRN_gt: 31.375757\n",
            "Iteration: 01570, Loss: 0.000207, PSRN_gt: 31.357073\n",
            "Iteration: 01571, Loss: 0.000210, PSRN_gt: 31.331709\n",
            "Iteration: 01572, Loss: 0.000216, PSRN_gt: 31.254694\n",
            "Iteration: 01573, Loss: 0.000226, PSRN_gt: 31.160522\n",
            "Iteration: 01574, Loss: 0.000237, PSRN_gt: 31.033905\n",
            "Iteration: 01575, Loss: 0.000251, PSRN_gt: 30.896209\n",
            "Iteration: 01576, Loss: 0.000266, PSRN_gt: 30.712040\n",
            "Iteration: 01577, Loss: 0.000284, PSRN_gt: 30.553080\n",
            "Iteration: 01578, Loss: 0.000297, PSRN_gt: 30.425464\n",
            "Iteration: 01579, Loss: 0.000313, PSRN_gt: 30.251413\n",
            "Iteration: 01580, Loss: 0.000337, PSRN_gt: 30.079360\n",
            "Iteration: 01581, Loss: 0.000330, PSRN_gt: 30.118878\n",
            "Iteration: 01582, Loss: 0.000311, PSRN_gt: 30.313187\n",
            "Iteration: 01583, Loss: 0.000290, PSRN_gt: 30.526744\n",
            "Iteration: 01584, Loss: 0.000296, PSRN_gt: 30.441274\n",
            "Iteration: 01585, Loss: 0.000293, PSRN_gt: 30.484900\n",
            "Iteration: 01586, Loss: 0.000264, PSRN_gt: 30.735502\n",
            "Iteration: 01587, Loss: 0.000258, PSRN_gt: 30.830158\n",
            "Iteration: 01588, Loss: 0.000267, PSRN_gt: 30.734903\n",
            "Iteration: 01589, Loss: 0.000252, PSRN_gt: 30.876335\n",
            "Iteration: 01590, Loss: 0.000234, PSRN_gt: 31.100382\n",
            "Iteration: 01591, Loss: 0.000239, PSRN_gt: 31.047059\n",
            "Iteration: 01592, Loss: 0.000241, PSRN_gt: 30.999410\n",
            "Iteration: 01593, Loss: 0.000231, PSRN_gt: 31.101134\n",
            "Iteration: 01594, Loss: 0.000227, PSRN_gt: 31.164326\n",
            "Iteration: 01595, Loss: 0.000227, PSRN_gt: 31.153842\n",
            "Iteration: 01596, Loss: 0.000225, PSRN_gt: 31.170297\n",
            "Iteration: 01597, Loss: 0.000220, PSRN_gt: 31.227391\n",
            "Iteration: 01598, Loss: 0.000216, PSRN_gt: 31.269984\n",
            "Iteration: 01599, Loss: 0.000215, PSRN_gt: 31.294177\n",
            "Iteration: 01600, Loss: 0.000214, PSRN_gt: 31.293298\n",
            "Iteration: 01601, Loss: 0.000210, PSRN_gt: 31.324644\n",
            "Iteration: 01602, Loss: 0.000208, PSRN_gt: 31.369390\n",
            "Iteration: 01603, Loss: 0.000208, PSRN_gt: 31.358672\n",
            "Iteration: 01604, Loss: 0.000206, PSRN_gt: 31.374781\n",
            "Iteration: 01605, Loss: 0.000205, PSRN_gt: 31.386477\n",
            "Iteration: 01606, Loss: 0.000204, PSRN_gt: 31.406956\n",
            "Iteration: 01607, Loss: 0.000202, PSRN_gt: 31.418816\n",
            "Iteration: 01608, Loss: 0.000202, PSRN_gt: 31.415469\n",
            "Iteration: 01609, Loss: 0.000201, PSRN_gt: 31.426869\n",
            "Iteration: 01610, Loss: 0.000200, PSRN_gt: 31.438649\n",
            "Iteration: 01611, Loss: 0.000200, PSRN_gt: 31.438264\n",
            "Iteration: 01612, Loss: 0.000202, PSRN_gt: 31.413068\n",
            "Iteration: 01613, Loss: 0.000204, PSRN_gt: 31.386879\n",
            "Iteration: 01614, Loss: 0.000210, PSRN_gt: 31.322566\n",
            "Iteration: 01615, Loss: 0.000220, PSRN_gt: 31.203535\n",
            "Iteration: 01616, Loss: 0.000235, PSRN_gt: 31.039990\n",
            "Iteration: 01617, Loss: 0.000256, PSRN_gt: 30.809697\n",
            "Iteration: 01618, Loss: 0.000283, PSRN_gt: 30.546589\n",
            "Iteration: 01619, Loss: 0.000298, PSRN_gt: 30.373161\n",
            "Iteration: 01620, Loss: 0.000303, PSRN_gt: 30.366962\n",
            "Iteration: 01621, Loss: 0.000280, PSRN_gt: 30.563411\n",
            "Iteration: 01622, Loss: 0.000254, PSRN_gt: 30.869876\n",
            "Iteration: 01623, Loss: 0.000236, PSRN_gt: 31.034711\n",
            "Iteration: 01624, Loss: 0.000239, PSRN_gt: 31.012887\n",
            "Iteration: 01625, Loss: 0.000250, PSRN_gt: 30.884379\n",
            "Iteration: 01626, Loss: 0.000250, PSRN_gt: 30.862109\n",
            "Iteration: 01627, Loss: 0.000238, PSRN_gt: 31.051496\n",
            "Iteration: 01628, Loss: 0.000222, PSRN_gt: 31.180666\n",
            "Iteration: 01629, Loss: 0.000219, PSRN_gt: 31.224719\n",
            "Iteration: 01630, Loss: 0.000225, PSRN_gt: 31.169703\n",
            "Iteration: 01631, Loss: 0.000227, PSRN_gt: 31.124515\n",
            "Iteration: 01632, Loss: 0.000218, PSRN_gt: 31.231703\n",
            "Iteration: 01633, Loss: 0.000210, PSRN_gt: 31.334910\n",
            "Iteration: 01634, Loss: 0.000207, PSRN_gt: 31.352577\n",
            "Iteration: 01635, Loss: 0.000210, PSRN_gt: 31.330727\n",
            "Iteration: 01636, Loss: 0.000211, PSRN_gt: 31.302555\n",
            "Iteration: 01637, Loss: 0.000208, PSRN_gt: 31.349447\n",
            "Iteration: 01638, Loss: 0.000202, PSRN_gt: 31.412623\n",
            "Iteration: 01639, Loss: 0.000202, PSRN_gt: 31.418406\n",
            "Iteration: 01640, Loss: 0.000201, PSRN_gt: 31.426116\n",
            "Iteration: 01641, Loss: 0.000199, PSRN_gt: 31.449223\n",
            "Iteration: 01642, Loss: 0.000199, PSRN_gt: 31.452936\n",
            "Iteration: 01643, Loss: 0.000198, PSRN_gt: 31.453009\n",
            "Iteration: 01644, Loss: 0.000198, PSRN_gt: 31.464034\n",
            "Iteration: 01645, Loss: 0.000198, PSRN_gt: 31.443617\n",
            "Iteration: 01646, Loss: 0.000199, PSRN_gt: 31.442691\n",
            "Iteration: 01647, Loss: 0.000203, PSRN_gt: 31.404625\n",
            "Iteration: 01648, Loss: 0.000208, PSRN_gt: 31.326146\n",
            "Iteration: 01649, Loss: 0.000218, PSRN_gt: 31.216339\n",
            "Iteration: 01650, Loss: 0.000236, PSRN_gt: 31.029720\n",
            "Iteration: 01651, Loss: 0.000256, PSRN_gt: 30.804801\n",
            "Iteration: 01652, Loss: 0.000273, PSRN_gt: 30.655426\n",
            "Iteration: 01653, Loss: 0.000272, PSRN_gt: 30.644437\n",
            "Iteration: 01654, Loss: 0.000255, PSRN_gt: 30.824069\n",
            "Iteration: 01655, Loss: 0.000238, PSRN_gt: 31.007728\n",
            "Iteration: 01656, Loss: 0.000231, PSRN_gt: 31.077393\n",
            "Iteration: 01657, Loss: 0.000239, PSRN_gt: 31.008335\n",
            "Iteration: 01658, Loss: 0.000249, PSRN_gt: 30.910758\n",
            "Iteration: 01659, Loss: 0.000244, PSRN_gt: 30.929568\n",
            "Iteration: 01660, Loss: 0.000227, PSRN_gt: 31.156605\n",
            "Iteration: 01661, Loss: 0.000213, PSRN_gt: 31.273045\n",
            "Iteration: 01662, Loss: 0.000215, PSRN_gt: 31.271203\n",
            "Iteration: 01663, Loss: 0.000225, PSRN_gt: 31.152413\n",
            "Iteration: 01664, Loss: 0.000222, PSRN_gt: 31.167652\n",
            "Iteration: 01665, Loss: 0.000213, PSRN_gt: 31.297636\n",
            "Iteration: 01666, Loss: 0.000209, PSRN_gt: 31.320387\n",
            "Iteration: 01667, Loss: 0.000211, PSRN_gt: 31.303377\n",
            "Iteration: 01668, Loss: 0.000212, PSRN_gt: 31.291481\n",
            "Iteration: 01669, Loss: 0.000212, PSRN_gt: 31.297412\n",
            "Iteration: 01670, Loss: 0.000211, PSRN_gt: 31.301802\n",
            "Iteration: 01671, Loss: 0.000212, PSRN_gt: 31.286235\n",
            "Iteration: 01672, Loss: 0.000216, PSRN_gt: 31.246959\n",
            "Iteration: 01673, Loss: 0.000222, PSRN_gt: 31.176360\n",
            "Iteration: 01674, Loss: 0.000229, PSRN_gt: 31.099499\n",
            "Iteration: 01675, Loss: 0.000238, PSRN_gt: 31.020565\n",
            "Iteration: 01676, Loss: 0.000242, PSRN_gt: 30.956393\n",
            "Iteration: 01677, Loss: 0.000244, PSRN_gt: 30.935503\n",
            "Iteration: 01678, Loss: 0.000241, PSRN_gt: 30.965731\n",
            "Iteration: 01679, Loss: 0.000235, PSRN_gt: 31.039998\n",
            "Iteration: 01680, Loss: 0.000221, PSRN_gt: 31.202476\n",
            "Iteration: 01681, Loss: 0.000212, PSRN_gt: 31.280967\n",
            "Iteration: 01682, Loss: 0.000211, PSRN_gt: 31.293826\n",
            "Iteration: 01683, Loss: 0.000215, PSRN_gt: 31.270060\n",
            "Iteration: 01684, Loss: 0.000218, PSRN_gt: 31.210594\n",
            "Iteration: 01685, Loss: 0.000219, PSRN_gt: 31.217863\n",
            "Iteration: 01686, Loss: 0.000215, PSRN_gt: 31.245679\n",
            "Iteration: 01687, Loss: 0.000212, PSRN_gt: 31.289259\n",
            "Iteration: 01688, Loss: 0.000206, PSRN_gt: 31.363176\n",
            "Iteration: 01689, Loss: 0.000199, PSRN_gt: 31.434639\n",
            "Iteration: 01690, Loss: 0.000198, PSRN_gt: 31.441984\n",
            "Iteration: 01691, Loss: 0.000199, PSRN_gt: 31.445237\n",
            "Iteration: 01692, Loss: 0.000199, PSRN_gt: 31.423095\n",
            "Iteration: 01693, Loss: 0.000200, PSRN_gt: 31.411582\n",
            "Iteration: 01694, Loss: 0.000198, PSRN_gt: 31.447758\n",
            "Iteration: 01695, Loss: 0.000196, PSRN_gt: 31.468568\n",
            "Iteration: 01696, Loss: 0.000196, PSRN_gt: 31.452506\n",
            "Iteration: 01697, Loss: 0.000198, PSRN_gt: 31.446520\n",
            "Iteration: 01698, Loss: 0.000199, PSRN_gt: 31.430882\n",
            "Iteration: 01699, Loss: 0.000201, PSRN_gt: 31.398411\n",
            "Iteration: 01700, Loss: 0.000207, PSRN_gt: 31.344023\n",
            "Iteration: 01701, Loss: 0.000216, PSRN_gt: 31.224998\n",
            "Iteration: 01702, Loss: 0.000228, PSRN_gt: 31.108239\n",
            "Iteration: 01703, Loss: 0.000233, PSRN_gt: 31.058982\n",
            "Iteration: 01704, Loss: 0.000232, PSRN_gt: 31.077842\n",
            "Iteration: 01705, Loss: 0.000225, PSRN_gt: 31.131636\n",
            "Iteration: 01706, Loss: 0.000227, PSRN_gt: 31.124179\n",
            "Iteration: 01707, Loss: 0.000241, PSRN_gt: 30.955163\n",
            "Iteration: 01708, Loss: 0.000268, PSRN_gt: 30.704089\n",
            "Iteration: 01709, Loss: 0.000294, PSRN_gt: 30.413653\n",
            "Iteration: 01710, Loss: 0.000310, PSRN_gt: 30.302522\n",
            "Iteration: 01711, Loss: 0.000304, PSRN_gt: 30.328707\n",
            "Iteration: 01712, Loss: 0.000307, PSRN_gt: 30.309825\n",
            "Iteration: 01713, Loss: 0.000285, PSRN_gt: 30.559582\n",
            "Iteration: 01714, Loss: 0.000284, PSRN_gt: 30.523468\n",
            "Iteration: 01715, Loss: 0.000303, PSRN_gt: 30.402722\n",
            "Iteration: 01716, Loss: 0.000312, PSRN_gt: 30.260360\n",
            "Iteration: 01717, Loss: 0.000295, PSRN_gt: 30.462126\n",
            "Iteration: 01718, Loss: 0.000270, PSRN_gt: 30.655305\n",
            "Iteration: 01719, Loss: 0.000259, PSRN_gt: 30.802722\n",
            "Iteration: 01720, Loss: 0.000265, PSRN_gt: 30.735569\n",
            "Iteration: 01721, Loss: 0.000249, PSRN_gt: 30.894687\n",
            "Iteration: 01722, Loss: 0.000230, PSRN_gt: 31.110045\n",
            "Iteration: 01723, Loss: 0.000236, PSRN_gt: 31.024561\n",
            "Iteration: 01724, Loss: 0.000230, PSRN_gt: 31.106856\n",
            "Iteration: 01725, Loss: 0.000222, PSRN_gt: 31.207418\n",
            "Iteration: 01726, Loss: 0.000222, PSRN_gt: 31.186172\n",
            "Iteration: 01727, Loss: 0.000215, PSRN_gt: 31.271262\n",
            "Iteration: 01728, Loss: 0.000212, PSRN_gt: 31.298600\n",
            "Iteration: 01729, Loss: 0.000209, PSRN_gt: 31.339530\n",
            "Iteration: 01730, Loss: 0.000206, PSRN_gt: 31.369400\n",
            "Iteration: 01731, Loss: 0.000205, PSRN_gt: 31.385227\n",
            "Iteration: 01732, Loss: 0.000201, PSRN_gt: 31.428637\n",
            "Iteration: 01733, Loss: 0.000198, PSRN_gt: 31.462062\n",
            "Iteration: 01734, Loss: 0.000198, PSRN_gt: 31.462161\n",
            "Iteration: 01735, Loss: 0.000195, PSRN_gt: 31.496707\n",
            "Iteration: 01736, Loss: 0.000194, PSRN_gt: 31.508790\n",
            "Iteration: 01737, Loss: 0.000191, PSRN_gt: 31.528020\n",
            "Iteration: 01738, Loss: 0.000189, PSRN_gt: 31.559638\n",
            "Iteration: 01739, Loss: 0.000189, PSRN_gt: 31.556158\n",
            "Iteration: 01740, Loss: 0.000187, PSRN_gt: 31.583317\n",
            "Iteration: 01741, Loss: 0.000186, PSRN_gt: 31.578099\n",
            "Iteration: 01742, Loss: 0.000186, PSRN_gt: 31.578943\n",
            "Iteration: 01743, Loss: 0.000184, PSRN_gt: 31.609149\n",
            "Iteration: 01744, Loss: 0.000184, PSRN_gt: 31.605318\n",
            "Iteration: 01745, Loss: 0.000183, PSRN_gt: 31.611692\n",
            "Iteration: 01746, Loss: 0.000184, PSRN_gt: 31.614137\n",
            "Iteration: 01747, Loss: 0.000186, PSRN_gt: 31.579646\n",
            "Iteration: 01748, Loss: 0.000190, PSRN_gt: 31.524617\n",
            "Iteration: 01749, Loss: 0.000197, PSRN_gt: 31.443447\n",
            "Iteration: 01750, Loss: 0.000210, PSRN_gt: 31.296218\n",
            "Iteration: 01751, Loss: 0.000233, PSRN_gt: 31.036757\n",
            "Iteration: 01752, Loss: 0.000266, PSRN_gt: 30.699273\n",
            "Iteration: 01753, Loss: 0.000305, PSRN_gt: 30.310542\n",
            "Iteration: 01754, Loss: 0.000317, PSRN_gt: 30.223030\n",
            "Iteration: 01755, Loss: 0.000277, PSRN_gt: 30.571229\n",
            "Iteration: 01756, Loss: 0.000222, PSRN_gt: 31.185431\n",
            "Iteration: 01757, Loss: 0.000224, PSRN_gt: 31.131299\n",
            "Iteration: 01758, Loss: 0.000270, PSRN_gt: 30.687753\n",
            "Iteration: 01759, Loss: 0.000271, PSRN_gt: 30.663413\n",
            "Iteration: 01760, Loss: 0.000227, PSRN_gt: 31.120367\n",
            "Iteration: 01761, Loss: 0.000219, PSRN_gt: 31.216585\n",
            "Iteration: 01762, Loss: 0.000247, PSRN_gt: 30.907279\n",
            "Iteration: 01763, Loss: 0.000238, PSRN_gt: 31.004014\n",
            "Iteration: 01764, Loss: 0.000209, PSRN_gt: 31.316469\n",
            "Iteration: 01765, Loss: 0.000214, PSRN_gt: 31.258239\n",
            "Iteration: 01766, Loss: 0.000227, PSRN_gt: 31.143331\n",
            "Iteration: 01767, Loss: 0.000210, PSRN_gt: 31.312948\n",
            "Iteration: 01768, Loss: 0.000197, PSRN_gt: 31.457027\n",
            "Iteration: 01769, Loss: 0.000207, PSRN_gt: 31.349080\n",
            "Iteration: 01770, Loss: 0.000204, PSRN_gt: 31.377921\n",
            "Iteration: 01771, Loss: 0.000191, PSRN_gt: 31.535584\n",
            "Iteration: 01772, Loss: 0.000194, PSRN_gt: 31.500545\n",
            "Iteration: 01773, Loss: 0.000199, PSRN_gt: 31.440791\n",
            "Iteration: 01774, Loss: 0.000193, PSRN_gt: 31.513007\n",
            "Iteration: 01775, Loss: 0.000187, PSRN_gt: 31.577148\n",
            "Iteration: 01776, Loss: 0.000189, PSRN_gt: 31.533768\n",
            "Iteration: 01777, Loss: 0.000190, PSRN_gt: 31.540335\n",
            "Iteration: 01778, Loss: 0.000186, PSRN_gt: 31.585740\n",
            "Iteration: 01779, Loss: 0.000184, PSRN_gt: 31.609005\n",
            "Iteration: 01780, Loss: 0.000184, PSRN_gt: 31.609107\n",
            "Iteration: 01781, Loss: 0.000184, PSRN_gt: 31.607017\n",
            "Iteration: 01782, Loss: 0.000183, PSRN_gt: 31.612661\n",
            "Iteration: 01783, Loss: 0.000183, PSRN_gt: 31.609162\n",
            "Iteration: 01784, Loss: 0.000183, PSRN_gt: 31.621230\n",
            "Iteration: 01785, Loss: 0.000185, PSRN_gt: 31.585563\n",
            "Iteration: 01786, Loss: 0.000187, PSRN_gt: 31.553210\n",
            "Iteration: 01787, Loss: 0.000190, PSRN_gt: 31.515954\n",
            "Iteration: 01788, Loss: 0.000193, PSRN_gt: 31.492828\n",
            "Iteration: 01789, Loss: 0.000198, PSRN_gt: 31.426096\n",
            "Iteration: 01790, Loss: 0.000200, PSRN_gt: 31.414171\n",
            "Iteration: 01791, Loss: 0.000201, PSRN_gt: 31.375928\n",
            "Iteration: 01792, Loss: 0.000203, PSRN_gt: 31.387504\n",
            "Iteration: 01793, Loss: 0.000205, PSRN_gt: 31.318664\n",
            "Iteration: 01794, Loss: 0.000209, PSRN_gt: 31.310086\n",
            "Iteration: 01795, Loss: 0.000216, PSRN_gt: 31.213851\n",
            "Iteration: 01796, Loss: 0.000223, PSRN_gt: 31.159141\n",
            "Iteration: 01797, Loss: 0.000231, PSRN_gt: 31.054213\n",
            "Iteration: 01798, Loss: 0.000232, PSRN_gt: 31.058259\n",
            "Iteration: 01799, Loss: 0.000233, PSRN_gt: 31.039722\n",
            "Iteration: 01800, Loss: 0.000242, PSRN_gt: 30.928102\n",
            "Iteration: 01801, Loss: 0.000264, PSRN_gt: 30.728105\n",
            "Iteration: 01802, Loss: 0.000281, PSRN_gt: 30.542844\n",
            "Iteration: 01803, Loss: 0.000295, PSRN_gt: 30.425956\n",
            "Iteration: 01804, Loss: 0.000278, PSRN_gt: 30.565583\n",
            "Iteration: 01805, Loss: 0.000263, PSRN_gt: 30.757536\n",
            "Iteration: 01806, Loss: 0.000253, PSRN_gt: 30.828259\n",
            "Iteration: 01807, Loss: 0.000246, PSRN_gt: 30.916135\n",
            "Iteration: 01808, Loss: 0.000234, PSRN_gt: 31.070924\n",
            "Iteration: 01809, Loss: 0.000231, PSRN_gt: 31.053966\n",
            "Iteration: 01810, Loss: 0.000235, PSRN_gt: 31.054792\n",
            "Iteration: 01811, Loss: 0.000225, PSRN_gt: 31.122923\n",
            "Iteration: 01812, Loss: 0.000213, PSRN_gt: 31.269730\n",
            "Iteration: 01813, Loss: 0.000214, PSRN_gt: 31.265386\n",
            "Iteration: 01814, Loss: 0.000208, PSRN_gt: 31.331130\n",
            "Iteration: 01815, Loss: 0.000204, PSRN_gt: 31.366419\n",
            "Iteration: 01816, Loss: 0.000204, PSRN_gt: 31.367813\n",
            "Iteration: 01817, Loss: 0.000198, PSRN_gt: 31.435010\n",
            "Iteration: 01818, Loss: 0.000195, PSRN_gt: 31.481395\n",
            "Iteration: 01819, Loss: 0.000194, PSRN_gt: 31.491013\n",
            "Iteration: 01820, Loss: 0.000193, PSRN_gt: 31.496404\n",
            "Iteration: 01821, Loss: 0.000189, PSRN_gt: 31.544574\n",
            "Iteration: 01822, Loss: 0.000187, PSRN_gt: 31.570686\n",
            "Iteration: 01823, Loss: 0.000186, PSRN_gt: 31.571209\n",
            "Iteration: 01824, Loss: 0.000183, PSRN_gt: 31.617864\n",
            "Iteration: 01825, Loss: 0.000183, PSRN_gt: 31.623207\n",
            "Iteration: 01826, Loss: 0.000182, PSRN_gt: 31.616170\n",
            "Iteration: 01827, Loss: 0.000180, PSRN_gt: 31.654836\n",
            "Iteration: 01828, Loss: 0.000179, PSRN_gt: 31.648713\n",
            "Iteration: 01829, Loss: 0.000180, PSRN_gt: 31.643238\n",
            "Iteration: 01830, Loss: 0.000180, PSRN_gt: 31.652319\n",
            "Iteration: 01831, Loss: 0.000181, PSRN_gt: 31.622064\n",
            "Iteration: 01832, Loss: 0.000183, PSRN_gt: 31.603392\n",
            "Iteration: 01833, Loss: 0.000187, PSRN_gt: 31.561483\n",
            "Iteration: 01834, Loss: 0.000193, PSRN_gt: 31.479471\n",
            "Iteration: 01835, Loss: 0.000202, PSRN_gt: 31.368869\n",
            "Iteration: 01836, Loss: 0.000214, PSRN_gt: 31.238179\n",
            "Iteration: 01837, Loss: 0.000226, PSRN_gt: 31.106222\n",
            "Iteration: 01838, Loss: 0.000238, PSRN_gt: 30.966122\n",
            "Iteration: 01839, Loss: 0.000239, PSRN_gt: 30.969278\n",
            "Iteration: 01840, Loss: 0.000232, PSRN_gt: 31.021912\n",
            "Iteration: 01841, Loss: 0.000222, PSRN_gt: 31.163945\n",
            "Iteration: 01842, Loss: 0.000218, PSRN_gt: 31.198251\n",
            "Iteration: 01843, Loss: 0.000224, PSRN_gt: 31.121922\n",
            "Iteration: 01844, Loss: 0.000231, PSRN_gt: 31.063863\n",
            "Iteration: 01845, Loss: 0.000224, PSRN_gt: 31.109374\n",
            "Iteration: 01846, Loss: 0.000207, PSRN_gt: 31.345209\n",
            "Iteration: 01847, Loss: 0.000193, PSRN_gt: 31.477534\n",
            "Iteration: 01848, Loss: 0.000194, PSRN_gt: 31.489357\n",
            "Iteration: 01849, Loss: 0.000201, PSRN_gt: 31.377872\n",
            "Iteration: 01850, Loss: 0.000201, PSRN_gt: 31.382482\n",
            "Iteration: 01851, Loss: 0.000191, PSRN_gt: 31.516330\n",
            "Iteration: 01852, Loss: 0.000183, PSRN_gt: 31.592053\n",
            "Iteration: 01853, Loss: 0.000184, PSRN_gt: 31.596436\n",
            "Iteration: 01854, Loss: 0.000187, PSRN_gt: 31.557055\n",
            "Iteration: 01855, Loss: 0.000187, PSRN_gt: 31.547842\n",
            "Iteration: 01856, Loss: 0.000182, PSRN_gt: 31.616139\n",
            "Iteration: 01857, Loss: 0.000178, PSRN_gt: 31.643969\n",
            "Iteration: 01858, Loss: 0.000179, PSRN_gt: 31.664807\n",
            "Iteration: 01859, Loss: 0.000180, PSRN_gt: 31.634332\n",
            "Iteration: 01860, Loss: 0.000181, PSRN_gt: 31.618502\n",
            "Iteration: 01861, Loss: 0.000181, PSRN_gt: 31.618771\n",
            "Iteration: 01862, Loss: 0.000184, PSRN_gt: 31.587745\n",
            "Iteration: 01863, Loss: 0.000189, PSRN_gt: 31.518308\n",
            "Iteration: 01864, Loss: 0.000196, PSRN_gt: 31.457612\n",
            "Iteration: 01865, Loss: 0.000204, PSRN_gt: 31.329317\n",
            "Iteration: 01866, Loss: 0.000217, PSRN_gt: 31.207634\n",
            "Iteration: 01867, Loss: 0.000225, PSRN_gt: 31.097551\n",
            "Iteration: 01868, Loss: 0.000231, PSRN_gt: 31.059704\n",
            "Iteration: 01869, Loss: 0.000225, PSRN_gt: 31.077191\n",
            "Iteration: 01870, Loss: 0.000220, PSRN_gt: 31.185585\n",
            "Iteration: 01871, Loss: 0.000212, PSRN_gt: 31.236695\n",
            "Iteration: 01872, Loss: 0.000212, PSRN_gt: 31.255500\n",
            "Iteration: 01873, Loss: 0.000212, PSRN_gt: 31.249006\n",
            "Iteration: 01874, Loss: 0.000210, PSRN_gt: 31.275518\n",
            "Iteration: 01875, Loss: 0.000207, PSRN_gt: 31.334965\n",
            "Iteration: 01876, Loss: 0.000202, PSRN_gt: 31.341607\n",
            "Iteration: 01877, Loss: 0.000198, PSRN_gt: 31.459772\n",
            "Iteration: 01878, Loss: 0.000191, PSRN_gt: 31.470681\n",
            "Iteration: 01879, Loss: 0.000188, PSRN_gt: 31.535498\n",
            "Iteration: 01880, Loss: 0.000190, PSRN_gt: 31.537072\n",
            "Iteration: 01881, Loss: 0.000190, PSRN_gt: 31.502479\n",
            "Iteration: 01882, Loss: 0.000185, PSRN_gt: 31.576763\n",
            "Iteration: 01883, Loss: 0.000182, PSRN_gt: 31.609195\n",
            "Iteration: 01884, Loss: 0.000179, PSRN_gt: 31.640220\n",
            "Iteration: 01885, Loss: 0.000178, PSRN_gt: 31.648040\n",
            "Iteration: 01886, Loss: 0.000178, PSRN_gt: 31.653368\n",
            "Iteration: 01887, Loss: 0.000179, PSRN_gt: 31.638498\n",
            "Iteration: 01888, Loss: 0.000178, PSRN_gt: 31.638776\n",
            "Iteration: 01889, Loss: 0.000176, PSRN_gt: 31.667730\n",
            "Iteration: 01890, Loss: 0.000177, PSRN_gt: 31.666074\n",
            "Iteration: 01891, Loss: 0.000180, PSRN_gt: 31.616969\n",
            "Iteration: 01892, Loss: 0.000184, PSRN_gt: 31.582557\n",
            "Iteration: 01893, Loss: 0.000187, PSRN_gt: 31.542844\n",
            "Iteration: 01894, Loss: 0.000192, PSRN_gt: 31.484225\n",
            "Iteration: 01895, Loss: 0.000196, PSRN_gt: 31.432303\n",
            "Iteration: 01896, Loss: 0.000201, PSRN_gt: 31.381995\n",
            "Iteration: 01897, Loss: 0.000206, PSRN_gt: 31.307190\n",
            "Iteration: 01898, Loss: 0.000211, PSRN_gt: 31.255582\n",
            "Iteration: 01899, Loss: 0.000214, PSRN_gt: 31.217422\n",
            "Iteration: 01900, Loss: 0.000220, PSRN_gt: 31.160162\n",
            "Iteration: 01901, Loss: 0.000225, PSRN_gt: 31.102965\n",
            "Iteration: 01902, Loss: 0.000224, PSRN_gt: 31.110067\n",
            "Iteration: 01903, Loss: 0.000225, PSRN_gt: 31.102078\n",
            "Iteration: 01904, Loss: 0.000232, PSRN_gt: 31.036699\n",
            "Iteration: 01905, Loss: 0.000249, PSRN_gt: 30.873079\n",
            "Iteration: 01906, Loss: 0.000257, PSRN_gt: 30.784130\n",
            "Iteration: 01907, Loss: 0.000260, PSRN_gt: 30.734503\n",
            "Iteration: 01908, Loss: 0.000272, PSRN_gt: 30.630603\n",
            "Iteration: 01909, Loss: 0.000258, PSRN_gt: 30.762440\n",
            "Iteration: 01910, Loss: 0.000261, PSRN_gt: 30.773775\n",
            "Iteration: 01911, Loss: 0.000260, PSRN_gt: 30.778637\n",
            "Iteration: 01912, Loss: 0.000244, PSRN_gt: 30.889080\n",
            "Iteration: 01913, Loss: 0.000245, PSRN_gt: 30.948521\n",
            "Iteration: 01914, Loss: 0.000243, PSRN_gt: 30.962582\n",
            "Iteration: 01915, Loss: 0.000241, PSRN_gt: 30.927440\n",
            "Iteration: 01916, Loss: 0.000227, PSRN_gt: 31.134159\n",
            "Iteration: 01917, Loss: 0.000214, PSRN_gt: 31.242250\n",
            "Iteration: 01918, Loss: 0.000215, PSRN_gt: 31.227441\n",
            "Iteration: 01919, Loss: 0.000217, PSRN_gt: 31.216561\n",
            "Iteration: 01920, Loss: 0.000206, PSRN_gt: 31.350890\n",
            "Iteration: 01921, Loss: 0.000200, PSRN_gt: 31.410078\n",
            "Iteration: 01922, Loss: 0.000195, PSRN_gt: 31.437750\n",
            "Iteration: 01923, Loss: 0.000191, PSRN_gt: 31.522706\n",
            "Iteration: 01924, Loss: 0.000195, PSRN_gt: 31.455375\n",
            "Iteration: 01925, Loss: 0.000188, PSRN_gt: 31.519507\n",
            "Iteration: 01926, Loss: 0.000185, PSRN_gt: 31.581658\n",
            "Iteration: 01927, Loss: 0.000185, PSRN_gt: 31.593683\n",
            "Iteration: 01928, Loss: 0.000181, PSRN_gt: 31.627463\n",
            "Iteration: 01929, Loss: 0.000180, PSRN_gt: 31.653050\n",
            "Iteration: 01930, Loss: 0.000176, PSRN_gt: 31.676775\n",
            "Iteration: 01931, Loss: 0.000175, PSRN_gt: 31.693665\n",
            "Iteration: 01932, Loss: 0.000174, PSRN_gt: 31.706782\n",
            "Iteration: 01933, Loss: 0.000173, PSRN_gt: 31.689739\n",
            "Iteration: 01934, Loss: 0.000172, PSRN_gt: 31.729584\n",
            "Iteration: 01935, Loss: 0.000170, PSRN_gt: 31.753202\n",
            "Iteration: 01936, Loss: 0.000169, PSRN_gt: 31.752283\n",
            "Iteration: 01937, Loss: 0.000168, PSRN_gt: 31.759663\n",
            "Iteration: 01938, Loss: 0.000167, PSRN_gt: 31.781197\n",
            "Iteration: 01939, Loss: 0.000165, PSRN_gt: 31.800467\n",
            "Iteration: 01940, Loss: 0.000165, PSRN_gt: 31.792555\n",
            "Iteration: 01941, Loss: 0.000165, PSRN_gt: 31.809379\n",
            "Iteration: 01942, Loss: 0.000165, PSRN_gt: 31.805117\n",
            "Iteration: 01943, Loss: 0.000167, PSRN_gt: 31.774880\n",
            "Iteration: 01944, Loss: 0.000169, PSRN_gt: 31.743308\n",
            "Iteration: 01945, Loss: 0.000174, PSRN_gt: 31.689257\n",
            "Iteration: 01946, Loss: 0.000182, PSRN_gt: 31.574802\n",
            "Iteration: 01947, Loss: 0.000197, PSRN_gt: 31.413840\n",
            "Iteration: 01948, Loss: 0.000218, PSRN_gt: 31.150504\n",
            "Iteration: 01949, Loss: 0.000252, PSRN_gt: 30.806269\n",
            "Iteration: 01950, Loss: 0.000283, PSRN_gt: 30.480702\n",
            "Iteration: 01951, Loss: 0.000310, PSRN_gt: 30.241732\n",
            "Iteration: 01952, Loss: 0.000302, PSRN_gt: 30.324086\n",
            "Iteration: 01953, Loss: 0.000278, PSRN_gt: 30.569239\n",
            "Iteration: 01954, Loss: 0.000260, PSRN_gt: 30.773405\n",
            "Iteration: 01955, Loss: 0.000257, PSRN_gt: 30.763009\n",
            "Iteration: 01956, Loss: 0.000253, PSRN_gt: 30.810461\n",
            "Iteration: 01957, Loss: 0.000237, PSRN_gt: 31.000982\n",
            "Iteration: 01958, Loss: 0.000234, PSRN_gt: 31.013547\n",
            "Iteration: 01959, Loss: 0.000230, PSRN_gt: 31.069826\n",
            "Iteration: 01960, Loss: 0.000216, PSRN_gt: 31.236065\n",
            "Iteration: 01961, Loss: 0.000213, PSRN_gt: 31.252648\n",
            "Iteration: 01962, Loss: 0.000214, PSRN_gt: 31.256639\n",
            "Iteration: 01963, Loss: 0.000198, PSRN_gt: 31.432811\n",
            "Iteration: 01964, Loss: 0.000196, PSRN_gt: 31.456637\n",
            "Iteration: 01965, Loss: 0.000201, PSRN_gt: 31.402731\n",
            "Iteration: 01966, Loss: 0.000191, PSRN_gt: 31.504155\n",
            "Iteration: 01967, Loss: 0.000185, PSRN_gt: 31.580950\n",
            "Iteration: 01968, Loss: 0.000186, PSRN_gt: 31.563997\n",
            "Iteration: 01969, Loss: 0.000183, PSRN_gt: 31.596859\n",
            "Iteration: 01970, Loss: 0.000178, PSRN_gt: 31.669306\n",
            "Iteration: 01971, Loss: 0.000177, PSRN_gt: 31.680116\n",
            "Iteration: 01972, Loss: 0.000177, PSRN_gt: 31.660266\n",
            "Iteration: 01973, Loss: 0.000173, PSRN_gt: 31.724662\n",
            "Iteration: 01974, Loss: 0.000170, PSRN_gt: 31.752783\n",
            "Iteration: 01975, Loss: 0.000172, PSRN_gt: 31.725392\n",
            "Iteration: 01976, Loss: 0.000170, PSRN_gt: 31.759454\n",
            "Iteration: 01977, Loss: 0.000167, PSRN_gt: 31.777586\n",
            "Iteration: 01978, Loss: 0.000167, PSRN_gt: 31.787982\n",
            "Iteration: 01979, Loss: 0.000166, PSRN_gt: 31.802220\n",
            "Iteration: 01980, Loss: 0.000164, PSRN_gt: 31.808173\n",
            "Iteration: 01981, Loss: 0.000164, PSRN_gt: 31.820758\n",
            "Iteration: 01982, Loss: 0.000163, PSRN_gt: 31.838779\n",
            "Iteration: 01983, Loss: 0.000163, PSRN_gt: 31.830268\n",
            "Iteration: 01984, Loss: 0.000164, PSRN_gt: 31.801623\n",
            "Iteration: 01985, Loss: 0.000165, PSRN_gt: 31.810620\n",
            "Iteration: 01986, Loss: 0.000168, PSRN_gt: 31.760183\n",
            "Iteration: 01987, Loss: 0.000171, PSRN_gt: 31.728140\n",
            "Iteration: 01988, Loss: 0.000175, PSRN_gt: 31.660104\n",
            "Iteration: 01989, Loss: 0.000179, PSRN_gt: 31.635620\n",
            "Iteration: 01990, Loss: 0.000179, PSRN_gt: 31.616593\n",
            "Iteration: 01991, Loss: 0.000177, PSRN_gt: 31.641513\n",
            "Iteration: 01992, Loss: 0.000173, PSRN_gt: 31.697276\n",
            "Iteration: 01993, Loss: 0.000171, PSRN_gt: 31.700335\n",
            "Iteration: 01994, Loss: 0.000173, PSRN_gt: 31.715151\n",
            "Iteration: 01995, Loss: 0.000176, PSRN_gt: 31.628524\n",
            "Iteration: 01996, Loss: 0.000180, PSRN_gt: 31.637716\n",
            "Iteration: 01997, Loss: 0.000179, PSRN_gt: 31.582037\n",
            "Iteration: 01998, Loss: 0.000176, PSRN_gt: 31.672311\n",
            "Iteration: 01999, Loss: 0.000174, PSRN_gt: 31.664611\n",
            "Iteration: 02000, Loss: 0.000175, PSRN_gt: 31.666115\n",
            "Iteration: 02001, Loss: 0.000178, PSRN_gt: 31.638071\n",
            "Iteration: 02002, Loss: 0.000181, PSRN_gt: 31.580407\n",
            "Iteration: 02003, Loss: 0.000179, PSRN_gt: 31.633758\n",
            "Iteration: 02004, Loss: 0.000178, PSRN_gt: 31.609756\n",
            "Iteration: 02005, Loss: 0.000185, PSRN_gt: 31.541882\n",
            "Iteration: 02006, Loss: 0.000202, PSRN_gt: 31.350192\n",
            "Iteration: 02007, Loss: 0.000221, PSRN_gt: 31.108137\n",
            "Iteration: 02008, Loss: 0.000238, PSRN_gt: 30.975681\n",
            "Iteration: 02009, Loss: 0.000250, PSRN_gt: 30.806716\n",
            "Iteration: 02010, Loss: 0.000258, PSRN_gt: 30.750143\n",
            "Iteration: 02011, Loss: 0.000251, PSRN_gt: 30.812411\n",
            "Iteration: 02012, Loss: 0.000233, PSRN_gt: 31.020354\n",
            "Iteration: 02013, Loss: 0.000214, PSRN_gt: 31.219821\n",
            "Iteration: 02014, Loss: 0.000225, PSRN_gt: 31.110627\n",
            "Iteration: 02015, Loss: 0.000239, PSRN_gt: 30.953435\n",
            "Iteration: 02016, Loss: 0.000233, PSRN_gt: 31.021401\n",
            "Iteration: 02017, Loss: 0.000222, PSRN_gt: 31.148399\n",
            "Iteration: 02018, Loss: 0.000217, PSRN_gt: 31.175182\n",
            "Iteration: 02019, Loss: 0.000204, PSRN_gt: 31.359533\n",
            "Iteration: 02020, Loss: 0.000191, PSRN_gt: 31.483074\n",
            "Iteration: 02021, Loss: 0.000192, PSRN_gt: 31.473887\n",
            "Iteration: 02022, Loss: 0.000188, PSRN_gt: 31.535813\n",
            "Iteration: 02023, Loss: 0.000183, PSRN_gt: 31.586982\n",
            "Iteration: 02024, Loss: 0.000184, PSRN_gt: 31.569055\n",
            "Iteration: 02025, Loss: 0.000182, PSRN_gt: 31.599011\n",
            "Iteration: 02026, Loss: 0.000177, PSRN_gt: 31.668796\n",
            "Iteration: 02027, Loss: 0.000174, PSRN_gt: 31.691222\n",
            "Iteration: 02028, Loss: 0.000172, PSRN_gt: 31.722645\n",
            "Iteration: 02029, Loss: 0.000169, PSRN_gt: 31.755186\n",
            "Iteration: 02030, Loss: 0.000167, PSRN_gt: 31.762136\n",
            "Iteration: 02031, Loss: 0.000168, PSRN_gt: 31.773264\n",
            "Iteration: 02032, Loss: 0.000166, PSRN_gt: 31.767803\n",
            "Iteration: 02033, Loss: 0.000164, PSRN_gt: 31.793658\n",
            "Iteration: 02034, Loss: 0.000164, PSRN_gt: 31.813948\n",
            "Iteration: 02035, Loss: 0.000161, PSRN_gt: 31.830014\n",
            "Iteration: 02036, Loss: 0.000159, PSRN_gt: 31.847445\n",
            "Iteration: 02037, Loss: 0.000159, PSRN_gt: 31.871827\n",
            "Iteration: 02038, Loss: 0.000158, PSRN_gt: 31.870857\n",
            "Iteration: 02039, Loss: 0.000157, PSRN_gt: 31.881614\n",
            "Iteration: 02040, Loss: 0.000158, PSRN_gt: 31.875737\n",
            "Iteration: 02041, Loss: 0.000158, PSRN_gt: 31.865456\n",
            "Iteration: 02042, Loss: 0.000158, PSRN_gt: 31.866136\n",
            "Iteration: 02043, Loss: 0.000160, PSRN_gt: 31.847256\n",
            "Iteration: 02044, Loss: 0.000163, PSRN_gt: 31.796192\n",
            "Iteration: 02045, Loss: 0.000166, PSRN_gt: 31.768506\n",
            "Iteration: 02046, Loss: 0.000171, PSRN_gt: 31.691739\n",
            "Iteration: 02047, Loss: 0.000178, PSRN_gt: 31.615006\n",
            "Iteration: 02048, Loss: 0.000185, PSRN_gt: 31.523483\n",
            "Iteration: 02049, Loss: 0.000196, PSRN_gt: 31.411623\n",
            "Iteration: 02050, Loss: 0.000209, PSRN_gt: 31.225513\n",
            "Iteration: 02051, Loss: 0.000226, PSRN_gt: 31.077472\n",
            "Iteration: 02052, Loss: 0.000241, PSRN_gt: 30.880738\n",
            "Iteration: 02053, Loss: 0.000248, PSRN_gt: 30.862782\n",
            "Iteration: 02054, Loss: 0.000235, PSRN_gt: 30.941621\n",
            "Iteration: 02055, Loss: 0.000216, PSRN_gt: 31.191870\n",
            "Iteration: 02056, Loss: 0.000207, PSRN_gt: 31.254947\n",
            "Iteration: 02057, Loss: 0.000213, PSRN_gt: 31.217437\n",
            "Iteration: 02058, Loss: 0.000218, PSRN_gt: 31.172858\n",
            "Iteration: 02059, Loss: 0.000207, PSRN_gt: 31.272700\n",
            "Iteration: 02060, Loss: 0.000195, PSRN_gt: 31.450139\n",
            "Iteration: 02061, Loss: 0.000195, PSRN_gt: 31.418159\n",
            "Iteration: 02062, Loss: 0.000202, PSRN_gt: 31.344419\n",
            "Iteration: 02063, Loss: 0.000197, PSRN_gt: 31.399810\n",
            "Iteration: 02064, Loss: 0.000188, PSRN_gt: 31.503565\n",
            "Iteration: 02065, Loss: 0.000185, PSRN_gt: 31.559197\n",
            "Iteration: 02066, Loss: 0.000182, PSRN_gt: 31.569602\n",
            "Iteration: 02067, Loss: 0.000180, PSRN_gt: 31.611161\n",
            "Iteration: 02068, Loss: 0.000180, PSRN_gt: 31.607945\n",
            "Iteration: 02069, Loss: 0.000178, PSRN_gt: 31.624070\n",
            "Iteration: 02070, Loss: 0.000172, PSRN_gt: 31.715252\n",
            "Iteration: 02071, Loss: 0.000173, PSRN_gt: 31.682690\n",
            "Iteration: 02072, Loss: 0.000175, PSRN_gt: 31.642930\n",
            "Iteration: 02073, Loss: 0.000172, PSRN_gt: 31.715517\n",
            "Iteration: 02074, Loss: 0.000168, PSRN_gt: 31.733124\n",
            "Iteration: 02075, Loss: 0.000168, PSRN_gt: 31.743378\n",
            "Iteration: 02076, Loss: 0.000168, PSRN_gt: 31.738829\n",
            "Iteration: 02077, Loss: 0.000167, PSRN_gt: 31.750131\n",
            "Iteration: 02078, Loss: 0.000166, PSRN_gt: 31.768180\n",
            "Iteration: 02079, Loss: 0.000164, PSRN_gt: 31.794842\n",
            "Iteration: 02080, Loss: 0.000165, PSRN_gt: 31.759702\n",
            "Iteration: 02081, Loss: 0.000165, PSRN_gt: 31.777612\n",
            "Iteration: 02082, Loss: 0.000165, PSRN_gt: 31.773276\n",
            "Iteration: 02083, Loss: 0.000167, PSRN_gt: 31.751051\n",
            "Iteration: 02084, Loss: 0.000168, PSRN_gt: 31.729526\n",
            "Iteration: 02085, Loss: 0.000169, PSRN_gt: 31.731629\n",
            "Iteration: 02086, Loss: 0.000170, PSRN_gt: 31.700865\n",
            "Iteration: 02087, Loss: 0.000172, PSRN_gt: 31.700271\n",
            "Iteration: 02088, Loss: 0.000171, PSRN_gt: 31.689675\n",
            "Iteration: 02089, Loss: 0.000170, PSRN_gt: 31.706378\n",
            "Iteration: 02090, Loss: 0.000170, PSRN_gt: 31.698953\n",
            "Iteration: 02091, Loss: 0.000172, PSRN_gt: 31.678987\n",
            "Iteration: 02092, Loss: 0.000180, PSRN_gt: 31.573477\n",
            "Iteration: 02093, Loss: 0.000192, PSRN_gt: 31.434398\n",
            "Iteration: 02094, Loss: 0.000211, PSRN_gt: 31.219595\n",
            "Iteration: 02095, Loss: 0.000223, PSRN_gt: 31.076072\n",
            "Iteration: 02096, Loss: 0.000233, PSRN_gt: 30.982007\n",
            "Iteration: 02097, Loss: 0.000226, PSRN_gt: 31.017250\n",
            "Iteration: 02098, Loss: 0.000216, PSRN_gt: 31.195187\n",
            "Iteration: 02099, Loss: 0.000201, PSRN_gt: 31.322109\n",
            "Iteration: 02100, Loss: 0.000194, PSRN_gt: 31.445665\n",
            "Iteration: 02101, Loss: 0.000193, PSRN_gt: 31.430313\n",
            "Iteration: 02102, Loss: 0.000200, PSRN_gt: 31.351571\n",
            "Iteration: 02103, Loss: 0.000206, PSRN_gt: 31.305937\n",
            "Iteration: 02104, Loss: 0.000198, PSRN_gt: 31.370752\n",
            "Iteration: 02105, Loss: 0.000188, PSRN_gt: 31.506667\n",
            "Iteration: 02106, Loss: 0.000187, PSRN_gt: 31.509597\n",
            "Iteration: 02107, Loss: 0.000189, PSRN_gt: 31.488606\n",
            "Iteration: 02108, Loss: 0.000186, PSRN_gt: 31.520478\n",
            "Iteration: 02109, Loss: 0.000183, PSRN_gt: 31.568450\n",
            "Iteration: 02110, Loss: 0.000183, PSRN_gt: 31.569667\n",
            "Iteration: 02111, Loss: 0.000181, PSRN_gt: 31.582068\n",
            "Iteration: 02112, Loss: 0.000183, PSRN_gt: 31.570026\n",
            "Iteration: 02113, Loss: 0.000178, PSRN_gt: 31.608726\n",
            "Iteration: 02114, Loss: 0.000175, PSRN_gt: 31.662025\n",
            "Iteration: 02115, Loss: 0.000175, PSRN_gt: 31.639666\n",
            "Iteration: 02116, Loss: 0.000173, PSRN_gt: 31.660502\n",
            "Iteration: 02117, Loss: 0.000169, PSRN_gt: 31.726263\n",
            "Iteration: 02118, Loss: 0.000167, PSRN_gt: 31.749028\n",
            "Iteration: 02119, Loss: 0.000165, PSRN_gt: 31.766759\n",
            "Iteration: 02120, Loss: 0.000161, PSRN_gt: 31.831360\n",
            "Iteration: 02121, Loss: 0.000157, PSRN_gt: 31.870766\n",
            "Iteration: 02122, Loss: 0.000157, PSRN_gt: 31.870731\n",
            "Iteration: 02123, Loss: 0.000155, PSRN_gt: 31.881854\n",
            "Iteration: 02124, Loss: 0.000154, PSRN_gt: 31.922019\n",
            "Iteration: 02125, Loss: 0.000153, PSRN_gt: 31.907516\n",
            "Iteration: 02126, Loss: 0.000153, PSRN_gt: 31.921829\n",
            "Iteration: 02127, Loss: 0.000154, PSRN_gt: 31.902471\n",
            "Iteration: 02128, Loss: 0.000156, PSRN_gt: 31.878789\n",
            "Iteration: 02129, Loss: 0.000157, PSRN_gt: 31.860099\n",
            "Iteration: 02130, Loss: 0.000163, PSRN_gt: 31.790965\n",
            "Iteration: 02131, Loss: 0.000171, PSRN_gt: 31.692114\n",
            "Iteration: 02132, Loss: 0.000181, PSRN_gt: 31.548369\n",
            "Iteration: 02133, Loss: 0.000193, PSRN_gt: 31.434197\n",
            "Iteration: 02134, Loss: 0.000199, PSRN_gt: 31.321185\n",
            "Iteration: 02135, Loss: 0.000202, PSRN_gt: 31.329416\n",
            "Iteration: 02136, Loss: 0.000200, PSRN_gt: 31.309176\n",
            "Iteration: 02137, Loss: 0.000200, PSRN_gt: 31.354331\n",
            "Iteration: 02138, Loss: 0.000205, PSRN_gt: 31.257628\n",
            "Iteration: 02139, Loss: 0.000215, PSRN_gt: 31.186835\n",
            "Iteration: 02140, Loss: 0.000217, PSRN_gt: 31.169779\n",
            "Iteration: 02141, Loss: 0.000218, PSRN_gt: 31.120656\n",
            "Iteration: 02142, Loss: 0.000213, PSRN_gt: 31.206140\n",
            "Iteration: 02143, Loss: 0.000207, PSRN_gt: 31.224520\n",
            "Iteration: 02144, Loss: 0.000197, PSRN_gt: 31.427249\n",
            "Iteration: 02145, Loss: 0.000191, PSRN_gt: 31.464333\n",
            "Iteration: 02146, Loss: 0.000193, PSRN_gt: 31.410387\n",
            "Iteration: 02147, Loss: 0.000192, PSRN_gt: 31.479578\n",
            "Iteration: 02148, Loss: 0.000186, PSRN_gt: 31.518422\n",
            "Iteration: 02149, Loss: 0.000180, PSRN_gt: 31.586704\n",
            "Iteration: 02150, Loss: 0.000182, PSRN_gt: 31.582388\n",
            "Iteration: 02151, Loss: 0.000183, PSRN_gt: 31.539309\n",
            "Iteration: 02152, Loss: 0.000178, PSRN_gt: 31.615142\n",
            "Iteration: 02153, Loss: 0.000176, PSRN_gt: 31.655702\n",
            "Iteration: 02154, Loss: 0.000177, PSRN_gt: 31.626145\n",
            "Iteration: 02155, Loss: 0.000171, PSRN_gt: 31.715147\n",
            "Iteration: 02156, Loss: 0.000165, PSRN_gt: 31.773558\n",
            "Iteration: 02157, Loss: 0.000166, PSRN_gt: 31.741979\n",
            "Iteration: 02158, Loss: 0.000163, PSRN_gt: 31.796269\n",
            "Iteration: 02159, Loss: 0.000159, PSRN_gt: 31.843416\n",
            "Iteration: 02160, Loss: 0.000158, PSRN_gt: 31.838742\n",
            "Iteration: 02161, Loss: 0.000157, PSRN_gt: 31.866400\n",
            "Iteration: 02162, Loss: 0.000155, PSRN_gt: 31.879491\n",
            "Iteration: 02163, Loss: 0.000154, PSRN_gt: 31.900994\n",
            "Iteration: 02164, Loss: 0.000153, PSRN_gt: 31.894486\n",
            "Iteration: 02165, Loss: 0.000152, PSRN_gt: 31.924812\n",
            "Iteration: 02166, Loss: 0.000152, PSRN_gt: 31.913348\n",
            "Iteration: 02167, Loss: 0.000154, PSRN_gt: 31.899299\n",
            "Iteration: 02168, Loss: 0.000153, PSRN_gt: 31.897218\n",
            "Iteration: 02169, Loss: 0.000155, PSRN_gt: 31.897272\n",
            "Iteration: 02170, Loss: 0.000157, PSRN_gt: 31.832438\n",
            "Iteration: 02171, Loss: 0.000161, PSRN_gt: 31.813155\n",
            "Iteration: 02172, Loss: 0.000165, PSRN_gt: 31.741767\n",
            "Iteration: 02173, Loss: 0.000174, PSRN_gt: 31.646469\n",
            "Iteration: 02174, Loss: 0.000183, PSRN_gt: 31.524239\n",
            "Iteration: 02175, Loss: 0.000198, PSRN_gt: 31.358600\n",
            "Iteration: 02176, Loss: 0.000211, PSRN_gt: 31.195516\n",
            "Iteration: 02177, Loss: 0.000221, PSRN_gt: 31.092988\n",
            "Iteration: 02178, Loss: 0.000225, PSRN_gt: 31.060881\n",
            "Iteration: 02179, Loss: 0.000219, PSRN_gt: 31.117232\n",
            "Iteration: 02180, Loss: 0.000218, PSRN_gt: 31.153086\n",
            "Iteration: 02181, Loss: 0.000224, PSRN_gt: 31.048222\n",
            "Iteration: 02182, Loss: 0.000259, PSRN_gt: 30.715736\n",
            "Iteration: 02183, Loss: 0.000267, PSRN_gt: 30.617927\n",
            "Iteration: 02184, Loss: 0.000261, PSRN_gt: 30.694246\n",
            "Iteration: 02185, Loss: 0.000227, PSRN_gt: 31.050021\n",
            "Iteration: 02186, Loss: 0.000231, PSRN_gt: 31.009603\n",
            "Iteration: 02187, Loss: 0.000256, PSRN_gt: 30.759598\n",
            "Iteration: 02188, Loss: 0.000241, PSRN_gt: 30.838903\n",
            "Iteration: 02189, Loss: 0.000216, PSRN_gt: 31.191541\n",
            "Iteration: 02190, Loss: 0.000208, PSRN_gt: 31.254845\n",
            "Iteration: 02191, Loss: 0.000208, PSRN_gt: 31.241484\n",
            "Iteration: 02192, Loss: 0.000207, PSRN_gt: 31.306880\n",
            "Iteration: 02193, Loss: 0.000195, PSRN_gt: 31.406356\n",
            "Iteration: 02194, Loss: 0.000187, PSRN_gt: 31.490541\n",
            "Iteration: 02195, Loss: 0.000182, PSRN_gt: 31.569997\n",
            "Iteration: 02196, Loss: 0.000178, PSRN_gt: 31.626977\n",
            "Iteration: 02197, Loss: 0.000176, PSRN_gt: 31.634392\n",
            "Iteration: 02198, Loss: 0.000173, PSRN_gt: 31.665159\n",
            "Iteration: 02199, Loss: 0.000171, PSRN_gt: 31.704992\n",
            "Iteration: 02200, Loss: 0.000167, PSRN_gt: 31.739033\n",
            "Iteration: 02201, Loss: 0.000166, PSRN_gt: 31.762758\n",
            "Iteration: 02202, Loss: 0.000164, PSRN_gt: 31.783970\n",
            "Iteration: 02203, Loss: 0.000160, PSRN_gt: 31.815196\n",
            "Iteration: 02204, Loss: 0.000160, PSRN_gt: 31.822942\n",
            "Iteration: 02205, Loss: 0.000157, PSRN_gt: 31.857487\n",
            "Iteration: 02206, Loss: 0.000155, PSRN_gt: 31.876074\n",
            "Iteration: 02207, Loss: 0.000154, PSRN_gt: 31.906040\n",
            "Iteration: 02208, Loss: 0.000153, PSRN_gt: 31.925475\n",
            "Iteration: 02209, Loss: 0.000151, PSRN_gt: 31.937490\n",
            "Iteration: 02210, Loss: 0.000150, PSRN_gt: 31.942523\n",
            "Iteration: 02211, Loss: 0.000149, PSRN_gt: 31.957439\n",
            "Iteration: 02212, Loss: 0.000148, PSRN_gt: 31.968785\n",
            "Iteration: 02213, Loss: 0.000149, PSRN_gt: 31.964016\n",
            "Iteration: 02214, Loss: 0.000149, PSRN_gt: 31.957816\n",
            "Iteration: 02215, Loss: 0.000150, PSRN_gt: 31.947669\n",
            "Iteration: 02216, Loss: 0.000152, PSRN_gt: 31.913607\n",
            "Iteration: 02217, Loss: 0.000154, PSRN_gt: 31.879873\n",
            "Iteration: 02218, Loss: 0.000160, PSRN_gt: 31.796823\n",
            "Iteration: 02219, Loss: 0.000170, PSRN_gt: 31.682872\n",
            "Iteration: 02220, Loss: 0.000183, PSRN_gt: 31.510402\n",
            "Iteration: 02221, Loss: 0.000204, PSRN_gt: 31.270226\n",
            "Iteration: 02222, Loss: 0.000222, PSRN_gt: 31.053563\n",
            "Iteration: 02223, Loss: 0.000232, PSRN_gt: 30.961260\n",
            "Iteration: 02224, Loss: 0.000214, PSRN_gt: 31.148463\n",
            "Iteration: 02225, Loss: 0.000188, PSRN_gt: 31.449237\n",
            "Iteration: 02226, Loss: 0.000169, PSRN_gt: 31.694206\n",
            "Iteration: 02227, Loss: 0.000176, PSRN_gt: 31.624513\n",
            "Iteration: 02228, Loss: 0.000194, PSRN_gt: 31.395764\n",
            "Iteration: 02229, Loss: 0.000197, PSRN_gt: 31.371166\n",
            "Iteration: 02230, Loss: 0.000179, PSRN_gt: 31.570072\n",
            "Iteration: 02231, Loss: 0.000164, PSRN_gt: 31.775238\n",
            "Iteration: 02232, Loss: 0.000167, PSRN_gt: 31.718491\n",
            "Iteration: 02233, Loss: 0.000179, PSRN_gt: 31.585237\n",
            "Iteration: 02234, Loss: 0.000178, PSRN_gt: 31.598086\n",
            "Iteration: 02235, Loss: 0.000169, PSRN_gt: 31.709493\n",
            "Iteration: 02236, Loss: 0.000168, PSRN_gt: 31.720604\n",
            "Iteration: 02237, Loss: 0.000177, PSRN_gt: 31.600876\n",
            "Iteration: 02238, Loss: 0.000178, PSRN_gt: 31.586116\n",
            "Iteration: 02239, Loss: 0.000171, PSRN_gt: 31.663735\n",
            "Iteration: 02240, Loss: 0.000167, PSRN_gt: 31.729701\n",
            "Iteration: 02241, Loss: 0.000171, PSRN_gt: 31.690486\n",
            "Iteration: 02242, Loss: 0.000170, PSRN_gt: 31.683281\n",
            "Iteration: 02243, Loss: 0.000162, PSRN_gt: 31.796509\n",
            "Iteration: 02244, Loss: 0.000156, PSRN_gt: 31.853008\n",
            "Iteration: 02245, Loss: 0.000157, PSRN_gt: 31.850438\n",
            "Iteration: 02246, Loss: 0.000156, PSRN_gt: 31.866875\n",
            "Iteration: 02247, Loss: 0.000151, PSRN_gt: 31.929043\n",
            "Iteration: 02248, Loss: 0.000149, PSRN_gt: 31.946164\n",
            "Iteration: 02249, Loss: 0.000151, PSRN_gt: 31.911363\n",
            "Iteration: 02250, Loss: 0.000151, PSRN_gt: 31.919476\n",
            "Iteration: 02251, Loss: 0.000150, PSRN_gt: 31.931230\n",
            "Iteration: 02252, Loss: 0.000150, PSRN_gt: 31.932821\n",
            "Iteration: 02253, Loss: 0.000151, PSRN_gt: 31.921023\n",
            "Iteration: 02254, Loss: 0.000152, PSRN_gt: 31.919106\n",
            "Iteration: 02255, Loss: 0.000153, PSRN_gt: 31.881624\n",
            "Iteration: 02256, Loss: 0.000155, PSRN_gt: 31.858921\n",
            "Iteration: 02257, Loss: 0.000158, PSRN_gt: 31.829753\n",
            "Iteration: 02258, Loss: 0.000163, PSRN_gt: 31.752993\n",
            "Iteration: 02259, Loss: 0.000169, PSRN_gt: 31.691387\n",
            "Iteration: 02260, Loss: 0.000172, PSRN_gt: 31.637319\n",
            "Iteration: 02261, Loss: 0.000173, PSRN_gt: 31.642243\n",
            "Iteration: 02262, Loss: 0.000173, PSRN_gt: 31.616249\n",
            "Iteration: 02263, Loss: 0.000172, PSRN_gt: 31.656533\n",
            "Iteration: 02264, Loss: 0.000172, PSRN_gt: 31.627051\n",
            "Iteration: 02265, Loss: 0.000178, PSRN_gt: 31.593484\n",
            "Iteration: 02266, Loss: 0.000187, PSRN_gt: 31.458078\n",
            "Iteration: 02267, Loss: 0.000196, PSRN_gt: 31.377873\n",
            "Iteration: 02268, Loss: 0.000198, PSRN_gt: 31.331796\n",
            "Iteration: 02269, Loss: 0.000194, PSRN_gt: 31.388721\n",
            "Iteration: 02270, Loss: 0.000189, PSRN_gt: 31.468124\n",
            "Iteration: 02271, Loss: 0.000189, PSRN_gt: 31.439520\n",
            "Iteration: 02272, Loss: 0.000189, PSRN_gt: 31.501233\n",
            "Iteration: 02273, Loss: 0.000183, PSRN_gt: 31.514079\n",
            "Iteration: 02274, Loss: 0.000183, PSRN_gt: 31.533200\n",
            "Iteration: 02275, Loss: 0.000187, PSRN_gt: 31.503917\n",
            "Iteration: 02276, Loss: 0.000186, PSRN_gt: 31.481150\n",
            "Iteration: 02277, Loss: 0.000179, PSRN_gt: 31.581433\n",
            "Iteration: 02278, Loss: 0.000173, PSRN_gt: 31.649837\n",
            "Iteration: 02279, Loss: 0.000168, PSRN_gt: 31.715500\n",
            "Iteration: 02280, Loss: 0.000165, PSRN_gt: 31.741381\n",
            "Iteration: 02281, Loss: 0.000165, PSRN_gt: 31.757739\n",
            "Iteration: 02282, Loss: 0.000161, PSRN_gt: 31.794493\n",
            "Iteration: 02283, Loss: 0.000155, PSRN_gt: 31.882807\n",
            "Iteration: 02284, Loss: 0.000153, PSRN_gt: 31.912028\n",
            "Iteration: 02285, Loss: 0.000152, PSRN_gt: 31.901923\n",
            "Iteration: 02286, Loss: 0.000151, PSRN_gt: 31.918034\n",
            "Iteration: 02287, Loss: 0.000150, PSRN_gt: 31.939680\n",
            "Iteration: 02288, Loss: 0.000147, PSRN_gt: 31.968680\n",
            "Iteration: 02289, Loss: 0.000148, PSRN_gt: 31.961263\n",
            "Iteration: 02290, Loss: 0.000146, PSRN_gt: 31.967176\n",
            "Iteration: 02291, Loss: 0.000144, PSRN_gt: 32.001762\n",
            "Iteration: 02292, Loss: 0.000146, PSRN_gt: 31.979035\n",
            "Iteration: 02293, Loss: 0.000146, PSRN_gt: 31.978478\n",
            "Iteration: 02294, Loss: 0.000146, PSRN_gt: 31.959075\n",
            "Iteration: 02295, Loss: 0.000150, PSRN_gt: 31.940276\n",
            "Iteration: 02296, Loss: 0.000153, PSRN_gt: 31.866224\n",
            "Iteration: 02297, Loss: 0.000158, PSRN_gt: 31.822165\n",
            "Iteration: 02298, Loss: 0.000165, PSRN_gt: 31.727074\n",
            "Iteration: 02299, Loss: 0.000173, PSRN_gt: 31.628408\n",
            "Iteration: 02300, Loss: 0.000178, PSRN_gt: 31.551934\n",
            "Iteration: 02301, Loss: 0.000183, PSRN_gt: 31.510321\n",
            "Iteration: 02302, Loss: 0.000183, PSRN_gt: 31.492527\n",
            "Iteration: 02303, Loss: 0.000181, PSRN_gt: 31.536920\n",
            "Iteration: 02304, Loss: 0.000179, PSRN_gt: 31.550629\n",
            "Iteration: 02305, Loss: 0.000179, PSRN_gt: 31.574083\n",
            "Iteration: 02306, Loss: 0.000181, PSRN_gt: 31.528317\n",
            "Iteration: 02307, Loss: 0.000186, PSRN_gt: 31.486604\n",
            "Iteration: 02308, Loss: 0.000186, PSRN_gt: 31.472721\n",
            "Iteration: 02309, Loss: 0.000184, PSRN_gt: 31.494266\n",
            "Iteration: 02310, Loss: 0.000181, PSRN_gt: 31.559625\n",
            "Iteration: 02311, Loss: 0.000180, PSRN_gt: 31.544182\n",
            "Iteration: 02312, Loss: 0.000185, PSRN_gt: 31.521159\n",
            "Iteration: 02313, Loss: 0.000180, PSRN_gt: 31.547604\n",
            "Iteration: 02314, Loss: 0.000179, PSRN_gt: 31.587395\n",
            "Iteration: 02315, Loss: 0.000178, PSRN_gt: 31.575873\n",
            "Iteration: 02316, Loss: 0.000176, PSRN_gt: 31.613237\n",
            "Iteration: 02317, Loss: 0.000174, PSRN_gt: 31.625840\n",
            "Iteration: 02318, Loss: 0.000168, PSRN_gt: 31.686878\n",
            "Iteration: 02319, Loss: 0.000169, PSRN_gt: 31.676306\n",
            "Iteration: 02320, Loss: 0.000176, PSRN_gt: 31.615605\n",
            "Iteration: 02321, Loss: 0.000174, PSRN_gt: 31.599986\n",
            "Iteration: 02322, Loss: 0.000174, PSRN_gt: 31.641339\n",
            "Iteration: 02323, Loss: 0.000177, PSRN_gt: 31.570485\n",
            "Iteration: 02324, Loss: 0.000179, PSRN_gt: 31.558025\n",
            "Iteration: 02325, Loss: 0.000181, PSRN_gt: 31.524844\n",
            "Iteration: 02326, Loss: 0.000183, PSRN_gt: 31.514576\n",
            "Iteration: 02327, Loss: 0.000177, PSRN_gt: 31.572949\n",
            "Iteration: 02328, Loss: 0.000174, PSRN_gt: 31.638823\n",
            "Iteration: 02329, Loss: 0.000167, PSRN_gt: 31.696354\n",
            "Iteration: 02330, Loss: 0.000160, PSRN_gt: 31.804421\n",
            "Iteration: 02331, Loss: 0.000157, PSRN_gt: 31.826939\n",
            "Iteration: 02332, Loss: 0.000158, PSRN_gt: 31.816709\n",
            "Iteration: 02333, Loss: 0.000156, PSRN_gt: 31.846841\n",
            "Iteration: 02334, Loss: 0.000156, PSRN_gt: 31.835759\n",
            "Iteration: 02335, Loss: 0.000160, PSRN_gt: 31.802339\n",
            "Iteration: 02336, Loss: 0.000161, PSRN_gt: 31.769505\n",
            "Iteration: 02337, Loss: 0.000159, PSRN_gt: 31.816817\n",
            "Iteration: 02338, Loss: 0.000157, PSRN_gt: 31.816349\n",
            "Iteration: 02339, Loss: 0.000157, PSRN_gt: 31.843251\n",
            "Iteration: 02340, Loss: 0.000155, PSRN_gt: 31.829521\n",
            "Iteration: 02341, Loss: 0.000153, PSRN_gt: 31.888958\n",
            "Iteration: 02342, Loss: 0.000151, PSRN_gt: 31.898008\n",
            "Iteration: 02343, Loss: 0.000151, PSRN_gt: 31.893832\n",
            "Iteration: 02344, Loss: 0.000153, PSRN_gt: 31.871538\n",
            "Iteration: 02345, Loss: 0.000155, PSRN_gt: 31.839589\n",
            "Iteration: 02346, Loss: 0.000159, PSRN_gt: 31.818376\n",
            "Iteration: 02347, Loss: 0.000159, PSRN_gt: 31.774434\n",
            "Iteration: 02348, Loss: 0.000161, PSRN_gt: 31.779621\n",
            "Iteration: 02349, Loss: 0.000161, PSRN_gt: 31.752483\n",
            "Iteration: 02350, Loss: 0.000159, PSRN_gt: 31.814098\n",
            "Iteration: 02351, Loss: 0.000155, PSRN_gt: 31.841292\n",
            "Iteration: 02352, Loss: 0.000153, PSRN_gt: 31.891531\n",
            "Iteration: 02353, Loss: 0.000151, PSRN_gt: 31.885749\n",
            "Iteration: 02354, Loss: 0.000153, PSRN_gt: 31.888868\n",
            "Iteration: 02355, Loss: 0.000155, PSRN_gt: 31.839062\n",
            "Iteration: 02356, Loss: 0.000157, PSRN_gt: 31.816114\n",
            "Iteration: 02357, Loss: 0.000156, PSRN_gt: 31.824288\n",
            "Iteration: 02358, Loss: 0.000155, PSRN_gt: 31.840914\n",
            "Iteration: 02359, Loss: 0.000157, PSRN_gt: 31.819947\n",
            "Iteration: 02360, Loss: 0.000161, PSRN_gt: 31.775563\n",
            "Iteration: 02361, Loss: 0.000163, PSRN_gt: 31.755160\n",
            "Iteration: 02362, Loss: 0.000164, PSRN_gt: 31.723187\n",
            "Iteration: 02363, Loss: 0.000164, PSRN_gt: 31.745745\n",
            "Iteration: 02364, Loss: 0.000159, PSRN_gt: 31.786091\n",
            "Iteration: 02365, Loss: 0.000157, PSRN_gt: 31.816276\n",
            "Iteration: 02366, Loss: 0.000155, PSRN_gt: 31.857402\n",
            "Iteration: 02367, Loss: 0.000156, PSRN_gt: 31.827952\n",
            "Iteration: 02368, Loss: 0.000159, PSRN_gt: 31.803024\n",
            "Iteration: 02369, Loss: 0.000161, PSRN_gt: 31.756701\n",
            "Iteration: 02370, Loss: 0.000164, PSRN_gt: 31.740880\n",
            "Iteration: 02371, Loss: 0.000165, PSRN_gt: 31.712847\n",
            "Iteration: 02372, Loss: 0.000165, PSRN_gt: 31.721265\n",
            "Iteration: 02373, Loss: 0.000166, PSRN_gt: 31.710510\n",
            "Iteration: 02374, Loss: 0.000171, PSRN_gt: 31.638264\n",
            "Iteration: 02375, Loss: 0.000175, PSRN_gt: 31.606373\n",
            "Iteration: 02376, Loss: 0.000170, PSRN_gt: 31.661027\n",
            "Iteration: 02377, Loss: 0.000167, PSRN_gt: 31.689011\n",
            "Iteration: 02378, Loss: 0.000170, PSRN_gt: 31.669585\n",
            "Iteration: 02379, Loss: 0.000173, PSRN_gt: 31.599611\n",
            "Iteration: 02380, Loss: 0.000173, PSRN_gt: 31.627397\n",
            "Iteration: 02381, Loss: 0.000173, PSRN_gt: 31.624948\n",
            "Iteration: 02382, Loss: 0.000176, PSRN_gt: 31.586163\n",
            "Iteration: 02383, Loss: 0.000181, PSRN_gt: 31.532548\n",
            "Iteration: 02384, Loss: 0.000182, PSRN_gt: 31.493335\n",
            "Iteration: 02385, Loss: 0.000186, PSRN_gt: 31.475823\n",
            "Iteration: 02386, Loss: 0.000192, PSRN_gt: 31.361388\n",
            "Iteration: 02387, Loss: 0.000193, PSRN_gt: 31.393841\n",
            "Iteration: 02388, Loss: 0.000187, PSRN_gt: 31.449431\n",
            "Iteration: 02389, Loss: 0.000179, PSRN_gt: 31.564997\n",
            "Iteration: 02390, Loss: 0.000173, PSRN_gt: 31.637846\n",
            "Iteration: 02391, Loss: 0.000168, PSRN_gt: 31.686703\n",
            "Iteration: 02392, Loss: 0.000171, PSRN_gt: 31.664046\n",
            "Iteration: 02393, Loss: 0.000170, PSRN_gt: 31.632719\n",
            "Iteration: 02394, Loss: 0.000168, PSRN_gt: 31.723552\n",
            "Iteration: 02395, Loss: 0.000168, PSRN_gt: 31.668978\n",
            "Iteration: 02396, Loss: 0.000169, PSRN_gt: 31.705308\n",
            "Iteration: 02397, Loss: 0.000168, PSRN_gt: 31.687127\n",
            "Iteration: 02398, Loss: 0.000163, PSRN_gt: 31.746867\n",
            "Iteration: 02399, Loss: 0.000158, PSRN_gt: 31.831193\n",
            "Iteration: 02400, Loss: 0.000154, PSRN_gt: 31.861965\n",
            "Iteration: 02401, Loss: 0.000155, PSRN_gt: 31.849483\n",
            "Iteration: 02402, Loss: 0.000153, PSRN_gt: 31.857453\n",
            "Iteration: 02403, Loss: 0.000154, PSRN_gt: 31.875373\n",
            "Iteration: 02404, Loss: 0.000151, PSRN_gt: 31.897064\n",
            "Iteration: 02405, Loss: 0.000148, PSRN_gt: 31.942516\n",
            "Iteration: 02406, Loss: 0.000146, PSRN_gt: 31.964177\n",
            "Iteration: 02407, Loss: 0.000145, PSRN_gt: 31.989137\n",
            "Iteration: 02408, Loss: 0.000142, PSRN_gt: 32.017027\n",
            "Iteration: 02409, Loss: 0.000142, PSRN_gt: 32.011068\n",
            "Iteration: 02410, Loss: 0.000142, PSRN_gt: 32.016857\n",
            "Iteration: 02411, Loss: 0.000142, PSRN_gt: 31.993828\n",
            "Iteration: 02412, Loss: 0.000144, PSRN_gt: 31.995241\n",
            "Iteration: 02413, Loss: 0.000145, PSRN_gt: 31.945771\n",
            "Iteration: 02414, Loss: 0.000148, PSRN_gt: 31.941880\n",
            "Iteration: 02415, Loss: 0.000152, PSRN_gt: 31.856066\n",
            "Iteration: 02416, Loss: 0.000159, PSRN_gt: 31.794981\n",
            "Iteration: 02417, Loss: 0.000164, PSRN_gt: 31.688565\n",
            "Iteration: 02418, Loss: 0.000174, PSRN_gt: 31.613155\n",
            "Iteration: 02419, Loss: 0.000179, PSRN_gt: 31.510921\n",
            "Iteration: 02420, Loss: 0.000186, PSRN_gt: 31.470659\n",
            "Iteration: 02421, Loss: 0.000187, PSRN_gt: 31.436463\n",
            "Iteration: 02422, Loss: 0.000180, PSRN_gt: 31.525504\n",
            "Iteration: 02423, Loss: 0.000170, PSRN_gt: 31.667105\n",
            "Iteration: 02424, Loss: 0.000163, PSRN_gt: 31.721545\n",
            "Iteration: 02425, Loss: 0.000163, PSRN_gt: 31.757980\n",
            "Iteration: 02426, Loss: 0.000164, PSRN_gt: 31.713641\n",
            "Iteration: 02427, Loss: 0.000171, PSRN_gt: 31.648948\n",
            "Iteration: 02428, Loss: 0.000171, PSRN_gt: 31.621547\n",
            "Iteration: 02429, Loss: 0.000167, PSRN_gt: 31.705654\n",
            "Iteration: 02430, Loss: 0.000160, PSRN_gt: 31.764540\n",
            "Iteration: 02431, Loss: 0.000158, PSRN_gt: 31.803505\n",
            "Iteration: 02432, Loss: 0.000163, PSRN_gt: 31.731364\n",
            "Iteration: 02433, Loss: 0.000168, PSRN_gt: 31.676180\n",
            "Iteration: 02434, Loss: 0.000172, PSRN_gt: 31.614050\n",
            "Iteration: 02435, Loss: 0.000173, PSRN_gt: 31.611436\n",
            "Iteration: 02436, Loss: 0.000177, PSRN_gt: 31.574390\n",
            "Iteration: 02437, Loss: 0.000179, PSRN_gt: 31.537321\n",
            "Iteration: 02438, Loss: 0.000176, PSRN_gt: 31.586190\n",
            "Iteration: 02439, Loss: 0.000171, PSRN_gt: 31.647518\n",
            "Iteration: 02440, Loss: 0.000171, PSRN_gt: 31.634294\n",
            "Iteration: 02441, Loss: 0.000167, PSRN_gt: 31.697406\n",
            "Iteration: 02442, Loss: 0.000160, PSRN_gt: 31.772749\n",
            "Iteration: 02443, Loss: 0.000160, PSRN_gt: 31.803429\n",
            "Iteration: 02444, Loss: 0.000161, PSRN_gt: 31.745070\n",
            "Iteration: 02445, Loss: 0.000159, PSRN_gt: 31.790842\n",
            "Iteration: 02446, Loss: 0.000154, PSRN_gt: 31.861166\n",
            "Iteration: 02447, Loss: 0.000150, PSRN_gt: 31.884835\n",
            "Iteration: 02448, Loss: 0.000147, PSRN_gt: 31.956243\n",
            "Iteration: 02449, Loss: 0.000147, PSRN_gt: 31.932350\n",
            "Iteration: 02450, Loss: 0.000146, PSRN_gt: 31.964125\n",
            "Iteration: 02451, Loss: 0.000143, PSRN_gt: 31.982045\n",
            "Iteration: 02452, Loss: 0.000143, PSRN_gt: 31.999042\n",
            "Iteration: 02453, Loss: 0.000143, PSRN_gt: 31.988924\n",
            "Iteration: 02454, Loss: 0.000142, PSRN_gt: 32.005953\n",
            "Iteration: 02455, Loss: 0.000142, PSRN_gt: 31.995433\n",
            "Iteration: 02456, Loss: 0.000143, PSRN_gt: 31.983866\n",
            "Iteration: 02457, Loss: 0.000145, PSRN_gt: 31.972588\n",
            "Iteration: 02458, Loss: 0.000148, PSRN_gt: 31.905259\n",
            "Iteration: 02459, Loss: 0.000149, PSRN_gt: 31.912227\n",
            "Iteration: 02460, Loss: 0.000151, PSRN_gt: 31.877031\n",
            "Iteration: 02461, Loss: 0.000154, PSRN_gt: 31.847921\n",
            "Iteration: 02462, Loss: 0.000158, PSRN_gt: 31.778241\n",
            "Iteration: 02463, Loss: 0.000162, PSRN_gt: 31.743006\n",
            "Iteration: 02464, Loss: 0.000167, PSRN_gt: 31.669142\n",
            "Iteration: 02465, Loss: 0.000174, PSRN_gt: 31.594447\n",
            "Iteration: 02466, Loss: 0.000175, PSRN_gt: 31.562317\n",
            "Iteration: 02467, Loss: 0.000174, PSRN_gt: 31.590044\n",
            "Iteration: 02468, Loss: 0.000169, PSRN_gt: 31.662395\n",
            "Iteration: 02469, Loss: 0.000168, PSRN_gt: 31.659028\n",
            "Iteration: 02470, Loss: 0.000173, PSRN_gt: 31.627411\n",
            "Iteration: 02471, Loss: 0.000181, PSRN_gt: 31.513260\n",
            "Iteration: 02472, Loss: 0.000189, PSRN_gt: 31.432233\n",
            "Iteration: 02473, Loss: 0.000185, PSRN_gt: 31.477893\n",
            "Iteration: 02474, Loss: 0.000177, PSRN_gt: 31.564134\n",
            "Iteration: 02475, Loss: 0.000169, PSRN_gt: 31.667938\n",
            "Iteration: 02476, Loss: 0.000174, PSRN_gt: 31.601381\n",
            "Iteration: 02477, Loss: 0.000183, PSRN_gt: 31.508637\n",
            "Iteration: 02478, Loss: 0.000178, PSRN_gt: 31.565573\n",
            "Iteration: 02479, Loss: 0.000170, PSRN_gt: 31.681026\n",
            "Iteration: 02480, Loss: 0.000174, PSRN_gt: 31.586225\n",
            "Iteration: 02481, Loss: 0.000181, PSRN_gt: 31.537168\n",
            "Iteration: 02482, Loss: 0.000172, PSRN_gt: 31.626817\n",
            "Iteration: 02483, Loss: 0.000167, PSRN_gt: 31.707166\n",
            "Iteration: 02484, Loss: 0.000163, PSRN_gt: 31.730966\n",
            "Iteration: 02485, Loss: 0.000156, PSRN_gt: 31.818600\n",
            "Iteration: 02486, Loss: 0.000153, PSRN_gt: 31.875049\n",
            "Iteration: 02487, Loss: 0.000150, PSRN_gt: 31.909429\n",
            "Iteration: 02488, Loss: 0.000148, PSRN_gt: 31.946496\n",
            "Iteration: 02489, Loss: 0.000150, PSRN_gt: 31.887490\n",
            "Iteration: 02490, Loss: 0.000148, PSRN_gt: 31.934822\n",
            "Iteration: 02491, Loss: 0.000147, PSRN_gt: 31.920244\n",
            "Iteration: 02492, Loss: 0.000148, PSRN_gt: 31.932062\n",
            "Iteration: 02493, Loss: 0.000147, PSRN_gt: 31.915062\n",
            "Iteration: 02494, Loss: 0.000147, PSRN_gt: 31.935672\n",
            "Iteration: 02495, Loss: 0.000146, PSRN_gt: 31.932224\n",
            "Iteration: 02496, Loss: 0.000145, PSRN_gt: 31.973042\n",
            "Iteration: 02497, Loss: 0.000143, PSRN_gt: 31.986484\n",
            "Iteration: 02498, Loss: 0.000142, PSRN_gt: 31.982760\n",
            "Iteration: 02499, Loss: 0.000142, PSRN_gt: 31.982298\n",
            "Iteration: 02500, Loss: 0.000142, PSRN_gt: 32.003565\n",
            "Iteration: 02501, Loss: 0.000142, PSRN_gt: 31.985581\n",
            "Iteration: 02502, Loss: 0.000144, PSRN_gt: 31.963214\n",
            "Iteration: 02503, Loss: 0.000148, PSRN_gt: 31.914800\n",
            "Iteration: 02504, Loss: 0.000151, PSRN_gt: 31.856814\n",
            "Iteration: 02505, Loss: 0.000156, PSRN_gt: 31.812940\n",
            "Iteration: 02506, Loss: 0.000161, PSRN_gt: 31.722696\n",
            "Iteration: 02507, Loss: 0.000168, PSRN_gt: 31.653023\n",
            "Iteration: 02508, Loss: 0.000174, PSRN_gt: 31.581046\n",
            "Iteration: 02509, Loss: 0.000180, PSRN_gt: 31.519776\n",
            "Iteration: 02510, Loss: 0.000181, PSRN_gt: 31.500836\n",
            "Iteration: 02511, Loss: 0.000177, PSRN_gt: 31.556308\n",
            "Iteration: 02512, Loss: 0.000170, PSRN_gt: 31.619312\n",
            "Iteration: 02513, Loss: 0.000163, PSRN_gt: 31.729668\n",
            "Iteration: 02514, Loss: 0.000162, PSRN_gt: 31.737152\n",
            "Iteration: 02515, Loss: 0.000168, PSRN_gt: 31.625776\n",
            "Iteration: 02516, Loss: 0.000177, PSRN_gt: 31.577658\n",
            "Iteration: 02517, Loss: 0.000176, PSRN_gt: 31.552233\n",
            "Iteration: 02518, Loss: 0.000167, PSRN_gt: 31.683458\n",
            "Iteration: 02519, Loss: 0.000156, PSRN_gt: 31.818690\n",
            "Iteration: 02520, Loss: 0.000153, PSRN_gt: 31.847327\n",
            "Iteration: 02521, Loss: 0.000155, PSRN_gt: 31.824680\n",
            "Iteration: 02522, Loss: 0.000157, PSRN_gt: 31.806881\n",
            "Iteration: 02523, Loss: 0.000150, PSRN_gt: 31.898689\n",
            "Iteration: 02524, Loss: 0.000145, PSRN_gt: 31.949415\n",
            "Iteration: 02525, Loss: 0.000148, PSRN_gt: 31.930143\n",
            "Iteration: 02526, Loss: 0.000152, PSRN_gt: 31.854159\n",
            "Iteration: 02527, Loss: 0.000147, PSRN_gt: 31.930899\n",
            "Iteration: 02528, Loss: 0.000140, PSRN_gt: 32.017966\n",
            "Iteration: 02529, Loss: 0.000142, PSRN_gt: 31.983168\n",
            "Iteration: 02530, Loss: 0.000144, PSRN_gt: 31.963973\n",
            "Iteration: 02531, Loss: 0.000143, PSRN_gt: 32.002164\n",
            "Iteration: 02532, Loss: 0.000143, PSRN_gt: 31.962335\n",
            "Iteration: 02533, Loss: 0.000148, PSRN_gt: 31.914093\n",
            "Iteration: 02534, Loss: 0.000151, PSRN_gt: 31.864383\n",
            "Iteration: 02535, Loss: 0.000155, PSRN_gt: 31.817599\n",
            "Iteration: 02536, Loss: 0.000159, PSRN_gt: 31.754200\n",
            "Iteration: 02537, Loss: 0.000161, PSRN_gt: 31.729675\n",
            "Iteration: 02538, Loss: 0.000163, PSRN_gt: 31.707147\n",
            "Iteration: 02539, Loss: 0.000159, PSRN_gt: 31.756716\n",
            "Iteration: 02540, Loss: 0.000155, PSRN_gt: 31.809445\n",
            "Iteration: 02541, Loss: 0.000154, PSRN_gt: 31.816379\n",
            "Iteration: 02542, Loss: 0.000156, PSRN_gt: 31.805923\n",
            "Iteration: 02543, Loss: 0.000158, PSRN_gt: 31.779257\n",
            "Iteration: 02544, Loss: 0.000163, PSRN_gt: 31.725338\n",
            "Iteration: 02545, Loss: 0.000165, PSRN_gt: 31.697928\n",
            "Iteration: 02546, Loss: 0.000162, PSRN_gt: 31.732467\n",
            "Iteration: 02547, Loss: 0.000158, PSRN_gt: 31.772997\n",
            "Iteration: 02548, Loss: 0.000156, PSRN_gt: 31.824598\n",
            "Iteration: 02549, Loss: 0.000153, PSRN_gt: 31.835021\n",
            "Iteration: 02550, Loss: 0.000150, PSRN_gt: 31.902041\n",
            "Iteration: 02551, Loss: 0.000150, PSRN_gt: 31.897746\n",
            "Iteration: 02552, Loss: 0.000150, PSRN_gt: 31.894100\n",
            "Iteration: 02553, Loss: 0.000149, PSRN_gt: 31.901899\n",
            "Iteration: 02554, Loss: 0.000147, PSRN_gt: 31.927288\n",
            "Iteration: 02555, Loss: 0.000143, PSRN_gt: 31.968543\n",
            "Iteration: 02556, Loss: 0.000141, PSRN_gt: 32.009186\n",
            "Iteration: 02557, Loss: 0.000141, PSRN_gt: 31.992002\n",
            "Iteration: 02558, Loss: 0.000142, PSRN_gt: 31.988460\n",
            "Iteration: 02559, Loss: 0.000142, PSRN_gt: 31.985651\n",
            "Iteration: 02560, Loss: 0.000140, PSRN_gt: 31.994714\n",
            "Iteration: 02561, Loss: 0.000140, PSRN_gt: 32.014668\n",
            "Iteration: 02562, Loss: 0.000140, PSRN_gt: 31.997009\n",
            "Iteration: 02563, Loss: 0.000142, PSRN_gt: 31.983418\n",
            "Iteration: 02564, Loss: 0.000144, PSRN_gt: 31.950465\n",
            "Iteration: 02565, Loss: 0.000145, PSRN_gt: 31.934644\n",
            "Iteration: 02566, Loss: 0.000147, PSRN_gt: 31.885393\n",
            "Iteration: 02567, Loss: 0.000148, PSRN_gt: 31.912549\n",
            "Iteration: 02568, Loss: 0.000149, PSRN_gt: 31.872251\n",
            "Iteration: 02569, Loss: 0.000151, PSRN_gt: 31.847192\n",
            "Iteration: 02570, Loss: 0.000154, PSRN_gt: 31.830044\n",
            "Iteration: 02571, Loss: 0.000154, PSRN_gt: 31.803656\n",
            "Iteration: 02572, Loss: 0.000154, PSRN_gt: 31.813768\n",
            "Iteration: 02573, Loss: 0.000157, PSRN_gt: 31.773997\n",
            "Iteration: 02574, Loss: 0.000159, PSRN_gt: 31.754572\n",
            "Iteration: 02575, Loss: 0.000163, PSRN_gt: 31.703483\n",
            "Iteration: 02576, Loss: 0.000165, PSRN_gt: 31.706175\n",
            "Iteration: 02577, Loss: 0.000165, PSRN_gt: 31.682572\n",
            "Iteration: 02578, Loss: 0.000162, PSRN_gt: 31.736064\n",
            "Iteration: 02579, Loss: 0.000159, PSRN_gt: 31.764206\n",
            "Iteration: 02580, Loss: 0.000158, PSRN_gt: 31.766356\n",
            "Iteration: 02581, Loss: 0.000162, PSRN_gt: 31.712174\n",
            "Iteration: 02582, Loss: 0.000166, PSRN_gt: 31.686632\n",
            "Iteration: 02583, Loss: 0.000163, PSRN_gt: 31.716403\n",
            "Iteration: 02584, Loss: 0.000161, PSRN_gt: 31.708772\n",
            "Iteration: 02585, Loss: 0.000168, PSRN_gt: 31.671660\n",
            "Iteration: 02586, Loss: 0.000168, PSRN_gt: 31.638940\n",
            "Iteration: 02587, Loss: 0.000163, PSRN_gt: 31.708709\n",
            "Iteration: 02588, Loss: 0.000167, PSRN_gt: 31.676974\n",
            "Iteration: 02589, Loss: 0.000179, PSRN_gt: 31.503976\n",
            "Iteration: 02590, Loss: 0.000191, PSRN_gt: 31.379523\n",
            "Iteration: 02591, Loss: 0.000208, PSRN_gt: 31.198940\n",
            "Iteration: 02592, Loss: 0.000213, PSRN_gt: 31.113524\n",
            "Iteration: 02593, Loss: 0.000215, PSRN_gt: 31.128441\n",
            "Iteration: 02594, Loss: 0.000200, PSRN_gt: 31.263571\n",
            "Iteration: 02595, Loss: 0.000188, PSRN_gt: 31.448817\n",
            "Iteration: 02596, Loss: 0.000171, PSRN_gt: 31.617048\n",
            "Iteration: 02597, Loss: 0.000170, PSRN_gt: 31.640862\n",
            "Iteration: 02598, Loss: 0.000172, PSRN_gt: 31.632819\n",
            "Iteration: 02599, Loss: 0.000168, PSRN_gt: 31.655847\n",
            "Iteration: 02600, Loss: 0.000167, PSRN_gt: 31.703344\n",
            "Iteration: 02601, Loss: 0.000163, PSRN_gt: 31.712621\n",
            "Iteration: 02602, Loss: 0.000154, PSRN_gt: 31.853266\n",
            "Iteration: 02603, Loss: 0.000144, PSRN_gt: 31.980487\n",
            "Iteration: 02604, Loss: 0.000145, PSRN_gt: 31.950332\n",
            "Iteration: 02605, Loss: 0.000147, PSRN_gt: 31.936398\n",
            "Iteration: 02606, Loss: 0.000144, PSRN_gt: 31.952484\n",
            "Iteration: 02607, Loss: 0.000143, PSRN_gt: 31.991469\n",
            "Iteration: 02608, Loss: 0.000140, PSRN_gt: 32.016158\n",
            "Iteration: 02609, Loss: 0.000135, PSRN_gt: 32.068857\n",
            "Iteration: 02610, Loss: 0.000133, PSRN_gt: 32.114612\n",
            "Iteration: 02611, Loss: 0.000134, PSRN_gt: 32.088407\n",
            "Iteration: 02612, Loss: 0.000134, PSRN_gt: 32.103917\n",
            "Iteration: 02613, Loss: 0.000131, PSRN_gt: 32.114416\n",
            "Iteration: 02614, Loss: 0.000130, PSRN_gt: 32.151349\n",
            "Iteration: 02615, Loss: 0.000129, PSRN_gt: 32.141199\n",
            "Iteration: 02616, Loss: 0.000128, PSRN_gt: 32.171657\n",
            "Iteration: 02617, Loss: 0.000127, PSRN_gt: 32.172657\n",
            "Iteration: 02618, Loss: 0.000127, PSRN_gt: 32.170275\n",
            "Iteration: 02619, Loss: 0.000127, PSRN_gt: 32.183090\n",
            "Iteration: 02620, Loss: 0.000127, PSRN_gt: 32.165729\n",
            "Iteration: 02621, Loss: 0.000127, PSRN_gt: 32.153364\n",
            "Iteration: 02622, Loss: 0.000129, PSRN_gt: 32.146796\n",
            "Iteration: 02623, Loss: 0.000131, PSRN_gt: 32.095122\n",
            "Iteration: 02624, Loss: 0.000135, PSRN_gt: 32.066485\n",
            "Iteration: 02625, Loss: 0.000142, PSRN_gt: 31.938790\n",
            "Iteration: 02626, Loss: 0.000152, PSRN_gt: 31.841823\n",
            "Iteration: 02627, Loss: 0.000167, PSRN_gt: 31.616844\n",
            "Iteration: 02628, Loss: 0.000182, PSRN_gt: 31.476602\n",
            "Iteration: 02629, Loss: 0.000194, PSRN_gt: 31.286589\n",
            "Iteration: 02630, Loss: 0.000195, PSRN_gt: 31.326503\n",
            "Iteration: 02631, Loss: 0.000185, PSRN_gt: 31.426011\n",
            "Iteration: 02632, Loss: 0.000169, PSRN_gt: 31.625448\n",
            "Iteration: 02633, Loss: 0.000163, PSRN_gt: 31.721103\n",
            "Iteration: 02634, Loss: 0.000173, PSRN_gt: 31.556168\n",
            "Iteration: 02635, Loss: 0.000182, PSRN_gt: 31.497578\n",
            "Iteration: 02636, Loss: 0.000175, PSRN_gt: 31.529765\n",
            "Iteration: 02637, Loss: 0.000161, PSRN_gt: 31.779186\n",
            "Iteration: 02638, Loss: 0.000158, PSRN_gt: 31.759901\n",
            "Iteration: 02639, Loss: 0.000174, PSRN_gt: 31.585826\n",
            "Iteration: 02640, Loss: 0.000180, PSRN_gt: 31.522595\n",
            "Iteration: 02641, Loss: 0.000175, PSRN_gt: 31.578433\n",
            "Iteration: 02642, Loss: 0.000167, PSRN_gt: 31.659719\n",
            "Iteration: 02643, Loss: 0.000173, PSRN_gt: 31.605772\n",
            "Iteration: 02644, Loss: 0.000176, PSRN_gt: 31.568272\n",
            "Iteration: 02645, Loss: 0.000168, PSRN_gt: 31.645164\n",
            "Iteration: 02646, Loss: 0.000161, PSRN_gt: 31.760953\n",
            "Iteration: 02647, Loss: 0.000162, PSRN_gt: 31.710759\n",
            "Iteration: 02648, Loss: 0.000163, PSRN_gt: 31.735462\n",
            "Iteration: 02649, Loss: 0.000155, PSRN_gt: 31.827957\n",
            "Iteration: 02650, Loss: 0.000150, PSRN_gt: 31.894796\n",
            "Iteration: 02651, Loss: 0.000153, PSRN_gt: 31.825957\n",
            "Iteration: 02652, Loss: 0.000151, PSRN_gt: 31.880039\n",
            "Iteration: 02653, Loss: 0.000148, PSRN_gt: 31.904764\n",
            "Iteration: 02654, Loss: 0.000151, PSRN_gt: 31.882654\n",
            "Iteration: 02655, Loss: 0.000149, PSRN_gt: 31.903956\n",
            "Iteration: 02656, Loss: 0.000144, PSRN_gt: 31.952741\n",
            "Iteration: 02657, Loss: 0.000142, PSRN_gt: 31.971282\n",
            "Iteration: 02658, Loss: 0.000141, PSRN_gt: 32.004636\n",
            "Iteration: 02659, Loss: 0.000137, PSRN_gt: 32.030728\n",
            "Iteration: 02660, Loss: 0.000136, PSRN_gt: 32.053542\n",
            "Iteration: 02661, Loss: 0.000135, PSRN_gt: 32.079601\n",
            "Iteration: 02662, Loss: 0.000132, PSRN_gt: 32.092305\n",
            "Iteration: 02663, Loss: 0.000132, PSRN_gt: 32.100032\n",
            "Iteration: 02664, Loss: 0.000131, PSRN_gt: 32.126670\n",
            "Iteration: 02665, Loss: 0.000131, PSRN_gt: 32.110504\n",
            "Iteration: 02666, Loss: 0.000130, PSRN_gt: 32.127426\n",
            "Iteration: 02667, Loss: 0.000130, PSRN_gt: 32.142082\n",
            "Iteration: 02668, Loss: 0.000130, PSRN_gt: 32.114938\n",
            "Iteration: 02669, Loss: 0.000131, PSRN_gt: 32.115716\n",
            "Iteration: 02670, Loss: 0.000131, PSRN_gt: 32.105101\n",
            "Iteration: 02671, Loss: 0.000133, PSRN_gt: 32.074627\n",
            "Iteration: 02672, Loss: 0.000134, PSRN_gt: 32.063701\n",
            "Iteration: 02673, Loss: 0.000137, PSRN_gt: 32.026044\n",
            "Iteration: 02674, Loss: 0.000142, PSRN_gt: 31.954912\n",
            "Iteration: 02675, Loss: 0.000148, PSRN_gt: 31.869795\n",
            "Iteration: 02676, Loss: 0.000153, PSRN_gt: 31.822363\n",
            "Iteration: 02677, Loss: 0.000157, PSRN_gt: 31.761347\n",
            "Iteration: 02678, Loss: 0.000159, PSRN_gt: 31.740560\n",
            "Iteration: 02679, Loss: 0.000158, PSRN_gt: 31.735747\n",
            "Iteration: 02680, Loss: 0.000159, PSRN_gt: 31.724051\n",
            "Iteration: 02681, Loss: 0.000164, PSRN_gt: 31.672107\n",
            "Iteration: 02682, Loss: 0.000167, PSRN_gt: 31.621698\n",
            "Iteration: 02683, Loss: 0.000174, PSRN_gt: 31.582503\n",
            "Iteration: 02684, Loss: 0.000175, PSRN_gt: 31.515243\n",
            "Iteration: 02685, Loss: 0.000182, PSRN_gt: 31.485973\n",
            "Iteration: 02686, Loss: 0.000179, PSRN_gt: 31.484881\n",
            "Iteration: 02687, Loss: 0.000181, PSRN_gt: 31.490742\n",
            "Iteration: 02688, Loss: 0.000190, PSRN_gt: 31.387003\n",
            "Iteration: 02689, Loss: 0.000206, PSRN_gt: 31.211013\n",
            "Iteration: 02690, Loss: 0.000204, PSRN_gt: 31.205530\n",
            "Iteration: 02691, Loss: 0.000182, PSRN_gt: 31.498408\n",
            "Iteration: 02692, Loss: 0.000170, PSRN_gt: 31.606904\n",
            "Iteration: 02693, Loss: 0.000177, PSRN_gt: 31.533958\n",
            "Iteration: 02694, Loss: 0.000169, PSRN_gt: 31.660218\n",
            "Iteration: 02695, Loss: 0.000156, PSRN_gt: 31.807213\n",
            "Iteration: 02696, Loss: 0.000158, PSRN_gt: 31.799788\n",
            "Iteration: 02697, Loss: 0.000153, PSRN_gt: 31.831545\n",
            "Iteration: 02698, Loss: 0.000148, PSRN_gt: 31.921157\n",
            "Iteration: 02699, Loss: 0.000148, PSRN_gt: 31.915286\n",
            "Iteration: 02700, Loss: 0.000143, PSRN_gt: 31.940806\n",
            "Iteration: 02701, Loss: 0.000142, PSRN_gt: 32.002504\n",
            "Iteration: 02702, Loss: 0.000139, PSRN_gt: 32.026064\n",
            "Iteration: 02703, Loss: 0.000136, PSRN_gt: 32.037739\n",
            "Iteration: 02704, Loss: 0.000134, PSRN_gt: 32.081981\n",
            "Iteration: 02705, Loss: 0.000134, PSRN_gt: 32.094538\n",
            "Iteration: 02706, Loss: 0.000132, PSRN_gt: 32.099828\n",
            "Iteration: 02707, Loss: 0.000130, PSRN_gt: 32.127046\n",
            "Iteration: 02708, Loss: 0.000129, PSRN_gt: 32.143029\n",
            "Iteration: 02709, Loss: 0.000130, PSRN_gt: 32.127524\n",
            "Iteration: 02710, Loss: 0.000129, PSRN_gt: 32.135258\n",
            "Iteration: 02711, Loss: 0.000130, PSRN_gt: 32.118742\n",
            "Iteration: 02712, Loss: 0.000135, PSRN_gt: 32.046954\n",
            "Iteration: 02713, Loss: 0.000141, PSRN_gt: 31.966804\n",
            "Iteration: 02714, Loss: 0.000153, PSRN_gt: 31.792620\n",
            "Iteration: 02715, Loss: 0.000171, PSRN_gt: 31.596348\n",
            "Iteration: 02716, Loss: 0.000194, PSRN_gt: 31.295775\n",
            "Iteration: 02717, Loss: 0.000211, PSRN_gt: 31.127145\n",
            "Iteration: 02718, Loss: 0.000208, PSRN_gt: 31.140579\n",
            "Iteration: 02719, Loss: 0.000182, PSRN_gt: 31.478503\n",
            "Iteration: 02720, Loss: 0.000153, PSRN_gt: 31.790257\n",
            "Iteration: 02721, Loss: 0.000153, PSRN_gt: 31.835203\n",
            "Iteration: 02722, Loss: 0.000175, PSRN_gt: 31.531488\n",
            "Iteration: 02723, Loss: 0.000186, PSRN_gt: 31.419109\n",
            "Iteration: 02724, Loss: 0.000165, PSRN_gt: 31.675765\n",
            "Iteration: 02725, Loss: 0.000142, PSRN_gt: 31.942537\n",
            "Iteration: 02726, Loss: 0.000144, PSRN_gt: 31.945300\n",
            "Iteration: 02727, Loss: 0.000158, PSRN_gt: 31.739391\n",
            "Iteration: 02728, Loss: 0.000156, PSRN_gt: 31.789741\n",
            "Iteration: 02729, Loss: 0.000141, PSRN_gt: 31.986132\n",
            "Iteration: 02730, Loss: 0.000133, PSRN_gt: 32.092985\n",
            "Iteration: 02731, Loss: 0.000139, PSRN_gt: 32.002280\n",
            "Iteration: 02732, Loss: 0.000141, PSRN_gt: 31.979640\n",
            "Iteration: 02733, Loss: 0.000134, PSRN_gt: 32.073602\n",
            "Iteration: 02734, Loss: 0.000127, PSRN_gt: 32.154428\n",
            "Iteration: 02735, Loss: 0.000129, PSRN_gt: 32.135038\n",
            "Iteration: 02736, Loss: 0.000132, PSRN_gt: 32.098918\n",
            "Iteration: 02737, Loss: 0.000131, PSRN_gt: 32.111017\n",
            "Iteration: 02738, Loss: 0.000127, PSRN_gt: 32.171935\n",
            "Iteration: 02739, Loss: 0.000124, PSRN_gt: 32.214089\n",
            "Iteration: 02740, Loss: 0.000125, PSRN_gt: 32.183756\n",
            "Iteration: 02741, Loss: 0.000126, PSRN_gt: 32.186758\n",
            "Iteration: 02742, Loss: 0.000124, PSRN_gt: 32.186802\n",
            "Iteration: 02743, Loss: 0.000121, PSRN_gt: 32.231218\n",
            "Iteration: 02744, Loss: 0.000121, PSRN_gt: 32.250560\n",
            "Iteration: 02745, Loss: 0.000122, PSRN_gt: 32.227696\n",
            "Iteration: 02746, Loss: 0.000122, PSRN_gt: 32.219084\n",
            "Iteration: 02747, Loss: 0.000122, PSRN_gt: 32.217452\n",
            "Iteration: 02748, Loss: 0.000123, PSRN_gt: 32.200163\n",
            "Iteration: 02749, Loss: 0.000124, PSRN_gt: 32.190885\n",
            "Iteration: 02750, Loss: 0.000127, PSRN_gt: 32.135749\n",
            "Iteration: 02751, Loss: 0.000132, PSRN_gt: 32.079728\n",
            "Iteration: 02752, Loss: 0.000140, PSRN_gt: 31.969601\n",
            "Iteration: 02753, Loss: 0.000150, PSRN_gt: 31.843907\n",
            "Iteration: 02754, Loss: 0.000161, PSRN_gt: 31.716199\n",
            "Iteration: 02755, Loss: 0.000167, PSRN_gt: 31.638381\n",
            "Iteration: 02756, Loss: 0.000168, PSRN_gt: 31.611285\n",
            "Iteration: 02757, Loss: 0.000166, PSRN_gt: 31.634767\n",
            "Iteration: 02758, Loss: 0.000171, PSRN_gt: 31.588147\n",
            "Iteration: 02759, Loss: 0.000185, PSRN_gt: 31.402832\n",
            "Iteration: 02760, Loss: 0.000190, PSRN_gt: 31.397648\n",
            "Iteration: 02761, Loss: 0.000183, PSRN_gt: 31.420807\n",
            "Iteration: 02762, Loss: 0.000171, PSRN_gt: 31.618424\n",
            "Iteration: 02763, Loss: 0.000170, PSRN_gt: 31.612856\n",
            "Iteration: 02764, Loss: 0.000181, PSRN_gt: 31.474434\n",
            "Iteration: 02765, Loss: 0.000187, PSRN_gt: 31.419295\n",
            "Iteration: 02766, Loss: 0.000174, PSRN_gt: 31.548257\n",
            "Iteration: 02767, Loss: 0.000166, PSRN_gt: 31.674326\n",
            "Iteration: 02768, Loss: 0.000164, PSRN_gt: 31.686914\n",
            "Iteration: 02769, Loss: 0.000159, PSRN_gt: 31.758717\n",
            "Iteration: 02770, Loss: 0.000152, PSRN_gt: 31.836464\n",
            "Iteration: 02771, Loss: 0.000150, PSRN_gt: 31.879162\n",
            "Iteration: 02772, Loss: 0.000146, PSRN_gt: 31.902651\n",
            "Iteration: 02773, Loss: 0.000143, PSRN_gt: 31.963605\n",
            "Iteration: 02774, Loss: 0.000141, PSRN_gt: 31.992100\n",
            "Iteration: 02775, Loss: 0.000138, PSRN_gt: 32.009789\n",
            "Iteration: 02776, Loss: 0.000136, PSRN_gt: 32.056858\n",
            "Iteration: 02777, Loss: 0.000134, PSRN_gt: 32.067948\n",
            "Iteration: 02778, Loss: 0.000133, PSRN_gt: 32.100128\n",
            "Iteration: 02779, Loss: 0.000131, PSRN_gt: 32.118363\n",
            "Iteration: 02780, Loss: 0.000129, PSRN_gt: 32.128711\n",
            "Iteration: 02781, Loss: 0.000127, PSRN_gt: 32.156975\n",
            "Iteration: 02782, Loss: 0.000128, PSRN_gt: 32.137904\n",
            "Iteration: 02783, Loss: 0.000128, PSRN_gt: 32.143326\n",
            "Iteration: 02784, Loss: 0.000128, PSRN_gt: 32.132240\n",
            "Iteration: 02785, Loss: 0.000130, PSRN_gt: 32.105994\n",
            "Iteration: 02786, Loss: 0.000135, PSRN_gt: 32.033192\n",
            "Iteration: 02787, Loss: 0.000142, PSRN_gt: 31.945095\n",
            "Iteration: 02788, Loss: 0.000152, PSRN_gt: 31.797365\n",
            "Iteration: 02789, Loss: 0.000165, PSRN_gt: 31.644577\n",
            "Iteration: 02790, Loss: 0.000177, PSRN_gt: 31.490501\n",
            "Iteration: 02791, Loss: 0.000183, PSRN_gt: 31.450464\n",
            "Iteration: 02792, Loss: 0.000174, PSRN_gt: 31.503296\n",
            "Iteration: 02793, Loss: 0.000157, PSRN_gt: 31.760309\n",
            "Iteration: 02794, Loss: 0.000138, PSRN_gt: 31.974364\n",
            "Iteration: 02795, Loss: 0.000133, PSRN_gt: 32.091825\n",
            "Iteration: 02796, Loss: 0.000142, PSRN_gt: 31.938657\n",
            "Iteration: 02797, Loss: 0.000154, PSRN_gt: 31.817767\n",
            "Iteration: 02798, Loss: 0.000153, PSRN_gt: 31.793693\n",
            "Iteration: 02799, Loss: 0.000141, PSRN_gt: 31.957525\n",
            "Iteration: 02800, Loss: 0.000128, PSRN_gt: 32.152458\n",
            "Iteration: 02801, Loss: 0.000127, PSRN_gt: 32.154625\n",
            "Iteration: 02802, Loss: 0.000132, PSRN_gt: 32.083687\n",
            "Iteration: 02803, Loss: 0.000134, PSRN_gt: 32.050982\n",
            "Iteration: 02804, Loss: 0.000130, PSRN_gt: 32.110335\n",
            "Iteration: 02805, Loss: 0.000126, PSRN_gt: 32.170276\n",
            "Iteration: 02806, Loss: 0.000123, PSRN_gt: 32.193978\n",
            "Iteration: 02807, Loss: 0.000125, PSRN_gt: 32.195607\n",
            "Iteration: 02808, Loss: 0.000125, PSRN_gt: 32.163573\n",
            "Iteration: 02809, Loss: 0.000123, PSRN_gt: 32.208493\n",
            "Iteration: 02810, Loss: 0.000122, PSRN_gt: 32.209077\n",
            "Iteration: 02811, Loss: 0.000123, PSRN_gt: 32.191414\n",
            "Iteration: 02812, Loss: 0.000125, PSRN_gt: 32.161215\n",
            "Iteration: 02813, Loss: 0.000125, PSRN_gt: 32.167652\n",
            "Iteration: 02814, Loss: 0.000126, PSRN_gt: 32.154581\n",
            "Iteration: 02815, Loss: 0.000127, PSRN_gt: 32.136036\n",
            "Iteration: 02816, Loss: 0.000132, PSRN_gt: 32.077539\n",
            "Iteration: 02817, Loss: 0.000137, PSRN_gt: 32.000741\n",
            "Iteration: 02818, Loss: 0.000141, PSRN_gt: 31.947934\n",
            "Iteration: 02819, Loss: 0.000145, PSRN_gt: 31.887693\n",
            "Iteration: 02820, Loss: 0.000148, PSRN_gt: 31.859433\n",
            "Iteration: 02821, Loss: 0.000151, PSRN_gt: 31.794970\n",
            "Iteration: 02822, Loss: 0.000154, PSRN_gt: 31.787953\n",
            "Iteration: 02823, Loss: 0.000157, PSRN_gt: 31.712779\n",
            "Iteration: 02824, Loss: 0.000163, PSRN_gt: 31.705739\n",
            "Iteration: 02825, Loss: 0.000162, PSRN_gt: 31.653881\n",
            "Iteration: 02826, Loss: 0.000164, PSRN_gt: 31.680045\n",
            "Iteration: 02827, Loss: 0.000167, PSRN_gt: 31.598624\n",
            "Iteration: 02828, Loss: 0.000172, PSRN_gt: 31.576767\n",
            "Iteration: 02829, Loss: 0.000187, PSRN_gt: 31.365698\n",
            "Iteration: 02830, Loss: 0.000199, PSRN_gt: 31.258446\n",
            "Iteration: 02831, Loss: 0.000206, PSRN_gt: 31.162114\n",
            "Iteration: 02832, Loss: 0.000204, PSRN_gt: 31.204721\n",
            "Iteration: 02833, Loss: 0.000218, PSRN_gt: 31.050094\n",
            "Iteration: 02834, Loss: 0.000242, PSRN_gt: 30.811714\n",
            "Iteration: 02835, Loss: 0.000312, PSRN_gt: 30.201208\n",
            "Iteration: 02836, Loss: 0.000413, PSRN_gt: 29.379636\n",
            "Iteration: 02837, Loss: 0.000546, PSRN_gt: 28.538947\n",
            "Iteration: 02838, Loss: 0.000701, PSRN_gt: 27.654090\n",
            "Iteration: 02839, Loss: 0.000696, PSRN_gt: 27.654289\n",
            "Iteration: 02840, Loss: 0.000650, PSRN_gt: 27.973020\n",
            "Iteration: 02841, Loss: 0.000620, PSRN_gt: 28.097653\n",
            "Iteration: 02842, Loss: 0.000614, PSRN_gt: 28.152105\n",
            "Iteration: 02843, Loss: 0.000578, PSRN_gt: 28.349197\n",
            "Iteration: 02844, Loss: 0.000527, PSRN_gt: 28.702890\n",
            "Iteration: 02845, Loss: 0.000525, PSRN_gt: 28.685451\n",
            "Iteration: 02846, Loss: 0.000497, PSRN_gt: 28.885262\n",
            "Iteration: 02847, Loss: 0.000475, PSRN_gt: 29.008729\n",
            "Iteration: 02848, Loss: 0.000444, PSRN_gt: 29.222246\n",
            "Iteration: 02849, Loss: 0.000410, PSRN_gt: 29.520894\n",
            "Iteration: 02850, Loss: 0.000389, PSRN_gt: 29.678610\n",
            "Iteration: 02851, Loss: 0.000370, PSRN_gt: 29.831171\n",
            "Iteration: 02852, Loss: 0.000357, PSRN_gt: 29.965937\n",
            "Iteration: 02853, Loss: 0.000332, PSRN_gt: 30.171169\n",
            "Iteration: 02854, Loss: 0.000319, PSRN_gt: 30.274215\n",
            "Iteration: 02855, Loss: 0.000308, PSRN_gt: 30.378192\n",
            "Iteration: 02856, Loss: 0.000290, PSRN_gt: 30.559072\n",
            "Iteration: 02857, Loss: 0.000277, PSRN_gt: 30.659075\n",
            "Iteration: 02858, Loss: 0.000270, PSRN_gt: 30.717254\n",
            "Iteration: 02859, Loss: 0.000258, PSRN_gt: 30.835405\n",
            "Iteration: 02860, Loss: 0.000246, PSRN_gt: 30.963468\n",
            "Iteration: 02861, Loss: 0.000240, PSRN_gt: 31.046066\n",
            "Iteration: 02862, Loss: 0.000232, PSRN_gt: 31.131638\n",
            "Iteration: 02863, Loss: 0.000223, PSRN_gt: 31.222072\n",
            "Iteration: 02864, Loss: 0.000218, PSRN_gt: 31.288280\n",
            "Iteration: 02865, Loss: 0.000211, PSRN_gt: 31.346293\n",
            "Iteration: 02866, Loss: 0.000205, PSRN_gt: 31.389435\n",
            "Iteration: 02867, Loss: 0.000200, PSRN_gt: 31.459197\n",
            "Iteration: 02868, Loss: 0.000195, PSRN_gt: 31.516232\n",
            "Iteration: 02869, Loss: 0.000190, PSRN_gt: 31.571804\n",
            "Iteration: 02870, Loss: 0.000186, PSRN_gt: 31.618777\n",
            "Iteration: 02871, Loss: 0.000182, PSRN_gt: 31.651027\n",
            "Iteration: 02872, Loss: 0.000178, PSRN_gt: 31.696187\n",
            "Iteration: 02873, Loss: 0.000175, PSRN_gt: 31.728539\n",
            "Iteration: 02874, Loss: 0.000171, PSRN_gt: 31.764638\n",
            "Iteration: 02875, Loss: 0.000168, PSRN_gt: 31.796688\n",
            "Iteration: 02876, Loss: 0.000165, PSRN_gt: 31.836882\n",
            "Iteration: 02877, Loss: 0.000163, PSRN_gt: 31.866634\n",
            "Iteration: 02878, Loss: 0.000160, PSRN_gt: 31.888103\n",
            "Iteration: 02879, Loss: 0.000158, PSRN_gt: 31.918634\n",
            "Iteration: 02880, Loss: 0.000156, PSRN_gt: 31.943445\n",
            "Iteration: 02881, Loss: 0.000154, PSRN_gt: 31.966732\n",
            "Iteration: 02882, Loss: 0.000152, PSRN_gt: 31.984836\n",
            "Iteration: 02883, Loss: 0.000150, PSRN_gt: 32.004932\n",
            "Iteration: 02884, Loss: 0.000149, PSRN_gt: 32.027339\n",
            "Iteration: 02885, Loss: 0.000147, PSRN_gt: 32.043628\n",
            "Iteration: 02886, Loss: 0.000146, PSRN_gt: 32.056098\n",
            "Iteration: 02887, Loss: 0.000144, PSRN_gt: 32.073712\n",
            "Iteration: 02888, Loss: 0.000143, PSRN_gt: 32.085618\n",
            "Iteration: 02889, Loss: 0.000142, PSRN_gt: 32.105911\n",
            "Iteration: 02890, Loss: 0.000140, PSRN_gt: 32.112164\n",
            "Iteration: 02891, Loss: 0.000139, PSRN_gt: 32.123559\n",
            "Iteration: 02892, Loss: 0.000138, PSRN_gt: 32.132180\n",
            "Iteration: 02893, Loss: 0.000137, PSRN_gt: 32.146663\n",
            "Iteration: 02894, Loss: 0.000136, PSRN_gt: 32.159086\n",
            "Iteration: 02895, Loss: 0.000136, PSRN_gt: 32.167199\n",
            "Iteration: 02896, Loss: 0.000135, PSRN_gt: 32.172322\n",
            "Iteration: 02897, Loss: 0.000134, PSRN_gt: 32.181944\n",
            "Iteration: 02898, Loss: 0.000134, PSRN_gt: 32.181024\n",
            "Iteration: 02899, Loss: 0.000133, PSRN_gt: 32.181769\n",
            "Iteration: 02900, Loss: 0.000134, PSRN_gt: 32.172119\n",
            "Iteration: 02901, Loss: 0.000134, PSRN_gt: 32.173048\n",
            "Iteration: 02902, Loss: 0.000134, PSRN_gt: 32.158242\n",
            "Iteration: 02903, Loss: 0.000134, PSRN_gt: 32.171695\n",
            "Iteration: 02904, Loss: 0.000133, PSRN_gt: 32.167658\n",
            "Iteration: 02905, Loss: 0.000132, PSRN_gt: 32.185411\n",
            "Iteration: 02906, Loss: 0.000132, PSRN_gt: 32.178174\n",
            "Iteration: 02907, Loss: 0.000132, PSRN_gt: 32.173409\n",
            "Iteration: 02908, Loss: 0.000134, PSRN_gt: 32.149548\n",
            "Iteration: 02909, Loss: 0.000136, PSRN_gt: 32.124105\n",
            "Iteration: 02910, Loss: 0.000136, PSRN_gt: 32.126605\n",
            "Iteration: 02911, Loss: 0.000135, PSRN_gt: 32.128290\n",
            "Iteration: 02912, Loss: 0.000132, PSRN_gt: 32.184286\n",
            "Iteration: 02913, Loss: 0.000130, PSRN_gt: 32.193498\n",
            "Iteration: 02914, Loss: 0.000130, PSRN_gt: 32.206492\n",
            "Iteration: 02915, Loss: 0.000131, PSRN_gt: 32.173623\n",
            "Iteration: 02916, Loss: 0.000133, PSRN_gt: 32.164353\n",
            "Iteration: 02917, Loss: 0.000132, PSRN_gt: 32.158227\n",
            "Iteration: 02918, Loss: 0.000131, PSRN_gt: 32.193761\n",
            "Iteration: 02919, Loss: 0.000130, PSRN_gt: 32.160048\n",
            "Iteration: 02920, Loss: 0.000132, PSRN_gt: 32.175175\n",
            "Iteration: 02921, Loss: 0.000135, PSRN_gt: 32.094433\n",
            "Iteration: 02922, Loss: 0.000138, PSRN_gt: 32.081577\n",
            "Iteration: 02923, Loss: 0.000143, PSRN_gt: 31.996662\n",
            "Iteration: 02924, Loss: 0.000148, PSRN_gt: 31.943048\n",
            "Iteration: 02925, Loss: 0.000153, PSRN_gt: 31.852477\n",
            "Iteration: 02926, Loss: 0.000159, PSRN_gt: 31.804920\n",
            "Iteration: 02927, Loss: 0.000160, PSRN_gt: 31.765525\n",
            "Iteration: 02928, Loss: 0.000155, PSRN_gt: 31.845454\n",
            "Iteration: 02929, Loss: 0.000144, PSRN_gt: 31.983462\n",
            "Iteration: 02930, Loss: 0.000134, PSRN_gt: 32.115176\n",
            "Iteration: 02931, Loss: 0.000133, PSRN_gt: 32.140014\n",
            "Iteration: 02932, Loss: 0.000138, PSRN_gt: 32.058804\n",
            "Iteration: 02933, Loss: 0.000141, PSRN_gt: 32.028726\n",
            "Iteration: 02934, Loss: 0.000139, PSRN_gt: 32.033817\n",
            "Iteration: 02935, Loss: 0.000135, PSRN_gt: 32.106867\n",
            "Iteration: 02936, Loss: 0.000133, PSRN_gt: 32.131144\n",
            "Iteration: 02937, Loss: 0.000133, PSRN_gt: 32.150346\n",
            "Iteration: 02938, Loss: 0.000136, PSRN_gt: 32.073743\n",
            "Iteration: 02939, Loss: 0.000140, PSRN_gt: 32.060552\n",
            "Iteration: 02940, Loss: 0.000142, PSRN_gt: 31.987470\n",
            "Iteration: 02941, Loss: 0.000144, PSRN_gt: 31.993770\n",
            "Iteration: 02942, Loss: 0.000145, PSRN_gt: 31.964566\n",
            "Iteration: 02943, Loss: 0.000147, PSRN_gt: 31.931164\n",
            "Iteration: 02944, Loss: 0.000148, PSRN_gt: 31.919037\n",
            "Iteration: 02945, Loss: 0.000147, PSRN_gt: 31.948771\n",
            "Iteration: 02946, Loss: 0.000147, PSRN_gt: 31.905940\n",
            "Iteration: 02947, Loss: 0.000148, PSRN_gt: 31.956677\n",
            "Iteration: 02948, Loss: 0.000144, PSRN_gt: 31.956911\n",
            "Iteration: 02949, Loss: 0.000138, PSRN_gt: 32.076302\n",
            "Iteration: 02950, Loss: 0.000132, PSRN_gt: 32.125019\n",
            "Iteration: 02951, Loss: 0.000131, PSRN_gt: 32.143780\n",
            "Iteration: 02952, Loss: 0.000131, PSRN_gt: 32.148370\n",
            "Iteration: 02953, Loss: 0.000133, PSRN_gt: 32.119685\n",
            "Iteration: 02954, Loss: 0.000134, PSRN_gt: 32.117746\n",
            "Iteration: 02955, Loss: 0.000136, PSRN_gt: 32.066176\n",
            "Iteration: 02956, Loss: 0.000137, PSRN_gt: 32.071660\n",
            "Iteration: 02957, Loss: 0.000138, PSRN_gt: 32.035862\n",
            "Iteration: 02958, Loss: 0.000137, PSRN_gt: 32.073219\n",
            "Iteration: 02959, Loss: 0.000136, PSRN_gt: 32.059237\n",
            "Iteration: 02960, Loss: 0.000134, PSRN_gt: 32.115083\n",
            "Iteration: 02961, Loss: 0.000131, PSRN_gt: 32.138766\n",
            "Iteration: 02962, Loss: 0.000130, PSRN_gt: 32.157642\n",
            "Iteration: 02963, Loss: 0.000130, PSRN_gt: 32.162258\n",
            "Iteration: 02964, Loss: 0.000130, PSRN_gt: 32.137933\n",
            "Iteration: 02965, Loss: 0.000130, PSRN_gt: 32.176743\n",
            "Iteration: 02966, Loss: 0.000130, PSRN_gt: 32.130939\n",
            "Iteration: 02967, Loss: 0.000132, PSRN_gt: 32.136317\n",
            "Iteration: 02968, Loss: 0.000133, PSRN_gt: 32.082425\n",
            "Iteration: 02969, Loss: 0.000135, PSRN_gt: 32.096318\n",
            "Iteration: 02970, Loss: 0.000138, PSRN_gt: 32.028721\n",
            "Iteration: 02971, Loss: 0.000139, PSRN_gt: 32.037817\n",
            "Iteration: 02972, Loss: 0.000138, PSRN_gt: 32.023006\n",
            "Iteration: 02973, Loss: 0.000136, PSRN_gt: 32.060375\n",
            "Iteration: 02974, Loss: 0.000134, PSRN_gt: 32.095494\n",
            "Iteration: 02975, Loss: 0.000130, PSRN_gt: 32.139935\n",
            "Iteration: 02976, Loss: 0.000128, PSRN_gt: 32.163998\n",
            "Iteration: 02977, Loss: 0.000130, PSRN_gt: 32.150400\n",
            "Iteration: 02978, Loss: 0.000131, PSRN_gt: 32.124948\n",
            "Iteration: 02979, Loss: 0.000131, PSRN_gt: 32.118322\n",
            "Iteration: 02980, Loss: 0.000130, PSRN_gt: 32.142819\n",
            "Iteration: 02981, Loss: 0.000130, PSRN_gt: 32.132489\n",
            "Iteration: 02982, Loss: 0.000128, PSRN_gt: 32.167553\n",
            "Iteration: 02983, Loss: 0.000126, PSRN_gt: 32.186110\n",
            "Iteration: 02984, Loss: 0.000126, PSRN_gt: 32.198602\n",
            "Iteration: 02985, Loss: 0.000127, PSRN_gt: 32.179606\n",
            "Iteration: 02986, Loss: 0.000129, PSRN_gt: 32.146910\n",
            "Iteration: 02987, Loss: 0.000133, PSRN_gt: 32.086536\n",
            "Iteration: 02988, Loss: 0.000138, PSRN_gt: 32.021190\n",
            "Iteration: 02989, Loss: 0.000144, PSRN_gt: 31.953592\n",
            "Iteration: 02990, Loss: 0.000151, PSRN_gt: 31.859302\n",
            "Iteration: 02991, Loss: 0.000158, PSRN_gt: 31.757180\n",
            "Iteration: 02992, Loss: 0.000168, PSRN_gt: 31.649728\n",
            "Iteration: 02993, Loss: 0.000172, PSRN_gt: 31.580940\n",
            "Iteration: 02994, Loss: 0.000167, PSRN_gt: 31.654065\n",
            "Iteration: 02995, Loss: 0.000152, PSRN_gt: 31.833234\n",
            "Iteration: 02996, Loss: 0.000143, PSRN_gt: 31.978454\n",
            "Iteration: 02997, Loss: 0.000140, PSRN_gt: 32.011777\n",
            "Iteration: 02998, Loss: 0.000138, PSRN_gt: 32.028969\n",
            "Iteration: 02999, Loss: 0.000138, PSRN_gt: 32.038421\n",
            "Iteration: 03000, Loss: 0.000140, PSRN_gt: 32.004158\n",
            "Iteration: 03001, Loss: 0.000141, PSRN_gt: 31.993111\n",
            "Iteration: 03002, Loss: 0.000137, PSRN_gt: 32.060963\n",
            "Iteration: 03003, Loss: 0.000131, PSRN_gt: 32.111220\n",
            "Iteration: 03004, Loss: 0.000128, PSRN_gt: 32.186609\n",
            "Iteration: 03005, Loss: 0.000128, PSRN_gt: 32.162106\n",
            "Iteration: 03006, Loss: 0.000128, PSRN_gt: 32.172065\n",
            "Iteration: 03007, Loss: 0.000127, PSRN_gt: 32.168475\n",
            "Iteration: 03008, Loss: 0.000128, PSRN_gt: 32.175345\n",
            "Iteration: 03009, Loss: 0.000129, PSRN_gt: 32.133493\n",
            "Iteration: 03010, Loss: 0.000126, PSRN_gt: 32.211011\n",
            "Iteration: 03011, Loss: 0.000124, PSRN_gt: 32.208410\n",
            "Iteration: 03012, Loss: 0.000126, PSRN_gt: 32.210014\n",
            "Iteration: 03013, Loss: 0.000126, PSRN_gt: 32.184709\n",
            "Iteration: 03014, Loss: 0.000126, PSRN_gt: 32.202338\n",
            "Iteration: 03015, Loss: 0.000127, PSRN_gt: 32.153352\n",
            "Iteration: 03016, Loss: 0.000129, PSRN_gt: 32.152746\n",
            "Iteration: 03017, Loss: 0.000132, PSRN_gt: 32.083868\n",
            "Iteration: 03018, Loss: 0.000135, PSRN_gt: 32.079042\n",
            "Iteration: 03019, Loss: 0.000137, PSRN_gt: 32.009321\n",
            "Iteration: 03020, Loss: 0.000140, PSRN_gt: 31.999283\n",
            "Iteration: 03021, Loss: 0.000144, PSRN_gt: 31.913885\n",
            "Iteration: 03022, Loss: 0.000148, PSRN_gt: 31.876860\n",
            "Iteration: 03023, Loss: 0.000153, PSRN_gt: 31.801753\n",
            "Iteration: 03024, Loss: 0.000158, PSRN_gt: 31.744862\n",
            "Iteration: 03025, Loss: 0.000162, PSRN_gt: 31.693905\n",
            "Iteration: 03026, Loss: 0.000161, PSRN_gt: 31.704555\n",
            "Iteration: 03027, Loss: 0.000159, PSRN_gt: 31.748071\n",
            "Iteration: 03028, Loss: 0.000153, PSRN_gt: 31.810143\n",
            "Iteration: 03029, Loss: 0.000148, PSRN_gt: 31.905825\n",
            "Iteration: 03030, Loss: 0.000145, PSRN_gt: 31.913276\n",
            "Iteration: 03031, Loss: 0.000146, PSRN_gt: 31.927536\n",
            "Iteration: 03032, Loss: 0.000146, PSRN_gt: 31.892217\n",
            "Iteration: 03033, Loss: 0.000145, PSRN_gt: 31.944722\n",
            "Iteration: 03034, Loss: 0.000138, PSRN_gt: 32.017343\n",
            "Iteration: 03035, Loss: 0.000129, PSRN_gt: 32.156600\n",
            "Iteration: 03036, Loss: 0.000126, PSRN_gt: 32.175027\n",
            "Iteration: 03037, Loss: 0.000127, PSRN_gt: 32.171084\n",
            "Iteration: 03038, Loss: 0.000128, PSRN_gt: 32.146873\n",
            "Iteration: 03039, Loss: 0.000128, PSRN_gt: 32.140254\n",
            "Iteration: 03040, Loss: 0.000126, PSRN_gt: 32.192062\n",
            "Iteration: 03041, Loss: 0.000123, PSRN_gt: 32.224652\n",
            "Iteration: 03042, Loss: 0.000120, PSRN_gt: 32.264847\n",
            "Iteration: 03043, Loss: 0.000118, PSRN_gt: 32.278655\n",
            "Iteration: 03044, Loss: 0.000119, PSRN_gt: 32.277420\n",
            "Iteration: 03045, Loss: 0.000120, PSRN_gt: 32.267804\n",
            "Iteration: 03046, Loss: 0.000118, PSRN_gt: 32.282652\n",
            "Iteration: 03047, Loss: 0.000117, PSRN_gt: 32.311598\n",
            "Iteration: 03048, Loss: 0.000117, PSRN_gt: 32.281258\n",
            "Iteration: 03049, Loss: 0.000118, PSRN_gt: 32.284908\n",
            "Iteration: 03050, Loss: 0.000117, PSRN_gt: 32.286180\n",
            "Iteration: 03051, Loss: 0.000117, PSRN_gt: 32.300178\n",
            "Iteration: 03052, Loss: 0.000119, PSRN_gt: 32.238960\n",
            "Iteration: 03053, Loss: 0.000123, PSRN_gt: 32.238323\n",
            "Iteration: 03054, Loss: 0.000127, PSRN_gt: 32.112421\n",
            "Iteration: 03055, Loss: 0.000135, PSRN_gt: 32.067526\n",
            "Iteration: 03056, Loss: 0.000145, PSRN_gt: 31.894066\n",
            "Iteration: 03057, Loss: 0.000155, PSRN_gt: 31.807330\n",
            "Iteration: 03058, Loss: 0.000161, PSRN_gt: 31.681098\n",
            "Iteration: 03059, Loss: 0.000163, PSRN_gt: 31.702744\n",
            "Iteration: 03060, Loss: 0.000157, PSRN_gt: 31.737105\n",
            "Iteration: 03061, Loss: 0.000151, PSRN_gt: 31.831196\n",
            "Iteration: 03062, Loss: 0.000146, PSRN_gt: 31.908734\n",
            "Iteration: 03063, Loss: 0.000147, PSRN_gt: 31.853047\n",
            "Iteration: 03064, Loss: 0.000152, PSRN_gt: 31.851542\n",
            "Iteration: 03065, Loss: 0.000157, PSRN_gt: 31.741357\n",
            "Iteration: 03066, Loss: 0.000151, PSRN_gt: 31.845585\n",
            "Iteration: 03067, Loss: 0.000138, PSRN_gt: 31.996573\n",
            "Iteration: 03068, Loss: 0.000134, PSRN_gt: 32.061216\n",
            "Iteration: 03069, Loss: 0.000140, PSRN_gt: 32.006801\n",
            "Iteration: 03070, Loss: 0.000139, PSRN_gt: 31.983034\n",
            "Iteration: 03071, Loss: 0.000133, PSRN_gt: 32.083300\n",
            "Iteration: 03072, Loss: 0.000131, PSRN_gt: 32.091624\n",
            "Iteration: 03073, Loss: 0.000132, PSRN_gt: 32.093805\n",
            "Iteration: 03074, Loss: 0.000130, PSRN_gt: 32.110855\n",
            "Iteration: 03075, Loss: 0.000127, PSRN_gt: 32.145858\n",
            "Iteration: 03076, Loss: 0.000127, PSRN_gt: 32.148079\n",
            "Iteration: 03077, Loss: 0.000127, PSRN_gt: 32.159195\n",
            "Iteration: 03078, Loss: 0.000124, PSRN_gt: 32.186203\n",
            "Iteration: 03079, Loss: 0.000123, PSRN_gt: 32.214134\n",
            "Iteration: 03080, Loss: 0.000123, PSRN_gt: 32.197273\n",
            "Iteration: 03081, Loss: 0.000122, PSRN_gt: 32.235241\n",
            "Iteration: 03082, Loss: 0.000119, PSRN_gt: 32.243545\n",
            "Iteration: 03083, Loss: 0.000118, PSRN_gt: 32.279357\n",
            "Iteration: 03084, Loss: 0.000118, PSRN_gt: 32.258812\n",
            "Iteration: 03085, Loss: 0.000118, PSRN_gt: 32.263095\n",
            "Iteration: 03086, Loss: 0.000119, PSRN_gt: 32.250789\n",
            "Iteration: 03087, Loss: 0.000121, PSRN_gt: 32.228219\n",
            "Iteration: 03088, Loss: 0.000124, PSRN_gt: 32.175905\n",
            "Iteration: 03089, Loss: 0.000129, PSRN_gt: 32.114643\n",
            "Iteration: 03090, Loss: 0.000134, PSRN_gt: 32.049142\n",
            "Iteration: 03091, Loss: 0.000137, PSRN_gt: 31.984829\n",
            "Iteration: 03092, Loss: 0.000141, PSRN_gt: 31.957719\n",
            "Iteration: 03093, Loss: 0.000143, PSRN_gt: 31.912576\n",
            "Iteration: 03094, Loss: 0.000144, PSRN_gt: 31.916061\n",
            "Iteration: 03095, Loss: 0.000143, PSRN_gt: 31.905220\n",
            "Iteration: 03096, Loss: 0.000146, PSRN_gt: 31.884312\n",
            "Iteration: 03097, Loss: 0.000151, PSRN_gt: 31.819369\n",
            "Iteration: 03098, Loss: 0.000159, PSRN_gt: 31.730689\n",
            "Iteration: 03099, Loss: 0.000164, PSRN_gt: 31.634510\n",
            "Iteration: 03100, Loss: 0.000167, PSRN_gt: 31.638239\n",
            "Iteration: 03101, Loss: 0.000161, PSRN_gt: 31.661660\n",
            "Iteration: 03102, Loss: 0.000154, PSRN_gt: 31.806127\n",
            "Iteration: 03103, Loss: 0.000146, PSRN_gt: 31.885132\n",
            "Iteration: 03104, Loss: 0.000141, PSRN_gt: 31.977469\n",
            "Iteration: 03105, Loss: 0.000136, PSRN_gt: 32.034494\n",
            "Iteration: 03106, Loss: 0.000133, PSRN_gt: 32.077891\n",
            "Iteration: 03107, Loss: 0.000132, PSRN_gt: 32.084088\n",
            "Iteration: 03108, Loss: 0.000131, PSRN_gt: 32.105721\n",
            "Iteration: 03109, Loss: 0.000130, PSRN_gt: 32.112831\n",
            "Iteration: 03110, Loss: 0.000125, PSRN_gt: 32.169033\n",
            "Iteration: 03111, Loss: 0.000121, PSRN_gt: 32.226139\n",
            "Iteration: 03112, Loss: 0.000120, PSRN_gt: 32.248210\n",
            "Iteration: 03113, Loss: 0.000119, PSRN_gt: 32.261541\n",
            "Iteration: 03114, Loss: 0.000117, PSRN_gt: 32.271874\n",
            "Iteration: 03115, Loss: 0.000116, PSRN_gt: 32.296255\n",
            "Iteration: 03116, Loss: 0.000115, PSRN_gt: 32.312539\n",
            "Iteration: 03117, Loss: 0.000113, PSRN_gt: 32.334740\n",
            "Iteration: 03118, Loss: 0.000112, PSRN_gt: 32.348897\n",
            "Iteration: 03119, Loss: 0.000113, PSRN_gt: 32.344601\n",
            "Iteration: 03120, Loss: 0.000111, PSRN_gt: 32.348147\n",
            "Iteration: 03121, Loss: 0.000110, PSRN_gt: 32.367796\n",
            "Iteration: 03122, Loss: 0.000111, PSRN_gt: 32.356909\n",
            "Iteration: 03123, Loss: 0.000111, PSRN_gt: 32.351236\n",
            "Iteration: 03124, Loss: 0.000112, PSRN_gt: 32.339436\n",
            "Iteration: 03125, Loss: 0.000114, PSRN_gt: 32.305185\n",
            "Iteration: 03126, Loss: 0.000120, PSRN_gt: 32.208266\n",
            "Iteration: 03127, Loss: 0.000129, PSRN_gt: 32.105739\n",
            "Iteration: 03128, Loss: 0.000143, PSRN_gt: 31.889680\n",
            "Iteration: 03129, Loss: 0.000162, PSRN_gt: 31.670826\n",
            "Iteration: 03130, Loss: 0.000178, PSRN_gt: 31.458355\n",
            "Iteration: 03131, Loss: 0.000184, PSRN_gt: 31.414866\n",
            "Iteration: 03132, Loss: 0.000167, PSRN_gt: 31.605396\n",
            "Iteration: 03133, Loss: 0.000140, PSRN_gt: 31.961228\n",
            "Iteration: 03134, Loss: 0.000127, PSRN_gt: 32.135397\n",
            "Iteration: 03135, Loss: 0.000136, PSRN_gt: 32.015001\n",
            "Iteration: 03136, Loss: 0.000149, PSRN_gt: 31.851172\n",
            "Iteration: 03137, Loss: 0.000149, PSRN_gt: 31.841403\n",
            "Iteration: 03138, Loss: 0.000134, PSRN_gt: 32.049185\n",
            "Iteration: 03139, Loss: 0.000124, PSRN_gt: 32.203459\n",
            "Iteration: 03140, Loss: 0.000128, PSRN_gt: 32.115514\n",
            "Iteration: 03141, Loss: 0.000133, PSRN_gt: 32.075821\n",
            "Iteration: 03142, Loss: 0.000129, PSRN_gt: 32.096365\n",
            "Iteration: 03143, Loss: 0.000122, PSRN_gt: 32.214651\n",
            "Iteration: 03144, Loss: 0.000120, PSRN_gt: 32.242114\n",
            "Iteration: 03145, Loss: 0.000122, PSRN_gt: 32.219057\n",
            "Iteration: 03146, Loss: 0.000124, PSRN_gt: 32.177376\n",
            "Iteration: 03147, Loss: 0.000122, PSRN_gt: 32.204883\n",
            "Iteration: 03148, Loss: 0.000120, PSRN_gt: 32.228842\n",
            "Iteration: 03149, Loss: 0.000119, PSRN_gt: 32.256532\n",
            "Iteration: 03150, Loss: 0.000121, PSRN_gt: 32.194515\n",
            "Iteration: 03151, Loss: 0.000122, PSRN_gt: 32.222215\n",
            "Iteration: 03152, Loss: 0.000121, PSRN_gt: 32.196010\n",
            "Iteration: 03153, Loss: 0.000122, PSRN_gt: 32.219546\n",
            "Iteration: 03154, Loss: 0.000121, PSRN_gt: 32.186277\n",
            "Iteration: 03155, Loss: 0.000123, PSRN_gt: 32.204973\n",
            "Iteration: 03156, Loss: 0.000125, PSRN_gt: 32.138574\n",
            "Iteration: 03157, Loss: 0.000126, PSRN_gt: 32.145045\n",
            "Iteration: 03158, Loss: 0.000125, PSRN_gt: 32.136032\n",
            "Iteration: 03159, Loss: 0.000125, PSRN_gt: 32.155151\n",
            "Iteration: 03160, Loss: 0.000125, PSRN_gt: 32.124302\n",
            "Iteration: 03161, Loss: 0.000126, PSRN_gt: 32.149721\n",
            "Iteration: 03162, Loss: 0.000126, PSRN_gt: 32.124345\n",
            "Iteration: 03163, Loss: 0.000129, PSRN_gt: 32.095127\n",
            "Iteration: 03164, Loss: 0.000134, PSRN_gt: 32.029058\n",
            "Iteration: 03165, Loss: 0.000137, PSRN_gt: 31.978694\n",
            "Iteration: 03166, Loss: 0.000140, PSRN_gt: 31.945176\n",
            "Iteration: 03167, Loss: 0.000138, PSRN_gt: 31.970006\n",
            "Iteration: 03168, Loss: 0.000135, PSRN_gt: 31.990812\n",
            "Iteration: 03169, Loss: 0.000136, PSRN_gt: 32.011554\n",
            "Iteration: 03170, Loss: 0.000140, PSRN_gt: 31.931049\n",
            "Iteration: 03171, Loss: 0.000144, PSRN_gt: 31.919345\n",
            "Iteration: 03172, Loss: 0.000144, PSRN_gt: 31.893218\n",
            "Iteration: 03173, Loss: 0.000143, PSRN_gt: 31.911847\n",
            "Iteration: 03174, Loss: 0.000138, PSRN_gt: 32.005144\n",
            "Iteration: 03175, Loss: 0.000128, PSRN_gt: 32.114417\n",
            "Iteration: 03176, Loss: 0.000120, PSRN_gt: 32.217901\n",
            "Iteration: 03177, Loss: 0.000120, PSRN_gt: 32.224993\n",
            "Iteration: 03178, Loss: 0.000124, PSRN_gt: 32.177050\n",
            "Iteration: 03179, Loss: 0.000125, PSRN_gt: 32.133445\n",
            "Iteration: 03180, Loss: 0.000121, PSRN_gt: 32.199789\n",
            "Iteration: 03181, Loss: 0.000116, PSRN_gt: 32.281390\n",
            "Iteration: 03182, Loss: 0.000114, PSRN_gt: 32.294651\n",
            "Iteration: 03183, Loss: 0.000114, PSRN_gt: 32.299685\n",
            "Iteration: 03184, Loss: 0.000114, PSRN_gt: 32.297343\n",
            "Iteration: 03185, Loss: 0.000112, PSRN_gt: 32.323031\n",
            "Iteration: 03186, Loss: 0.000111, PSRN_gt: 32.337375\n",
            "Iteration: 03187, Loss: 0.000110, PSRN_gt: 32.332267\n",
            "Iteration: 03188, Loss: 0.000110, PSRN_gt: 32.358858\n",
            "Iteration: 03189, Loss: 0.000110, PSRN_gt: 32.333404\n",
            "Iteration: 03190, Loss: 0.000111, PSRN_gt: 32.354356\n",
            "Iteration: 03191, Loss: 0.000112, PSRN_gt: 32.297634\n",
            "Iteration: 03192, Loss: 0.000114, PSRN_gt: 32.301182\n",
            "Iteration: 03193, Loss: 0.000117, PSRN_gt: 32.206998\n",
            "Iteration: 03194, Loss: 0.000122, PSRN_gt: 32.177557\n",
            "Iteration: 03195, Loss: 0.000130, PSRN_gt: 32.043332\n",
            "Iteration: 03196, Loss: 0.000142, PSRN_gt: 31.918703\n",
            "Iteration: 03197, Loss: 0.000155, PSRN_gt: 31.707647\n",
            "Iteration: 03198, Loss: 0.000168, PSRN_gt: 31.595169\n",
            "Iteration: 03199, Loss: 0.000172, PSRN_gt: 31.492558\n",
            "Iteration: 03200, Loss: 0.000172, PSRN_gt: 31.557221\n",
            "Iteration: 03201, Loss: 0.000168, PSRN_gt: 31.561897\n",
            "Iteration: 03202, Loss: 0.000168, PSRN_gt: 31.604647\n",
            "Iteration: 03203, Loss: 0.000166, PSRN_gt: 31.629803\n",
            "Iteration: 03204, Loss: 0.000168, PSRN_gt: 31.585776\n",
            "Iteration: 03205, Loss: 0.000171, PSRN_gt: 31.571678\n",
            "Iteration: 03206, Loss: 0.000168, PSRN_gt: 31.596003\n",
            "Iteration: 03207, Loss: 0.000161, PSRN_gt: 31.687549\n",
            "Iteration: 03208, Loss: 0.000143, PSRN_gt: 31.924778\n",
            "Iteration: 03209, Loss: 0.000137, PSRN_gt: 32.005299\n",
            "Iteration: 03210, Loss: 0.000145, PSRN_gt: 31.899759\n",
            "Iteration: 03211, Loss: 0.000139, PSRN_gt: 31.969622\n",
            "Iteration: 03212, Loss: 0.000129, PSRN_gt: 32.116232\n",
            "Iteration: 03213, Loss: 0.000128, PSRN_gt: 32.132728\n",
            "Iteration: 03214, Loss: 0.000128, PSRN_gt: 32.120927\n",
            "Iteration: 03215, Loss: 0.000126, PSRN_gt: 32.127418\n",
            "Iteration: 03216, Loss: 0.000125, PSRN_gt: 32.166740\n",
            "Iteration: 03217, Loss: 0.000121, PSRN_gt: 32.196529\n",
            "Iteration: 03218, Loss: 0.000119, PSRN_gt: 32.238478\n",
            "Iteration: 03219, Loss: 0.000119, PSRN_gt: 32.244001\n",
            "Iteration: 03220, Loss: 0.000120, PSRN_gt: 32.204056\n",
            "Iteration: 03221, Loss: 0.000118, PSRN_gt: 32.244699\n",
            "Iteration: 03222, Loss: 0.000118, PSRN_gt: 32.251830\n",
            "Iteration: 03223, Loss: 0.000119, PSRN_gt: 32.213853\n",
            "Iteration: 03224, Loss: 0.000120, PSRN_gt: 32.213987\n",
            "Iteration: 03225, Loss: 0.000120, PSRN_gt: 32.200806\n",
            "Iteration: 03226, Loss: 0.000122, PSRN_gt: 32.177267\n",
            "Iteration: 03227, Loss: 0.000122, PSRN_gt: 32.167090\n",
            "Iteration: 03228, Loss: 0.000121, PSRN_gt: 32.209214\n",
            "Iteration: 03229, Loss: 0.000119, PSRN_gt: 32.204696\n",
            "Iteration: 03230, Loss: 0.000117, PSRN_gt: 32.253557\n",
            "Iteration: 03231, Loss: 0.000114, PSRN_gt: 32.270855\n",
            "Iteration: 03232, Loss: 0.000113, PSRN_gt: 32.301366\n",
            "Iteration: 03233, Loss: 0.000114, PSRN_gt: 32.280375\n",
            "Iteration: 03234, Loss: 0.000116, PSRN_gt: 32.256167\n",
            "Iteration: 03235, Loss: 0.000120, PSRN_gt: 32.184562\n",
            "Iteration: 03236, Loss: 0.000126, PSRN_gt: 32.134579\n",
            "Iteration: 03237, Loss: 0.000132, PSRN_gt: 32.012673\n",
            "Iteration: 03238, Loss: 0.000139, PSRN_gt: 31.956130\n",
            "Iteration: 03239, Loss: 0.000140, PSRN_gt: 31.911615\n",
            "Iteration: 03240, Loss: 0.000135, PSRN_gt: 32.014629\n",
            "Iteration: 03241, Loss: 0.000123, PSRN_gt: 32.135559\n",
            "Iteration: 03242, Loss: 0.000113, PSRN_gt: 32.302958\n",
            "Iteration: 03243, Loss: 0.000111, PSRN_gt: 32.309022\n",
            "Iteration: 03244, Loss: 0.000117, PSRN_gt: 32.240314\n",
            "Iteration: 03245, Loss: 0.000123, PSRN_gt: 32.151503\n",
            "Iteration: 03246, Loss: 0.000123, PSRN_gt: 32.134950\n",
            "Iteration: 03247, Loss: 0.000118, PSRN_gt: 32.225211\n",
            "Iteration: 03248, Loss: 0.000112, PSRN_gt: 32.296332\n",
            "Iteration: 03249, Loss: 0.000112, PSRN_gt: 32.300052\n",
            "Iteration: 03250, Loss: 0.000117, PSRN_gt: 32.217116\n",
            "Iteration: 03251, Loss: 0.000123, PSRN_gt: 32.159288\n",
            "Iteration: 03252, Loss: 0.000125, PSRN_gt: 32.112511\n",
            "Iteration: 03253, Loss: 0.000127, PSRN_gt: 32.086513\n",
            "Iteration: 03254, Loss: 0.000134, PSRN_gt: 31.997012\n",
            "Iteration: 03255, Loss: 0.000142, PSRN_gt: 31.890703\n",
            "Iteration: 03256, Loss: 0.000147, PSRN_gt: 31.834756\n",
            "Iteration: 03257, Loss: 0.000141, PSRN_gt: 31.911408\n",
            "Iteration: 03258, Loss: 0.000134, PSRN_gt: 31.979536\n",
            "Iteration: 03259, Loss: 0.000130, PSRN_gt: 32.054749\n",
            "Iteration: 03260, Loss: 0.000130, PSRN_gt: 32.069994\n",
            "Iteration: 03261, Loss: 0.000126, PSRN_gt: 32.101720\n",
            "Iteration: 03262, Loss: 0.000125, PSRN_gt: 32.132360\n",
            "Iteration: 03263, Loss: 0.000130, PSRN_gt: 32.053576\n",
            "Iteration: 03264, Loss: 0.000134, PSRN_gt: 32.014821\n",
            "Iteration: 03265, Loss: 0.000129, PSRN_gt: 32.054824\n",
            "Iteration: 03266, Loss: 0.000122, PSRN_gt: 32.172340\n",
            "Iteration: 03267, Loss: 0.000121, PSRN_gt: 32.174314\n",
            "Iteration: 03268, Loss: 0.000124, PSRN_gt: 32.147974\n",
            "Iteration: 03269, Loss: 0.000123, PSRN_gt: 32.147759\n",
            "Iteration: 03270, Loss: 0.000123, PSRN_gt: 32.125351\n",
            "Iteration: 03271, Loss: 0.000126, PSRN_gt: 32.124555\n",
            "Iteration: 03272, Loss: 0.000128, PSRN_gt: 32.061380\n",
            "Iteration: 03273, Loss: 0.000128, PSRN_gt: 32.097248\n",
            "Iteration: 03274, Loss: 0.000128, PSRN_gt: 32.061975\n",
            "Iteration: 03275, Loss: 0.000131, PSRN_gt: 32.062825\n",
            "Iteration: 03276, Loss: 0.000133, PSRN_gt: 31.995829\n",
            "Iteration: 03277, Loss: 0.000133, PSRN_gt: 32.028334\n",
            "Iteration: 03278, Loss: 0.000130, PSRN_gt: 32.024896\n",
            "Iteration: 03279, Loss: 0.000128, PSRN_gt: 32.099188\n",
            "Iteration: 03280, Loss: 0.000127, PSRN_gt: 32.066240\n",
            "Iteration: 03281, Loss: 0.000125, PSRN_gt: 32.123040\n",
            "Iteration: 03282, Loss: 0.000125, PSRN_gt: 32.131075\n",
            "Iteration: 03283, Loss: 0.000126, PSRN_gt: 32.070552\n",
            "Iteration: 03284, Loss: 0.000127, PSRN_gt: 32.109855\n",
            "Iteration: 03285, Loss: 0.000125, PSRN_gt: 32.086718\n",
            "Iteration: 03286, Loss: 0.000124, PSRN_gt: 32.139227\n",
            "Iteration: 03287, Loss: 0.000122, PSRN_gt: 32.153549\n",
            "Iteration: 03288, Loss: 0.000118, PSRN_gt: 32.223092\n",
            "Iteration: 03289, Loss: 0.000114, PSRN_gt: 32.259783\n",
            "Iteration: 03290, Loss: 0.000113, PSRN_gt: 32.289767\n",
            "Iteration: 03291, Loss: 0.000110, PSRN_gt: 32.325655\n",
            "Iteration: 03292, Loss: 0.000109, PSRN_gt: 32.339871\n",
            "Iteration: 03293, Loss: 0.000109, PSRN_gt: 32.355941\n",
            "Iteration: 03294, Loss: 0.000109, PSRN_gt: 32.329351\n",
            "Iteration: 03295, Loss: 0.000109, PSRN_gt: 32.341928\n",
            "Iteration: 03296, Loss: 0.000109, PSRN_gt: 32.331311\n",
            "Iteration: 03297, Loss: 0.000109, PSRN_gt: 32.331477\n",
            "Iteration: 03298, Loss: 0.000109, PSRN_gt: 32.343735\n",
            "Iteration: 03299, Loss: 0.000108, PSRN_gt: 32.347367\n",
            "Iteration: 03300, Loss: 0.000106, PSRN_gt: 32.357325\n",
            "Iteration: 03301, Loss: 0.000106, PSRN_gt: 32.376809\n",
            "Iteration: 03302, Loss: 0.000107, PSRN_gt: 32.347330\n",
            "Iteration: 03303, Loss: 0.000108, PSRN_gt: 32.341295\n",
            "Iteration: 03304, Loss: 0.000110, PSRN_gt: 32.314266\n",
            "Iteration: 03305, Loss: 0.000111, PSRN_gt: 32.280553\n",
            "Iteration: 03306, Loss: 0.000113, PSRN_gt: 32.282469\n",
            "Iteration: 03307, Loss: 0.000116, PSRN_gt: 32.206586\n",
            "Iteration: 03308, Loss: 0.000123, PSRN_gt: 32.141031\n",
            "Iteration: 03309, Loss: 0.000131, PSRN_gt: 32.024390\n",
            "Iteration: 03310, Loss: 0.000138, PSRN_gt: 31.936479\n",
            "Iteration: 03311, Loss: 0.000141, PSRN_gt: 31.893727\n",
            "Iteration: 03312, Loss: 0.000143, PSRN_gt: 31.854296\n",
            "Iteration: 03313, Loss: 0.000147, PSRN_gt: 31.845622\n",
            "Iteration: 03314, Loss: 0.000151, PSRN_gt: 31.737739\n",
            "Iteration: 03315, Loss: 0.000158, PSRN_gt: 31.740946\n",
            "Iteration: 03316, Loss: 0.000159, PSRN_gt: 31.620119\n",
            "Iteration: 03317, Loss: 0.000167, PSRN_gt: 31.637217\n",
            "Iteration: 03318, Loss: 0.000167, PSRN_gt: 31.565804\n",
            "Iteration: 03319, Loss: 0.000162, PSRN_gt: 31.670776\n",
            "Iteration: 03320, Loss: 0.000148, PSRN_gt: 31.825464\n",
            "Iteration: 03321, Loss: 0.000145, PSRN_gt: 31.859085\n",
            "Iteration: 03322, Loss: 0.000150, PSRN_gt: 31.813659\n",
            "Iteration: 03323, Loss: 0.000146, PSRN_gt: 31.841487\n",
            "Iteration: 03324, Loss: 0.000141, PSRN_gt: 31.931888\n",
            "Iteration: 03325, Loss: 0.000144, PSRN_gt: 31.871065\n",
            "Iteration: 03326, Loss: 0.000145, PSRN_gt: 31.870434\n",
            "Iteration: 03327, Loss: 0.000134, PSRN_gt: 32.006637\n",
            "Iteration: 03328, Loss: 0.000133, PSRN_gt: 32.003537\n",
            "Iteration: 03329, Loss: 0.000135, PSRN_gt: 31.990647\n",
            "Iteration: 03330, Loss: 0.000126, PSRN_gt: 32.136777\n",
            "Iteration: 03331, Loss: 0.000122, PSRN_gt: 32.164167\n",
            "Iteration: 03332, Loss: 0.000120, PSRN_gt: 32.185851\n",
            "Iteration: 03333, Loss: 0.000118, PSRN_gt: 32.244303\n",
            "Iteration: 03334, Loss: 0.000115, PSRN_gt: 32.269366\n",
            "Iteration: 03335, Loss: 0.000113, PSRN_gt: 32.287473\n",
            "Iteration: 03336, Loss: 0.000112, PSRN_gt: 32.298041\n",
            "Iteration: 03337, Loss: 0.000110, PSRN_gt: 32.310896\n",
            "Iteration: 03338, Loss: 0.000110, PSRN_gt: 32.314292\n",
            "Iteration: 03339, Loss: 0.000108, PSRN_gt: 32.353248\n",
            "Iteration: 03340, Loss: 0.000107, PSRN_gt: 32.360355\n",
            "Iteration: 03341, Loss: 0.000106, PSRN_gt: 32.358702\n",
            "Iteration: 03342, Loss: 0.000105, PSRN_gt: 32.390215\n",
            "Iteration: 03343, Loss: 0.000103, PSRN_gt: 32.420881\n",
            "Iteration: 03344, Loss: 0.000103, PSRN_gt: 32.408212\n",
            "Iteration: 03345, Loss: 0.000101, PSRN_gt: 32.431278\n",
            "Iteration: 03346, Loss: 0.000101, PSRN_gt: 32.440993\n",
            "Iteration: 03347, Loss: 0.000100, PSRN_gt: 32.444867\n",
            "Iteration: 03348, Loss: 0.000099, PSRN_gt: 32.450212\n",
            "Iteration: 03349, Loss: 0.000100, PSRN_gt: 32.454160\n",
            "Iteration: 03350, Loss: 0.000100, PSRN_gt: 32.431733\n",
            "Iteration: 03351, Loss: 0.000102, PSRN_gt: 32.418293\n",
            "Iteration: 03352, Loss: 0.000105, PSRN_gt: 32.358601\n",
            "Iteration: 03353, Loss: 0.000112, PSRN_gt: 32.281845\n",
            "Iteration: 03354, Loss: 0.000122, PSRN_gt: 32.118696\n",
            "Iteration: 03355, Loss: 0.000139, PSRN_gt: 31.906553\n",
            "Iteration: 03356, Loss: 0.000158, PSRN_gt: 31.636080\n",
            "Iteration: 03357, Loss: 0.000179, PSRN_gt: 31.415347\n",
            "Iteration: 03358, Loss: 0.000180, PSRN_gt: 31.378979\n",
            "Iteration: 03359, Loss: 0.000169, PSRN_gt: 31.535170\n",
            "Iteration: 03360, Loss: 0.000153, PSRN_gt: 31.732587\n",
            "Iteration: 03361, Loss: 0.000153, PSRN_gt: 31.745238\n",
            "Iteration: 03362, Loss: 0.000161, PSRN_gt: 31.655412\n",
            "Iteration: 03363, Loss: 0.000163, PSRN_gt: 31.633820\n",
            "Iteration: 03364, Loss: 0.000151, PSRN_gt: 31.780436\n",
            "Iteration: 03365, Loss: 0.000143, PSRN_gt: 31.897802\n",
            "Iteration: 03366, Loss: 0.000141, PSRN_gt: 31.927452\n",
            "Iteration: 03367, Loss: 0.000139, PSRN_gt: 31.939379\n",
            "Iteration: 03368, Loss: 0.000132, PSRN_gt: 32.002488\n",
            "Iteration: 03369, Loss: 0.000128, PSRN_gt: 32.078092\n",
            "Iteration: 03370, Loss: 0.000126, PSRN_gt: 32.117951\n",
            "Iteration: 03371, Loss: 0.000122, PSRN_gt: 32.151940\n",
            "Iteration: 03372, Loss: 0.000120, PSRN_gt: 32.180928\n",
            "Iteration: 03373, Loss: 0.000118, PSRN_gt: 32.211309\n",
            "Iteration: 03374, Loss: 0.000115, PSRN_gt: 32.260509\n",
            "Iteration: 03375, Loss: 0.000112, PSRN_gt: 32.291492\n",
            "Iteration: 03376, Loss: 0.000111, PSRN_gt: 32.314552\n",
            "Iteration: 03377, Loss: 0.000111, PSRN_gt: 32.308420\n",
            "Iteration: 03378, Loss: 0.000108, PSRN_gt: 32.346032\n",
            "Iteration: 03379, Loss: 0.000106, PSRN_gt: 32.370119\n",
            "Iteration: 03380, Loss: 0.000106, PSRN_gt: 32.375498\n",
            "Iteration: 03381, Loss: 0.000104, PSRN_gt: 32.389276\n",
            "Iteration: 03382, Loss: 0.000103, PSRN_gt: 32.403727\n",
            "Iteration: 03383, Loss: 0.000102, PSRN_gt: 32.412118\n",
            "Iteration: 03384, Loss: 0.000101, PSRN_gt: 32.437159\n",
            "Iteration: 03385, Loss: 0.000101, PSRN_gt: 32.427249\n",
            "Iteration: 03386, Loss: 0.000101, PSRN_gt: 32.423731\n",
            "Iteration: 03387, Loss: 0.000099, PSRN_gt: 32.447999\n",
            "Iteration: 03388, Loss: 0.000100, PSRN_gt: 32.437734\n",
            "Iteration: 03389, Loss: 0.000100, PSRN_gt: 32.432693\n",
            "Iteration: 03390, Loss: 0.000100, PSRN_gt: 32.436248\n",
            "Iteration: 03391, Loss: 0.000103, PSRN_gt: 32.400155\n",
            "Iteration: 03392, Loss: 0.000105, PSRN_gt: 32.371006\n",
            "Iteration: 03393, Loss: 0.000109, PSRN_gt: 32.299036\n",
            "Iteration: 03394, Loss: 0.000115, PSRN_gt: 32.223995\n",
            "Iteration: 03395, Loss: 0.000124, PSRN_gt: 32.077147\n",
            "Iteration: 03396, Loss: 0.000136, PSRN_gt: 31.940337\n",
            "Iteration: 03397, Loss: 0.000151, PSRN_gt: 31.724571\n",
            "Iteration: 03398, Loss: 0.000167, PSRN_gt: 31.538594\n",
            "Iteration: 03399, Loss: 0.000178, PSRN_gt: 31.418114\n",
            "Iteration: 03400, Loss: 0.000178, PSRN_gt: 31.418624\n",
            "Iteration: 03401, Loss: 0.000173, PSRN_gt: 31.492953\n",
            "Iteration: 03402, Loss: 0.000171, PSRN_gt: 31.490372\n",
            "Iteration: 03403, Loss: 0.000189, PSRN_gt: 31.328541\n",
            "Iteration: 03404, Loss: 0.000233, PSRN_gt: 30.789865\n",
            "Iteration: 03405, Loss: 0.000282, PSRN_gt: 30.344482\n",
            "Iteration: 03406, Loss: 0.000292, PSRN_gt: 30.152841\n",
            "Iteration: 03407, Loss: 0.000324, PSRN_gt: 29.985771\n",
            "Iteration: 03408, Loss: 0.000283, PSRN_gt: 30.376271\n",
            "Iteration: 03409, Loss: 0.000376, PSRN_gt: 29.569721\n",
            "Iteration: 03410, Loss: 0.000357, PSRN_gt: 29.759250\n",
            "Iteration: 03411, Loss: 0.000327, PSRN_gt: 29.989648\n",
            "Iteration: 03412, Loss: 0.000308, PSRN_gt: 30.167025\n",
            "Iteration: 03413, Loss: 0.000307, PSRN_gt: 30.220051\n",
            "Iteration: 03414, Loss: 0.000273, PSRN_gt: 30.526703\n",
            "Iteration: 03415, Loss: 0.000262, PSRN_gt: 30.642335\n",
            "Iteration: 03416, Loss: 0.000256, PSRN_gt: 30.680247\n",
            "Iteration: 03417, Loss: 0.000247, PSRN_gt: 30.802827\n",
            "Iteration: 03418, Loss: 0.000228, PSRN_gt: 30.984678\n",
            "Iteration: 03419, Loss: 0.000222, PSRN_gt: 31.064296\n",
            "Iteration: 03420, Loss: 0.000210, PSRN_gt: 31.205636\n",
            "Iteration: 03421, Loss: 0.000198, PSRN_gt: 31.362740\n",
            "Iteration: 03422, Loss: 0.000192, PSRN_gt: 31.415460\n",
            "Iteration: 03423, Loss: 0.000184, PSRN_gt: 31.458433\n",
            "Iteration: 03424, Loss: 0.000178, PSRN_gt: 31.557001\n",
            "Iteration: 03425, Loss: 0.000171, PSRN_gt: 31.647701\n",
            "Iteration: 03426, Loss: 0.000164, PSRN_gt: 31.730227\n",
            "Iteration: 03427, Loss: 0.000158, PSRN_gt: 31.803140\n",
            "Iteration: 03428, Loss: 0.000154, PSRN_gt: 31.851969\n",
            "Iteration: 03429, Loss: 0.000150, PSRN_gt: 31.885062\n",
            "Iteration: 03430, Loss: 0.000146, PSRN_gt: 31.922901\n",
            "Iteration: 03431, Loss: 0.000141, PSRN_gt: 32.012259\n",
            "Iteration: 03432, Loss: 0.000138, PSRN_gt: 32.038547\n",
            "Iteration: 03433, Loss: 0.000134, PSRN_gt: 32.078954\n",
            "Iteration: 03434, Loss: 0.000132, PSRN_gt: 32.117626\n",
            "Iteration: 03435, Loss: 0.000130, PSRN_gt: 32.124320\n",
            "Iteration: 03436, Loss: 0.000127, PSRN_gt: 32.163119\n",
            "Iteration: 03437, Loss: 0.000125, PSRN_gt: 32.181295\n",
            "Iteration: 03438, Loss: 0.000122, PSRN_gt: 32.206972\n",
            "Iteration: 03439, Loss: 0.000120, PSRN_gt: 32.247775\n",
            "Iteration: 03440, Loss: 0.000118, PSRN_gt: 32.252946\n",
            "Iteration: 03441, Loss: 0.000116, PSRN_gt: 32.278421\n",
            "Iteration: 03442, Loss: 0.000115, PSRN_gt: 32.284445\n",
            "Iteration: 03443, Loss: 0.000114, PSRN_gt: 32.311542\n",
            "Iteration: 03444, Loss: 0.000112, PSRN_gt: 32.334842\n",
            "Iteration: 03445, Loss: 0.000111, PSRN_gt: 32.341187\n",
            "Iteration: 03446, Loss: 0.000110, PSRN_gt: 32.357400\n",
            "Iteration: 03447, Loss: 0.000109, PSRN_gt: 32.373232\n",
            "Iteration: 03448, Loss: 0.000108, PSRN_gt: 32.386207\n",
            "Iteration: 03449, Loss: 0.000107, PSRN_gt: 32.383507\n",
            "Iteration: 03450, Loss: 0.000106, PSRN_gt: 32.396910\n",
            "Iteration: 03451, Loss: 0.000106, PSRN_gt: 32.403333\n",
            "Iteration: 03452, Loss: 0.000105, PSRN_gt: 32.412227\n",
            "Iteration: 03453, Loss: 0.000105, PSRN_gt: 32.403114\n",
            "Iteration: 03454, Loss: 0.000104, PSRN_gt: 32.409424\n",
            "Iteration: 03455, Loss: 0.000104, PSRN_gt: 32.405621\n",
            "Iteration: 03456, Loss: 0.000104, PSRN_gt: 32.415006\n",
            "Iteration: 03457, Loss: 0.000104, PSRN_gt: 32.399592\n",
            "Iteration: 03458, Loss: 0.000104, PSRN_gt: 32.413721\n",
            "Iteration: 03459, Loss: 0.000104, PSRN_gt: 32.391349\n",
            "Iteration: 03460, Loss: 0.000104, PSRN_gt: 32.409485\n",
            "Iteration: 03461, Loss: 0.000104, PSRN_gt: 32.384780\n",
            "Iteration: 03462, Loss: 0.000105, PSRN_gt: 32.399178\n",
            "Iteration: 03463, Loss: 0.000105, PSRN_gt: 32.369875\n",
            "Iteration: 03464, Loss: 0.000106, PSRN_gt: 32.372012\n",
            "Iteration: 03465, Loss: 0.000107, PSRN_gt: 32.351537\n",
            "Iteration: 03466, Loss: 0.000108, PSRN_gt: 32.325409\n",
            "Iteration: 03467, Loss: 0.000111, PSRN_gt: 32.305231\n",
            "Iteration: 03468, Loss: 0.000114, PSRN_gt: 32.229718\n",
            "Iteration: 03469, Loss: 0.000119, PSRN_gt: 32.195850\n",
            "Iteration: 03470, Loss: 0.000125, PSRN_gt: 32.071618\n",
            "Iteration: 03471, Loss: 0.000133, PSRN_gt: 32.006348\n",
            "Iteration: 03472, Loss: 0.000140, PSRN_gt: 31.867205\n",
            "Iteration: 03473, Loss: 0.000148, PSRN_gt: 31.813655\n",
            "Iteration: 03474, Loss: 0.000155, PSRN_gt: 31.667286\n",
            "Iteration: 03475, Loss: 0.000167, PSRN_gt: 31.568787\n",
            "Iteration: 03476, Loss: 0.000175, PSRN_gt: 31.433038\n",
            "Iteration: 03477, Loss: 0.000172, PSRN_gt: 31.485845\n",
            "Iteration: 03478, Loss: 0.000163, PSRN_gt: 31.609800\n",
            "Iteration: 03479, Loss: 0.000151, PSRN_gt: 31.753069\n",
            "Iteration: 03480, Loss: 0.000149, PSRN_gt: 31.818622\n",
            "Iteration: 03481, Loss: 0.000149, PSRN_gt: 31.788083\n",
            "Iteration: 03482, Loss: 0.000144, PSRN_gt: 31.856629\n",
            "Iteration: 03483, Loss: 0.000137, PSRN_gt: 31.978380\n",
            "Iteration: 03484, Loss: 0.000130, PSRN_gt: 32.061980\n",
            "Iteration: 03485, Loss: 0.000126, PSRN_gt: 32.108137\n",
            "Iteration: 03486, Loss: 0.000125, PSRN_gt: 32.131630\n",
            "Iteration: 03487, Loss: 0.000125, PSRN_gt: 32.110203\n",
            "Iteration: 03488, Loss: 0.000122, PSRN_gt: 32.162297\n",
            "Iteration: 03489, Loss: 0.000118, PSRN_gt: 32.226744\n",
            "Iteration: 03490, Loss: 0.000117, PSRN_gt: 32.197253\n",
            "Iteration: 03491, Loss: 0.000113, PSRN_gt: 32.295141\n",
            "Iteration: 03492, Loss: 0.000109, PSRN_gt: 32.329205\n",
            "Iteration: 03493, Loss: 0.000109, PSRN_gt: 32.326731\n",
            "Iteration: 03494, Loss: 0.000108, PSRN_gt: 32.350250\n",
            "Iteration: 03495, Loss: 0.000106, PSRN_gt: 32.348344\n",
            "Iteration: 03496, Loss: 0.000107, PSRN_gt: 32.360955\n",
            "Iteration: 03497, Loss: 0.000105, PSRN_gt: 32.370882\n",
            "Iteration: 03498, Loss: 0.000103, PSRN_gt: 32.409688\n",
            "Iteration: 03499, Loss: 0.000102, PSRN_gt: 32.400519\n",
            "Iteration: 03500, Loss: 0.000101, PSRN_gt: 32.420855\n",
            "Iteration: 03501, Loss: 0.000100, PSRN_gt: 32.437794\n",
            "Iteration: 03502, Loss: 0.000099, PSRN_gt: 32.442787\n",
            "Iteration: 03503, Loss: 0.000099, PSRN_gt: 32.451833\n",
            "Iteration: 03504, Loss: 0.000099, PSRN_gt: 32.451959\n",
            "Iteration: 03505, Loss: 0.000097, PSRN_gt: 32.468123\n",
            "Iteration: 03506, Loss: 0.000098, PSRN_gt: 32.459877\n",
            "Iteration: 03507, Loss: 0.000097, PSRN_gt: 32.460358\n",
            "Iteration: 03508, Loss: 0.000097, PSRN_gt: 32.462980\n",
            "Iteration: 03509, Loss: 0.000098, PSRN_gt: 32.456245\n",
            "Iteration: 03510, Loss: 0.000099, PSRN_gt: 32.435984\n",
            "Iteration: 03511, Loss: 0.000100, PSRN_gt: 32.412776\n",
            "Iteration: 03512, Loss: 0.000104, PSRN_gt: 32.356833\n",
            "Iteration: 03513, Loss: 0.000110, PSRN_gt: 32.275224\n",
            "Iteration: 03514, Loss: 0.000119, PSRN_gt: 32.147449\n",
            "Iteration: 03515, Loss: 0.000133, PSRN_gt: 31.966127\n",
            "Iteration: 03516, Loss: 0.000149, PSRN_gt: 31.755514\n",
            "Iteration: 03517, Loss: 0.000168, PSRN_gt: 31.515256\n",
            "Iteration: 03518, Loss: 0.000178, PSRN_gt: 31.415249\n",
            "Iteration: 03519, Loss: 0.000185, PSRN_gt: 31.298586\n",
            "Iteration: 03520, Loss: 0.000189, PSRN_gt: 31.309778\n",
            "Iteration: 03521, Loss: 0.000192, PSRN_gt: 31.216502\n",
            "Iteration: 03522, Loss: 0.000187, PSRN_gt: 31.354018\n",
            "Iteration: 03523, Loss: 0.000170, PSRN_gt: 31.480035\n",
            "Iteration: 03524, Loss: 0.000149, PSRN_gt: 31.801768\n",
            "Iteration: 03525, Loss: 0.000146, PSRN_gt: 31.848352\n",
            "Iteration: 03526, Loss: 0.000151, PSRN_gt: 31.711237\n",
            "Iteration: 03527, Loss: 0.000143, PSRN_gt: 31.895909\n",
            "Iteration: 03528, Loss: 0.000132, PSRN_gt: 31.998266\n",
            "Iteration: 03529, Loss: 0.000132, PSRN_gt: 32.000895\n",
            "Iteration: 03530, Loss: 0.000128, PSRN_gt: 32.083832\n",
            "Iteration: 03531, Loss: 0.000123, PSRN_gt: 32.119881\n",
            "Iteration: 03532, Loss: 0.000121, PSRN_gt: 32.166727\n",
            "Iteration: 03533, Loss: 0.000117, PSRN_gt: 32.209987\n",
            "Iteration: 03534, Loss: 0.000116, PSRN_gt: 32.220678\n",
            "Iteration: 03535, Loss: 0.000114, PSRN_gt: 32.255313\n",
            "Iteration: 03536, Loss: 0.000111, PSRN_gt: 32.282628\n",
            "Iteration: 03537, Loss: 0.000109, PSRN_gt: 32.329892\n",
            "Iteration: 03538, Loss: 0.000108, PSRN_gt: 32.342878\n",
            "Iteration: 03539, Loss: 0.000106, PSRN_gt: 32.347802\n",
            "Iteration: 03540, Loss: 0.000104, PSRN_gt: 32.385785\n",
            "Iteration: 03541, Loss: 0.000104, PSRN_gt: 32.393383\n",
            "Iteration: 03542, Loss: 0.000103, PSRN_gt: 32.392694\n",
            "Iteration: 03543, Loss: 0.000101, PSRN_gt: 32.421458\n",
            "Iteration: 03544, Loss: 0.000100, PSRN_gt: 32.427484\n",
            "Iteration: 03545, Loss: 0.000100, PSRN_gt: 32.427968\n",
            "Iteration: 03546, Loss: 0.000098, PSRN_gt: 32.441714\n",
            "Iteration: 03547, Loss: 0.000098, PSRN_gt: 32.459918\n",
            "Iteration: 03548, Loss: 0.000097, PSRN_gt: 32.452489\n",
            "Iteration: 03549, Loss: 0.000097, PSRN_gt: 32.477233\n",
            "Iteration: 03550, Loss: 0.000096, PSRN_gt: 32.471629\n",
            "Iteration: 03551, Loss: 0.000096, PSRN_gt: 32.468301\n",
            "Iteration: 03552, Loss: 0.000097, PSRN_gt: 32.450413\n",
            "Iteration: 03553, Loss: 0.000098, PSRN_gt: 32.438427\n",
            "Iteration: 03554, Loss: 0.000100, PSRN_gt: 32.404045\n",
            "Iteration: 03555, Loss: 0.000104, PSRN_gt: 32.350193\n",
            "Iteration: 03556, Loss: 0.000111, PSRN_gt: 32.237013\n",
            "Iteration: 03557, Loss: 0.000120, PSRN_gt: 32.129573\n",
            "Iteration: 03558, Loss: 0.000131, PSRN_gt: 31.970928\n",
            "Iteration: 03559, Loss: 0.000140, PSRN_gt: 31.848553\n",
            "Iteration: 03560, Loss: 0.000142, PSRN_gt: 31.826363\n",
            "Iteration: 03561, Loss: 0.000134, PSRN_gt: 31.926578\n",
            "Iteration: 03562, Loss: 0.000122, PSRN_gt: 32.097599\n",
            "Iteration: 03563, Loss: 0.000114, PSRN_gt: 32.198027\n",
            "Iteration: 03564, Loss: 0.000116, PSRN_gt: 32.194403\n",
            "Iteration: 03565, Loss: 0.000122, PSRN_gt: 32.084615\n",
            "Iteration: 03566, Loss: 0.000125, PSRN_gt: 32.073288\n",
            "Iteration: 03567, Loss: 0.000119, PSRN_gt: 32.121985\n",
            "Iteration: 03568, Loss: 0.000114, PSRN_gt: 32.218501\n",
            "Iteration: 03569, Loss: 0.000115, PSRN_gt: 32.201300\n",
            "Iteration: 03570, Loss: 0.000119, PSRN_gt: 32.162624\n",
            "Iteration: 03571, Loss: 0.000120, PSRN_gt: 32.124599\n",
            "Iteration: 03572, Loss: 0.000117, PSRN_gt: 32.188805\n",
            "Iteration: 03573, Loss: 0.000112, PSRN_gt: 32.233293\n",
            "Iteration: 03574, Loss: 0.000112, PSRN_gt: 32.243118\n",
            "Iteration: 03575, Loss: 0.000110, PSRN_gt: 32.264464\n",
            "Iteration: 03576, Loss: 0.000106, PSRN_gt: 32.328161\n",
            "Iteration: 03577, Loss: 0.000105, PSRN_gt: 32.338054\n",
            "Iteration: 03578, Loss: 0.000106, PSRN_gt: 32.332118\n",
            "Iteration: 03579, Loss: 0.000104, PSRN_gt: 32.362284\n",
            "Iteration: 03580, Loss: 0.000101, PSRN_gt: 32.393535\n",
            "Iteration: 03581, Loss: 0.000099, PSRN_gt: 32.419835\n",
            "Iteration: 03582, Loss: 0.000102, PSRN_gt: 32.373332\n",
            "Iteration: 03583, Loss: 0.000103, PSRN_gt: 32.378554\n",
            "Iteration: 03584, Loss: 0.000101, PSRN_gt: 32.381148\n",
            "Iteration: 03585, Loss: 0.000100, PSRN_gt: 32.419974\n",
            "Iteration: 03586, Loss: 0.000101, PSRN_gt: 32.367382\n",
            "Iteration: 03587, Loss: 0.000104, PSRN_gt: 32.361827\n",
            "Iteration: 03588, Loss: 0.000104, PSRN_gt: 32.321979\n",
            "Iteration: 03589, Loss: 0.000106, PSRN_gt: 32.328450\n",
            "Iteration: 03590, Loss: 0.000109, PSRN_gt: 32.241908\n",
            "Iteration: 03591, Loss: 0.000114, PSRN_gt: 32.211999\n",
            "Iteration: 03592, Loss: 0.000118, PSRN_gt: 32.118057\n",
            "Iteration: 03593, Loss: 0.000121, PSRN_gt: 32.115374\n",
            "Iteration: 03594, Loss: 0.000124, PSRN_gt: 32.034042\n",
            "Iteration: 03595, Loss: 0.000127, PSRN_gt: 32.023836\n",
            "Iteration: 03596, Loss: 0.000127, PSRN_gt: 31.986714\n",
            "Iteration: 03597, Loss: 0.000125, PSRN_gt: 32.063272\n",
            "Iteration: 03598, Loss: 0.000120, PSRN_gt: 32.100917\n",
            "Iteration: 03599, Loss: 0.000115, PSRN_gt: 32.198101\n",
            "Iteration: 03600, Loss: 0.000112, PSRN_gt: 32.237886\n",
            "Iteration: 03601, Loss: 0.000111, PSRN_gt: 32.222945\n",
            "Iteration: 03602, Loss: 0.000114, PSRN_gt: 32.226486\n",
            "Iteration: 03603, Loss: 0.000115, PSRN_gt: 32.153021\n",
            "Iteration: 03604, Loss: 0.000116, PSRN_gt: 32.201641\n",
            "Iteration: 03605, Loss: 0.000113, PSRN_gt: 32.202598\n",
            "Iteration: 03606, Loss: 0.000107, PSRN_gt: 32.320518\n",
            "Iteration: 03607, Loss: 0.000101, PSRN_gt: 32.368317\n",
            "Iteration: 03608, Loss: 0.000102, PSRN_gt: 32.391152\n",
            "Iteration: 03609, Loss: 0.000104, PSRN_gt: 32.336627\n",
            "Iteration: 03610, Loss: 0.000103, PSRN_gt: 32.364780\n",
            "Iteration: 03611, Loss: 0.000102, PSRN_gt: 32.380218\n",
            "Iteration: 03612, Loss: 0.000103, PSRN_gt: 32.337889\n",
            "Iteration: 03613, Loss: 0.000105, PSRN_gt: 32.316449\n",
            "Iteration: 03614, Loss: 0.000107, PSRN_gt: 32.302187\n",
            "Iteration: 03615, Loss: 0.000109, PSRN_gt: 32.271098\n",
            "Iteration: 03616, Loss: 0.000112, PSRN_gt: 32.232524\n",
            "Iteration: 03617, Loss: 0.000117, PSRN_gt: 32.149907\n",
            "Iteration: 03618, Loss: 0.000123, PSRN_gt: 32.091804\n",
            "Iteration: 03619, Loss: 0.000124, PSRN_gt: 32.035340\n",
            "Iteration: 03620, Loss: 0.000123, PSRN_gt: 32.095991\n",
            "Iteration: 03621, Loss: 0.000119, PSRN_gt: 32.103547\n",
            "Iteration: 03622, Loss: 0.000116, PSRN_gt: 32.176255\n",
            "Iteration: 03623, Loss: 0.000114, PSRN_gt: 32.189216\n",
            "Iteration: 03624, Loss: 0.000112, PSRN_gt: 32.230774\n",
            "Iteration: 03625, Loss: 0.000111, PSRN_gt: 32.233291\n",
            "Iteration: 03626, Loss: 0.000110, PSRN_gt: 32.271332\n",
            "Iteration: 03627, Loss: 0.000107, PSRN_gt: 32.306373\n",
            "Iteration: 03628, Loss: 0.000105, PSRN_gt: 32.319735\n",
            "Iteration: 03629, Loss: 0.000103, PSRN_gt: 32.349759\n",
            "Iteration: 03630, Loss: 0.000102, PSRN_gt: 32.373632\n",
            "Iteration: 03631, Loss: 0.000103, PSRN_gt: 32.342465\n",
            "Iteration: 03632, Loss: 0.000102, PSRN_gt: 32.358088\n",
            "Iteration: 03633, Loss: 0.000103, PSRN_gt: 32.344876\n",
            "Iteration: 03634, Loss: 0.000107, PSRN_gt: 32.279696\n",
            "Iteration: 03635, Loss: 0.000109, PSRN_gt: 32.263180\n",
            "Iteration: 03636, Loss: 0.000109, PSRN_gt: 32.258626\n",
            "Iteration: 03637, Loss: 0.000112, PSRN_gt: 32.223428\n",
            "Iteration: 03638, Loss: 0.000117, PSRN_gt: 32.157287\n",
            "Iteration: 03639, Loss: 0.000120, PSRN_gt: 32.091353\n",
            "Iteration: 03640, Loss: 0.000123, PSRN_gt: 32.063979\n",
            "Iteration: 03641, Loss: 0.000129, PSRN_gt: 31.982697\n",
            "Iteration: 03642, Loss: 0.000131, PSRN_gt: 31.973928\n",
            "Iteration: 03643, Loss: 0.000130, PSRN_gt: 31.962746\n",
            "Iteration: 03644, Loss: 0.000130, PSRN_gt: 31.977612\n",
            "Iteration: 03645, Loss: 0.000126, PSRN_gt: 32.020689\n",
            "Iteration: 03646, Loss: 0.000121, PSRN_gt: 32.119218\n",
            "Iteration: 03647, Loss: 0.000117, PSRN_gt: 32.147157\n",
            "Iteration: 03648, Loss: 0.000116, PSRN_gt: 32.167688\n",
            "Iteration: 03649, Loss: 0.000115, PSRN_gt: 32.179700\n",
            "Iteration: 03650, Loss: 0.000115, PSRN_gt: 32.156860\n",
            "Iteration: 03651, Loss: 0.000114, PSRN_gt: 32.198238\n",
            "Iteration: 03652, Loss: 0.000112, PSRN_gt: 32.218497\n",
            "Iteration: 03653, Loss: 0.000110, PSRN_gt: 32.269870\n",
            "Iteration: 03654, Loss: 0.000107, PSRN_gt: 32.289936\n",
            "Iteration: 03655, Loss: 0.000107, PSRN_gt: 32.301347\n",
            "Iteration: 03656, Loss: 0.000107, PSRN_gt: 32.304105\n",
            "Iteration: 03657, Loss: 0.000106, PSRN_gt: 32.308466\n",
            "Iteration: 03658, Loss: 0.000105, PSRN_gt: 32.315098\n",
            "Iteration: 03659, Loss: 0.000104, PSRN_gt: 32.332227\n",
            "Iteration: 03660, Loss: 0.000104, PSRN_gt: 32.327935\n",
            "Iteration: 03661, Loss: 0.000104, PSRN_gt: 32.335272\n",
            "Iteration: 03662, Loss: 0.000104, PSRN_gt: 32.302979\n",
            "Iteration: 03663, Loss: 0.000105, PSRN_gt: 32.331343\n",
            "Iteration: 03664, Loss: 0.000106, PSRN_gt: 32.282007\n",
            "Iteration: 03665, Loss: 0.000108, PSRN_gt: 32.285832\n",
            "Iteration: 03666, Loss: 0.000108, PSRN_gt: 32.256504\n",
            "Iteration: 03667, Loss: 0.000110, PSRN_gt: 32.243349\n",
            "Iteration: 03668, Loss: 0.000110, PSRN_gt: 32.231863\n",
            "Iteration: 03669, Loss: 0.000109, PSRN_gt: 32.241170\n",
            "Iteration: 03670, Loss: 0.000106, PSRN_gt: 32.294564\n",
            "Iteration: 03671, Loss: 0.000104, PSRN_gt: 32.315819\n",
            "Iteration: 03672, Loss: 0.000103, PSRN_gt: 32.305564\n",
            "Iteration: 03673, Loss: 0.000104, PSRN_gt: 32.317781\n",
            "Iteration: 03674, Loss: 0.000107, PSRN_gt: 32.274043\n",
            "Iteration: 03675, Loss: 0.000112, PSRN_gt: 32.211500\n",
            "Iteration: 03676, Loss: 0.000116, PSRN_gt: 32.138344\n",
            "Iteration: 03677, Loss: 0.000122, PSRN_gt: 32.076632\n",
            "Iteration: 03678, Loss: 0.000126, PSRN_gt: 32.007475\n",
            "Iteration: 03679, Loss: 0.000128, PSRN_gt: 31.995723\n",
            "Iteration: 03680, Loss: 0.000125, PSRN_gt: 32.032982\n",
            "Iteration: 03681, Loss: 0.000123, PSRN_gt: 32.059264\n",
            "Iteration: 03682, Loss: 0.000123, PSRN_gt: 32.067217\n",
            "Iteration: 03683, Loss: 0.000124, PSRN_gt: 32.060283\n",
            "Iteration: 03684, Loss: 0.000123, PSRN_gt: 32.043041\n",
            "Iteration: 03685, Loss: 0.000123, PSRN_gt: 32.087876\n",
            "Iteration: 03686, Loss: 0.000127, PSRN_gt: 31.995603\n",
            "Iteration: 03687, Loss: 0.000127, PSRN_gt: 32.030164\n",
            "Iteration: 03688, Loss: 0.000124, PSRN_gt: 32.045120\n",
            "Iteration: 03689, Loss: 0.000117, PSRN_gt: 32.139233\n",
            "Iteration: 03690, Loss: 0.000116, PSRN_gt: 32.170282\n",
            "Iteration: 03691, Loss: 0.000119, PSRN_gt: 32.116489\n",
            "Iteration: 03692, Loss: 0.000117, PSRN_gt: 32.160955\n",
            "Iteration: 03693, Loss: 0.000110, PSRN_gt: 32.251907\n",
            "Iteration: 03694, Loss: 0.000105, PSRN_gt: 32.318726\n",
            "Iteration: 03695, Loss: 0.000103, PSRN_gt: 32.341177\n",
            "Iteration: 03696, Loss: 0.000103, PSRN_gt: 32.361109\n",
            "Iteration: 03697, Loss: 0.000102, PSRN_gt: 32.342837\n",
            "Iteration: 03698, Loss: 0.000102, PSRN_gt: 32.378388\n",
            "Iteration: 03699, Loss: 0.000100, PSRN_gt: 32.365128\n",
            "Iteration: 03700, Loss: 0.000100, PSRN_gt: 32.379781\n",
            "Iteration: 03701, Loss: 0.000101, PSRN_gt: 32.361441\n",
            "Iteration: 03702, Loss: 0.000101, PSRN_gt: 32.369378\n",
            "Iteration: 03703, Loss: 0.000102, PSRN_gt: 32.333254\n",
            "Iteration: 03704, Loss: 0.000104, PSRN_gt: 32.325889\n",
            "Iteration: 03705, Loss: 0.000108, PSRN_gt: 32.238659\n",
            "Iteration: 03706, Loss: 0.000113, PSRN_gt: 32.202446\n",
            "Iteration: 03707, Loss: 0.000118, PSRN_gt: 32.091345\n",
            "Iteration: 03708, Loss: 0.000123, PSRN_gt: 32.077433\n",
            "Iteration: 03709, Loss: 0.000125, PSRN_gt: 31.988486\n",
            "Iteration: 03710, Loss: 0.000126, PSRN_gt: 32.032405\n",
            "Iteration: 03711, Loss: 0.000120, PSRN_gt: 32.071716\n",
            "Iteration: 03712, Loss: 0.000112, PSRN_gt: 32.211603\n",
            "Iteration: 03713, Loss: 0.000108, PSRN_gt: 32.233200\n",
            "Iteration: 03714, Loss: 0.000112, PSRN_gt: 32.213292\n",
            "Iteration: 03715, Loss: 0.000116, PSRN_gt: 32.147651\n",
            "Iteration: 03716, Loss: 0.000117, PSRN_gt: 32.107261\n",
            "Iteration: 03717, Loss: 0.000116, PSRN_gt: 32.172918\n",
            "Iteration: 03718, Loss: 0.000111, PSRN_gt: 32.194726\n",
            "Iteration: 03719, Loss: 0.000104, PSRN_gt: 32.326225\n",
            "Iteration: 03720, Loss: 0.000100, PSRN_gt: 32.375527\n",
            "Iteration: 03721, Loss: 0.000100, PSRN_gt: 32.369984\n",
            "Iteration: 03722, Loss: 0.000100, PSRN_gt: 32.370341\n",
            "Iteration: 03723, Loss: 0.000102, PSRN_gt: 32.338041\n",
            "Iteration: 03724, Loss: 0.000102, PSRN_gt: 32.347955\n",
            "Iteration: 03725, Loss: 0.000101, PSRN_gt: 32.352970\n",
            "Iteration: 03726, Loss: 0.000100, PSRN_gt: 32.383645\n",
            "Iteration: 03727, Loss: 0.000099, PSRN_gt: 32.371651\n",
            "Iteration: 03728, Loss: 0.000099, PSRN_gt: 32.385039\n",
            "Iteration: 03729, Loss: 0.000099, PSRN_gt: 32.370629\n",
            "Iteration: 03730, Loss: 0.000100, PSRN_gt: 32.357941\n",
            "Iteration: 03731, Loss: 0.000103, PSRN_gt: 32.327765\n",
            "Iteration: 03732, Loss: 0.000104, PSRN_gt: 32.300588\n",
            "Iteration: 03733, Loss: 0.000105, PSRN_gt: 32.296793\n",
            "Iteration: 03734, Loss: 0.000104, PSRN_gt: 32.305931\n",
            "Iteration: 03735, Loss: 0.000103, PSRN_gt: 32.315576\n",
            "Iteration: 03736, Loss: 0.000104, PSRN_gt: 32.304788\n",
            "Iteration: 03737, Loss: 0.000105, PSRN_gt: 32.283479\n",
            "Iteration: 03738, Loss: 0.000106, PSRN_gt: 32.280454\n",
            "Iteration: 03739, Loss: 0.000106, PSRN_gt: 32.281617\n",
            "Iteration: 03740, Loss: 0.000107, PSRN_gt: 32.244129\n",
            "Iteration: 03741, Loss: 0.000110, PSRN_gt: 32.224463\n",
            "Iteration: 03742, Loss: 0.000115, PSRN_gt: 32.156341\n",
            "Iteration: 03743, Loss: 0.000122, PSRN_gt: 32.078325\n",
            "Iteration: 03744, Loss: 0.000130, PSRN_gt: 31.933713\n",
            "Iteration: 03745, Loss: 0.000142, PSRN_gt: 31.813353\n",
            "Iteration: 03746, Loss: 0.000150, PSRN_gt: 31.671293\n",
            "Iteration: 03747, Loss: 0.000153, PSRN_gt: 31.673617\n",
            "Iteration: 03748, Loss: 0.000153, PSRN_gt: 31.636476\n",
            "Iteration: 03749, Loss: 0.000161, PSRN_gt: 31.614821\n",
            "Iteration: 03750, Loss: 0.000162, PSRN_gt: 31.527409\n",
            "Iteration: 03751, Loss: 0.000166, PSRN_gt: 31.567058\n",
            "Iteration: 03752, Loss: 0.000159, PSRN_gt: 31.557505\n",
            "Iteration: 03753, Loss: 0.000150, PSRN_gt: 31.742563\n",
            "Iteration: 03754, Loss: 0.000143, PSRN_gt: 31.823665\n",
            "Iteration: 03755, Loss: 0.000138, PSRN_gt: 31.834864\n",
            "Iteration: 03756, Loss: 0.000132, PSRN_gt: 31.988809\n",
            "Iteration: 03757, Loss: 0.000125, PSRN_gt: 32.057626\n",
            "Iteration: 03758, Loss: 0.000125, PSRN_gt: 32.057817\n",
            "Iteration: 03759, Loss: 0.000122, PSRN_gt: 32.109945\n",
            "Iteration: 03760, Loss: 0.000116, PSRN_gt: 32.175612\n",
            "Iteration: 03761, Loss: 0.000115, PSRN_gt: 32.162548\n",
            "Iteration: 03762, Loss: 0.000113, PSRN_gt: 32.226457\n",
            "Iteration: 03763, Loss: 0.000109, PSRN_gt: 32.282799\n",
            "Iteration: 03764, Loss: 0.000108, PSRN_gt: 32.292809\n",
            "Iteration: 03765, Loss: 0.000105, PSRN_gt: 32.326876\n",
            "Iteration: 03766, Loss: 0.000102, PSRN_gt: 32.363435\n",
            "Iteration: 03767, Loss: 0.000102, PSRN_gt: 32.388355\n",
            "Iteration: 03768, Loss: 0.000100, PSRN_gt: 32.392995\n",
            "Iteration: 03769, Loss: 0.000099, PSRN_gt: 32.398962\n",
            "Iteration: 03770, Loss: 0.000098, PSRN_gt: 32.404091\n",
            "Iteration: 03771, Loss: 0.000097, PSRN_gt: 32.434306\n",
            "Iteration: 03772, Loss: 0.000095, PSRN_gt: 32.441975\n",
            "Iteration: 03773, Loss: 0.000094, PSRN_gt: 32.465723\n",
            "Iteration: 03774, Loss: 0.000093, PSRN_gt: 32.468552\n",
            "Iteration: 03775, Loss: 0.000092, PSRN_gt: 32.480542\n",
            "Iteration: 03776, Loss: 0.000092, PSRN_gt: 32.479519\n",
            "Iteration: 03777, Loss: 0.000091, PSRN_gt: 32.490067\n",
            "Iteration: 03778, Loss: 0.000090, PSRN_gt: 32.495462\n",
            "Iteration: 03779, Loss: 0.000090, PSRN_gt: 32.494688\n",
            "Iteration: 03780, Loss: 0.000090, PSRN_gt: 32.512888\n",
            "Iteration: 03781, Loss: 0.000090, PSRN_gt: 32.497828\n",
            "Iteration: 03782, Loss: 0.000090, PSRN_gt: 32.491623\n",
            "Iteration: 03783, Loss: 0.000091, PSRN_gt: 32.478616\n",
            "Iteration: 03784, Loss: 0.000093, PSRN_gt: 32.458735\n",
            "Iteration: 03785, Loss: 0.000095, PSRN_gt: 32.397888\n",
            "Iteration: 03786, Loss: 0.000099, PSRN_gt: 32.360337\n",
            "Iteration: 03787, Loss: 0.000105, PSRN_gt: 32.260910\n",
            "Iteration: 03788, Loss: 0.000113, PSRN_gt: 32.163148\n",
            "Iteration: 03789, Loss: 0.000121, PSRN_gt: 32.036581\n",
            "Iteration: 03790, Loss: 0.000127, PSRN_gt: 31.975708\n",
            "Iteration: 03791, Loss: 0.000129, PSRN_gt: 31.944947\n",
            "Iteration: 03792, Loss: 0.000125, PSRN_gt: 32.005938\n",
            "Iteration: 03793, Loss: 0.000120, PSRN_gt: 32.081107\n",
            "Iteration: 03794, Loss: 0.000119, PSRN_gt: 32.090925\n",
            "Iteration: 03795, Loss: 0.000125, PSRN_gt: 32.028168\n",
            "Iteration: 03796, Loss: 0.000131, PSRN_gt: 31.935339\n",
            "Iteration: 03797, Loss: 0.000135, PSRN_gt: 31.865907\n",
            "Iteration: 03798, Loss: 0.000136, PSRN_gt: 31.880294\n",
            "Iteration: 03799, Loss: 0.000138, PSRN_gt: 31.803497\n",
            "Iteration: 03800, Loss: 0.000146, PSRN_gt: 31.796651\n",
            "Iteration: 03801, Loss: 0.000151, PSRN_gt: 31.669784\n",
            "Iteration: 03802, Loss: 0.000153, PSRN_gt: 31.683975\n",
            "Iteration: 03803, Loss: 0.000148, PSRN_gt: 31.727473\n",
            "Iteration: 03804, Loss: 0.000145, PSRN_gt: 31.765639\n",
            "Iteration: 03805, Loss: 0.000133, PSRN_gt: 31.964725\n",
            "Iteration: 03806, Loss: 0.000122, PSRN_gt: 32.059305\n",
            "Iteration: 03807, Loss: 0.000121, PSRN_gt: 32.109801\n",
            "Iteration: 03808, Loss: 0.000122, PSRN_gt: 32.087429\n",
            "Iteration: 03809, Loss: 0.000121, PSRN_gt: 32.068027\n",
            "Iteration: 03810, Loss: 0.000118, PSRN_gt: 32.134329\n",
            "Iteration: 03811, Loss: 0.000114, PSRN_gt: 32.207268\n",
            "Iteration: 03812, Loss: 0.000111, PSRN_gt: 32.206405\n",
            "Iteration: 03813, Loss: 0.000109, PSRN_gt: 32.271295\n",
            "Iteration: 03814, Loss: 0.000105, PSRN_gt: 32.302677\n",
            "Iteration: 03815, Loss: 0.000101, PSRN_gt: 32.360929\n",
            "Iteration: 03816, Loss: 0.000100, PSRN_gt: 32.383028\n",
            "Iteration: 03817, Loss: 0.000099, PSRN_gt: 32.388401\n",
            "Iteration: 03818, Loss: 0.000097, PSRN_gt: 32.425556\n",
            "Iteration: 03819, Loss: 0.000097, PSRN_gt: 32.416095\n",
            "Iteration: 03820, Loss: 0.000096, PSRN_gt: 32.426320\n",
            "Iteration: 03821, Loss: 0.000094, PSRN_gt: 32.440584\n",
            "Iteration: 03822, Loss: 0.000093, PSRN_gt: 32.469145\n",
            "Iteration: 03823, Loss: 0.000092, PSRN_gt: 32.468898\n",
            "Iteration: 03824, Loss: 0.000091, PSRN_gt: 32.498476\n",
            "Iteration: 03825, Loss: 0.000090, PSRN_gt: 32.491470\n",
            "Iteration: 03826, Loss: 0.000089, PSRN_gt: 32.501694\n",
            "Iteration: 03827, Loss: 0.000089, PSRN_gt: 32.496745\n",
            "Iteration: 03828, Loss: 0.000088, PSRN_gt: 32.517864\n",
            "Iteration: 03829, Loss: 0.000088, PSRN_gt: 32.511864\n",
            "Iteration: 03830, Loss: 0.000089, PSRN_gt: 32.511072\n",
            "Iteration: 03831, Loss: 0.000089, PSRN_gt: 32.508074\n",
            "Iteration: 03832, Loss: 0.000089, PSRN_gt: 32.508381\n",
            "Iteration: 03833, Loss: 0.000091, PSRN_gt: 32.459363\n",
            "Iteration: 03834, Loss: 0.000093, PSRN_gt: 32.448236\n",
            "Iteration: 03835, Loss: 0.000096, PSRN_gt: 32.387948\n",
            "Iteration: 03836, Loss: 0.000101, PSRN_gt: 32.324147\n",
            "Iteration: 03837, Loss: 0.000109, PSRN_gt: 32.197064\n",
            "Iteration: 03838, Loss: 0.000120, PSRN_gt: 32.055061\n",
            "Iteration: 03839, Loss: 0.000134, PSRN_gt: 31.865319\n",
            "Iteration: 03840, Loss: 0.000151, PSRN_gt: 31.661946\n",
            "Iteration: 03841, Loss: 0.000161, PSRN_gt: 31.541719\n",
            "Iteration: 03842, Loss: 0.000159, PSRN_gt: 31.566383\n",
            "Iteration: 03843, Loss: 0.000144, PSRN_gt: 31.772856\n",
            "Iteration: 03844, Loss: 0.000130, PSRN_gt: 31.969364\n",
            "Iteration: 03845, Loss: 0.000130, PSRN_gt: 31.963666\n",
            "Iteration: 03846, Loss: 0.000139, PSRN_gt: 31.851515\n",
            "Iteration: 03847, Loss: 0.000138, PSRN_gt: 31.826664\n",
            "Iteration: 03848, Loss: 0.000128, PSRN_gt: 32.007107\n",
            "Iteration: 03849, Loss: 0.000118, PSRN_gt: 32.113866\n",
            "Iteration: 03850, Loss: 0.000117, PSRN_gt: 32.145846\n",
            "Iteration: 03851, Loss: 0.000119, PSRN_gt: 32.108972\n",
            "Iteration: 03852, Loss: 0.000116, PSRN_gt: 32.139349\n",
            "Iteration: 03853, Loss: 0.000112, PSRN_gt: 32.196480\n",
            "Iteration: 03854, Loss: 0.000111, PSRN_gt: 32.226137\n",
            "Iteration: 03855, Loss: 0.000109, PSRN_gt: 32.223856\n",
            "Iteration: 03856, Loss: 0.000104, PSRN_gt: 32.330946\n",
            "Iteration: 03857, Loss: 0.000101, PSRN_gt: 32.336464\n",
            "Iteration: 03858, Loss: 0.000105, PSRN_gt: 32.301633\n",
            "Iteration: 03859, Loss: 0.000104, PSRN_gt: 32.301944\n",
            "Iteration: 03860, Loss: 0.000100, PSRN_gt: 32.362790\n",
            "Iteration: 03861, Loss: 0.000098, PSRN_gt: 32.390859\n",
            "Iteration: 03862, Loss: 0.000100, PSRN_gt: 32.357672\n",
            "Iteration: 03863, Loss: 0.000101, PSRN_gt: 32.339296\n",
            "Iteration: 03864, Loss: 0.000098, PSRN_gt: 32.384835\n",
            "Iteration: 03865, Loss: 0.000096, PSRN_gt: 32.401152\n",
            "Iteration: 03866, Loss: 0.000098, PSRN_gt: 32.371566\n",
            "Iteration: 03867, Loss: 0.000097, PSRN_gt: 32.386887\n",
            "Iteration: 03868, Loss: 0.000099, PSRN_gt: 32.369687\n",
            "Iteration: 03869, Loss: 0.000101, PSRN_gt: 32.322565\n",
            "Iteration: 03870, Loss: 0.000102, PSRN_gt: 32.311512\n",
            "Iteration: 03871, Loss: 0.000104, PSRN_gt: 32.290533\n",
            "Iteration: 03872, Loss: 0.000104, PSRN_gt: 32.264243\n",
            "Iteration: 03873, Loss: 0.000104, PSRN_gt: 32.294214\n",
            "Iteration: 03874, Loss: 0.000103, PSRN_gt: 32.276997\n",
            "Iteration: 03875, Loss: 0.000102, PSRN_gt: 32.330019\n",
            "Iteration: 03876, Loss: 0.000099, PSRN_gt: 32.320231\n",
            "Iteration: 03877, Loss: 0.000099, PSRN_gt: 32.375424\n",
            "Iteration: 03878, Loss: 0.000099, PSRN_gt: 32.311145\n",
            "Iteration: 03879, Loss: 0.000104, PSRN_gt: 32.301469\n",
            "Iteration: 03880, Loss: 0.000108, PSRN_gt: 32.204954\n",
            "Iteration: 03881, Loss: 0.000110, PSRN_gt: 32.218578\n",
            "Iteration: 03882, Loss: 0.000107, PSRN_gt: 32.196136\n",
            "Iteration: 03883, Loss: 0.000103, PSRN_gt: 32.308672\n",
            "Iteration: 03884, Loss: 0.000098, PSRN_gt: 32.354007\n",
            "Iteration: 03885, Loss: 0.000095, PSRN_gt: 32.404691\n",
            "Iteration: 03886, Loss: 0.000095, PSRN_gt: 32.405127\n",
            "Iteration: 03887, Loss: 0.000097, PSRN_gt: 32.376868\n",
            "Iteration: 03888, Loss: 0.000099, PSRN_gt: 32.343474\n",
            "Iteration: 03889, Loss: 0.000100, PSRN_gt: 32.318182\n",
            "Iteration: 03890, Loss: 0.000100, PSRN_gt: 32.350356\n",
            "Iteration: 03891, Loss: 0.000098, PSRN_gt: 32.339179\n",
            "Iteration: 03892, Loss: 0.000098, PSRN_gt: 32.377881\n",
            "Iteration: 03893, Loss: 0.000099, PSRN_gt: 32.322099\n",
            "Iteration: 03894, Loss: 0.000103, PSRN_gt: 32.290023\n",
            "Iteration: 03895, Loss: 0.000110, PSRN_gt: 32.200976\n",
            "Iteration: 03896, Loss: 0.000119, PSRN_gt: 32.049415\n",
            "Iteration: 03897, Loss: 0.000129, PSRN_gt: 31.936100\n",
            "Iteration: 03898, Loss: 0.000136, PSRN_gt: 31.859011\n",
            "Iteration: 03899, Loss: 0.000137, PSRN_gt: 31.814391\n",
            "Iteration: 03900, Loss: 0.000137, PSRN_gt: 31.856778\n",
            "Iteration: 03901, Loss: 0.000134, PSRN_gt: 31.858478\n",
            "Iteration: 03902, Loss: 0.000131, PSRN_gt: 31.953262\n",
            "Iteration: 03903, Loss: 0.000129, PSRN_gt: 31.913785\n",
            "Iteration: 03904, Loss: 0.000133, PSRN_gt: 31.932306\n",
            "Iteration: 03905, Loss: 0.000132, PSRN_gt: 31.889139\n",
            "Iteration: 03906, Loss: 0.000130, PSRN_gt: 31.950413\n",
            "Iteration: 03907, Loss: 0.000129, PSRN_gt: 31.962674\n",
            "Iteration: 03908, Loss: 0.000127, PSRN_gt: 31.968517\n",
            "Iteration: 03909, Loss: 0.000121, PSRN_gt: 32.072480\n",
            "Iteration: 03910, Loss: 0.000113, PSRN_gt: 32.156281\n",
            "Iteration: 03911, Loss: 0.000109, PSRN_gt: 32.255889\n",
            "Iteration: 03912, Loss: 0.000107, PSRN_gt: 32.254325\n",
            "Iteration: 03913, Loss: 0.000105, PSRN_gt: 32.272902\n",
            "Iteration: 03914, Loss: 0.000105, PSRN_gt: 32.304524\n",
            "Iteration: 03915, Loss: 0.000101, PSRN_gt: 32.327809\n",
            "Iteration: 03916, Loss: 0.000098, PSRN_gt: 32.391475\n",
            "Iteration: 03917, Loss: 0.000098, PSRN_gt: 32.395166\n",
            "Iteration: 03918, Loss: 0.000095, PSRN_gt: 32.403923\n",
            "Iteration: 03919, Loss: 0.000094, PSRN_gt: 32.436199\n",
            "Iteration: 03920, Loss: 0.000094, PSRN_gt: 32.438558\n",
            "Iteration: 03921, Loss: 0.000093, PSRN_gt: 32.444440\n",
            "Iteration: 03922, Loss: 0.000091, PSRN_gt: 32.465857\n",
            "Iteration: 03923, Loss: 0.000091, PSRN_gt: 32.473303\n",
            "Iteration: 03924, Loss: 0.000092, PSRN_gt: 32.441437\n",
            "Iteration: 03925, Loss: 0.000092, PSRN_gt: 32.459211\n",
            "Iteration: 03926, Loss: 0.000093, PSRN_gt: 32.433417\n",
            "Iteration: 03927, Loss: 0.000094, PSRN_gt: 32.427338\n",
            "Iteration: 03928, Loss: 0.000095, PSRN_gt: 32.377567\n",
            "Iteration: 03929, Loss: 0.000098, PSRN_gt: 32.368862\n",
            "Iteration: 03930, Loss: 0.000101, PSRN_gt: 32.312814\n",
            "Iteration: 03931, Loss: 0.000105, PSRN_gt: 32.265059\n",
            "Iteration: 03932, Loss: 0.000109, PSRN_gt: 32.174458\n",
            "Iteration: 03933, Loss: 0.000112, PSRN_gt: 32.155947\n",
            "Iteration: 03934, Loss: 0.000112, PSRN_gt: 32.136828\n",
            "Iteration: 03935, Loss: 0.000110, PSRN_gt: 32.182260\n",
            "Iteration: 03936, Loss: 0.000105, PSRN_gt: 32.237686\n",
            "Iteration: 03937, Loss: 0.000102, PSRN_gt: 32.309159\n",
            "Iteration: 03938, Loss: 0.000101, PSRN_gt: 32.296776\n",
            "Iteration: 03939, Loss: 0.000106, PSRN_gt: 32.250976\n",
            "Iteration: 03940, Loss: 0.000113, PSRN_gt: 32.129332\n",
            "Iteration: 03941, Loss: 0.000116, PSRN_gt: 32.114765\n",
            "Iteration: 03942, Loss: 0.000112, PSRN_gt: 32.148506\n",
            "Iteration: 03943, Loss: 0.000103, PSRN_gt: 32.299193\n",
            "Iteration: 03944, Loss: 0.000095, PSRN_gt: 32.399849\n",
            "Iteration: 03945, Loss: 0.000095, PSRN_gt: 32.396321\n",
            "Iteration: 03946, Loss: 0.000100, PSRN_gt: 32.336207\n",
            "Iteration: 03947, Loss: 0.000103, PSRN_gt: 32.278395\n",
            "Iteration: 03948, Loss: 0.000099, PSRN_gt: 32.359303\n",
            "Iteration: 03949, Loss: 0.000093, PSRN_gt: 32.403997\n",
            "Iteration: 03950, Loss: 0.000092, PSRN_gt: 32.462749\n",
            "Iteration: 03951, Loss: 0.000094, PSRN_gt: 32.421925\n",
            "Iteration: 03952, Loss: 0.000094, PSRN_gt: 32.405986\n",
            "Iteration: 03953, Loss: 0.000093, PSRN_gt: 32.438559\n",
            "Iteration: 03954, Loss: 0.000094, PSRN_gt: 32.426844\n",
            "Iteration: 03955, Loss: 0.000098, PSRN_gt: 32.349192\n",
            "Iteration: 03956, Loss: 0.000102, PSRN_gt: 32.305681\n",
            "Iteration: 03957, Loss: 0.000106, PSRN_gt: 32.218133\n",
            "Iteration: 03958, Loss: 0.000114, PSRN_gt: 32.150114\n",
            "Iteration: 03959, Loss: 0.000120, PSRN_gt: 32.027218\n",
            "Iteration: 03960, Loss: 0.000129, PSRN_gt: 31.939090\n",
            "Iteration: 03961, Loss: 0.000132, PSRN_gt: 31.892181\n",
            "Iteration: 03962, Loss: 0.000138, PSRN_gt: 31.802976\n",
            "Iteration: 03963, Loss: 0.000135, PSRN_gt: 31.866073\n",
            "Iteration: 03964, Loss: 0.000129, PSRN_gt: 31.935896\n",
            "Iteration: 03965, Loss: 0.000126, PSRN_gt: 31.975569\n",
            "Iteration: 03966, Loss: 0.000130, PSRN_gt: 31.936128\n",
            "Iteration: 03967, Loss: 0.000133, PSRN_gt: 31.898190\n",
            "Iteration: 03968, Loss: 0.000135, PSRN_gt: 31.863965\n",
            "Iteration: 03969, Loss: 0.000140, PSRN_gt: 31.826674\n",
            "Iteration: 03970, Loss: 0.000140, PSRN_gt: 31.797516\n",
            "Iteration: 03971, Loss: 0.000137, PSRN_gt: 31.897994\n",
            "Iteration: 03972, Loss: 0.000130, PSRN_gt: 31.927302\n",
            "Iteration: 03973, Loss: 0.000126, PSRN_gt: 32.006814\n",
            "Iteration: 03974, Loss: 0.000120, PSRN_gt: 32.081560\n",
            "Iteration: 03975, Loss: 0.000112, PSRN_gt: 32.189537\n",
            "Iteration: 03976, Loss: 0.000113, PSRN_gt: 32.179064\n",
            "Iteration: 03977, Loss: 0.000113, PSRN_gt: 32.166229\n",
            "Iteration: 03978, Loss: 0.000112, PSRN_gt: 32.203253\n",
            "Iteration: 03979, Loss: 0.000110, PSRN_gt: 32.225720\n",
            "Iteration: 03980, Loss: 0.000105, PSRN_gt: 32.271204\n",
            "Iteration: 03981, Loss: 0.000104, PSRN_gt: 32.321954\n",
            "Iteration: 03982, Loss: 0.000099, PSRN_gt: 32.339894\n",
            "Iteration: 03983, Loss: 0.000097, PSRN_gt: 32.387781\n",
            "Iteration: 03984, Loss: 0.000097, PSRN_gt: 32.381575\n",
            "Iteration: 03985, Loss: 0.000095, PSRN_gt: 32.420478\n",
            "Iteration: 03986, Loss: 0.000093, PSRN_gt: 32.409913\n",
            "Iteration: 03987, Loss: 0.000093, PSRN_gt: 32.432061\n",
            "Iteration: 03988, Loss: 0.000091, PSRN_gt: 32.454896\n",
            "Iteration: 03989, Loss: 0.000090, PSRN_gt: 32.480362\n",
            "Iteration: 03990, Loss: 0.000090, PSRN_gt: 32.472493\n",
            "Iteration: 03991, Loss: 0.000088, PSRN_gt: 32.482756\n",
            "Iteration: 03992, Loss: 0.000088, PSRN_gt: 32.492975\n",
            "Iteration: 03993, Loss: 0.000089, PSRN_gt: 32.487488\n",
            "Iteration: 03994, Loss: 0.000088, PSRN_gt: 32.490808\n",
            "Iteration: 03995, Loss: 0.000089, PSRN_gt: 32.482744\n",
            "Iteration: 03996, Loss: 0.000090, PSRN_gt: 32.451661\n",
            "Iteration: 03997, Loss: 0.000091, PSRN_gt: 32.443828\n",
            "Iteration: 03998, Loss: 0.000093, PSRN_gt: 32.395371\n",
            "Iteration: 03999, Loss: 0.000095, PSRN_gt: 32.392923\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Can't write images with one color channel.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6c2a962ba74f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0mout_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0msave2img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./figs/%s_inpainted.png\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#save the denoised image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0mfrequency_lists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsnr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_log_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b7f75d91a63f>\u001b[0m in \u001b[0;36msave2img\u001b[0;34m(d_img, fn)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_img\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave2enhanceimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imageio/v2.py\u001b[0m in \u001b[0;36mimwrite\u001b[0;34m(uri, im, format, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0mimopen_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"legacy_mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mimopen_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, ndimage, mode, format, is_batch, **kwargs)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mis_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't write images with one color channel.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# Note: this makes a channel-last assumption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't write images with one color channel."
          ]
        }
      ]
    }
  ]
}